{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/archit436/Birds_Classifier/blob/main/Models/Main_Models/Main_Model_Audio_Main_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2Z5OlZ26H5S"
   },
   "source": [
    "0. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2v-te8X34pLq"
   },
   "outputs": [],
   "source": [
    "# Start by importing the relevant libraries.\n",
    "# Copied from Archit's Lab 3 Submission and then some more.\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPpgSPG16MVP"
   },
   "source": [
    "1. Data Preprocessing - HOG Features of Spectrograns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "Ce4imqv16FaI",
    "outputId": "796a298d-7eb5-4fcf-e73b-62fdf1d14186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"birds_df\",\n  \"rows\": 107,\n  \"fields\": [\n    {\n      \"column\": \"Class ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 186,\n        \"min\": 315,\n        \"max\": 987,\n        \"num_unique_values\": 107,\n        \"samples\": [\n          884,\n          458,\n          352\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Images Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 100,\n        \"max\": 120,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          116,\n          115,\n          104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"XC Recordings Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 152,\n        \"min\": 75,\n        \"max\": 850,\n        \"num_unique_values\": 87,\n        \"samples\": [\n          149,\n          167,\n          338\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Species Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 107,\n        \"samples\": [\n          \"Canada Warbler\",\n          \"Mute Swan\",\n          \"Black-crowned Night-Heron (Adult)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"XC Species Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 107,\n        \"samples\": [\n          \"Canada Warbler\",\n          \"Mute Swan\",\n          \"Black-crowned Night Heron\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "birds_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e3315a37-894f-4b68-aea8-9e261dae39f6\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class ID</th>\n",
       "      <th>Images Count</th>\n",
       "      <th>XC Recordings Count</th>\n",
       "      <th>Species Name</th>\n",
       "      <th>XC Species Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>315</td>\n",
       "      <td>116</td>\n",
       "      <td>167</td>\n",
       "      <td>Gadwall (Breeding male)</td>\n",
       "      <td>Gadwall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>Mallard (Breeding male)</td>\n",
       "      <td>Mallard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>333</td>\n",
       "      <td>105</td>\n",
       "      <td>114</td>\n",
       "      <td>Common Goldeneye (Breeding male)</td>\n",
       "      <td>Common Goldeneye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>338</td>\n",
       "      <td>116</td>\n",
       "      <td>89</td>\n",
       "      <td>California Quail (Male)</td>\n",
       "      <td>California Quail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>352</td>\n",
       "      <td>120</td>\n",
       "      <td>285</td>\n",
       "      <td>Black-crowned Night-Heron (Adult)</td>\n",
       "      <td>Black-crowned Night Heron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3315a37-894f-4b68-aea8-9e261dae39f6')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e3315a37-894f-4b68-aea8-9e261dae39f6 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e3315a37-894f-4b68-aea8-9e261dae39f6');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-6b2925e7-b9c2-4bb5-b62a-92df10c0337b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b2925e7-b9c2-4bb5-b62a-92df10c0337b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-6b2925e7-b9c2-4bb5-b62a-92df10c0337b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Class ID  Images Count  XC Recordings Count  \\\n",
       "0       315           116                  167   \n",
       "1       317           120                  240   \n",
       "2       333           105                  114   \n",
       "3       338           116                   89   \n",
       "4       352           120                  285   \n",
       "\n",
       "                        Species Name            XC Species Name  \n",
       "0            Gadwall (Breeding male)                    Gadwall  \n",
       "1            Mallard (Breeding male)                    Mallard  \n",
       "2   Common Goldeneye (Breeding male)           Common Goldeneye  \n",
       "3            California Quail (Male)           California Quail  \n",
       "4  Black-crowned Night-Heron (Adult)  Black-crowned Night Heron  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mount the drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# Import the csv file with the data details\n",
    "csv_path = \"/content/drive/MyDrive/APS360_Team_15/Data_Processing/chosen_classes_data_stats.csv\"\n",
    "birds_df = pd.read_csv(csv_path)\n",
    "birds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZw8YO3z94ip",
    "outputId": "5e14e882-b055-496d-b0c9-d92a113f25e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-ad1f6ea53532>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features_tensor = torch.load(pt_file)\n"
     ]
    }
   ],
   "source": [
    "# Now we move on to loading the category.pt files defined for each class.\n",
    "# Define the directory of the audio data.\n",
    "xc_data_dir = '/content/drive/MyDrive/APS360_Team_15/Data/Xeno_Canto'\n",
    "\n",
    "# Define lists to store the tensors extracted from the .pt files.\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through all the birds, skipping the ones without a .pt file.\n",
    "for it_bird in range(birds_df.shape[0]):\n",
    "  # Find the bird class ID and accordingly find the corresponding .pt file.\n",
    "  bird_class_id = birds_df.loc[it_bird, 'Class ID']\n",
    "  pt_file = glob.glob(os.path.join(xc_data_dir, str(bird_class_id), '*.pt'))\n",
    "  # Check if .pt file exists for this bird.\n",
    "  if(pt_file == []):\n",
    "    continue\n",
    "  # Iterate through all the pt files for this bird.\n",
    "  for pt_file in pt_file:\n",
    "    # Extract the data into a tensor.\n",
    "    features_tensor = torch.load(pt_file)\n",
    "    # Populate the lists with the features and labels tensors.\n",
    "    # For labels, we create a 1D tensor with num_samples of class id values.\n",
    "    num_samples = features_tensor['features'].shape[0]\n",
    "    all_features.append(features_tensor['features'])\n",
    "    all_labels.append(torch.full((num_samples,), bird_class_id, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsPfYRYO8vsk",
    "outputId": "f7c54e77-9ed0-4182-87ae-ec5d58655e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes for which data has been extracted: 101\n"
     ]
    }
   ],
   "source": [
    "# Print out number of classes for which data has been extracted.\n",
    "class_ids = [tensor[0].item() for tensor in all_labels]\n",
    "labels_set = sorted(set(class_ids))\n",
    "num_classes = len(labels_set)\n",
    "print(f\"Number of classes for which data has been extracted: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7GSA0yBWXm9U",
    "outputId": "aa9b3db6-0545-4f65-f4bf-e265a1c87208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features tensor: torch.Size([17687, 1764])\n",
      "Shape of labels tensor: torch.Size([17687])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all the tensors into one tensor.\n",
    "features_tensor = torch.cat(all_features, dim=0)\n",
    "labels_tensor = torch.cat(all_labels, dim=0)\n",
    "\n",
    "# Encode the labels to make them suitable for training the model.\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels_tensor)\n",
    "# Create mapping dictionaries for the encoding.\n",
    "id_to_index = dict(zip(labels_tensor, encoded_labels))\n",
    "index_to_id = dict(zip(encoded_labels, labels_tensor))\n",
    "# Pickle dump these mappings for use later.\n",
    "with open('label_mappings.pkl', 'wb') as f:\n",
    "    pickle.dump({'id_to_index': id_to_index, 'index_to_id': index_to_id}, f)\n",
    "\n",
    "# Replace the labels tensor.\n",
    "labels_tensor = torch.from_numpy(encoded_labels)\n",
    "\n",
    "# Print out stats.\n",
    "print(f\"Shape of features tensor: {features_tensor.shape}\")\n",
    "print(f\"Shape of labels tensor: {labels_tensor.shape}\")\n",
    "\n",
    "# Convert the tensors into numpy for sci-kit learn functions.\n",
    "features_np = features_tensor.numpy()\n",
    "labels_np = labels_tensor.numpy()\n",
    "\n",
    "# First split: (training + validation) vs test - 80:20\n",
    "# We use a stratified split for uniform distributions of the classes.\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "temp_idx, test_idx = next(sss1.split(features_np, labels_np))\n",
    "\n",
    "# Get the temporary set.\n",
    "temp_features_np = features_np[temp_idx]\n",
    "temp_labels_np = labels_np[temp_idx]\n",
    "\n",
    "# Second split: training vs validation - 80:20\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "train_idx, val_idx = next(sss2.split(temp_features_np, temp_labels_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lk05SzoHEVP5",
    "outputId": "ab07e462-953c-45a5-c4df-b646d81e6fea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features tensor: (11319, 1764)\n",
      "Shape of training labels tensor: (11319,)\n",
      "Shape of validation features tensor: (2830, 1764)\n",
      "Shape of validation labels tensor: (2830,)\n",
      "Shape of test features tensor: (3538, 1764)\n",
      "Shape of test labels tensor: (3538,)\n"
     ]
    }
   ],
   "source": [
    "# Use the split indices to extract the data.\n",
    "test_features_np = features_np[test_idx]\n",
    "test_labels_np = labels_np[test_idx]\n",
    "train_features_np = temp_features_np[train_idx]\n",
    "train_labels_np = temp_labels_np[train_idx]\n",
    "val_features_np = temp_features_np[val_idx]\n",
    "val_labels_np = temp_labels_np[val_idx]\n",
    "\n",
    "print(f\"Shape of training features tensor: {train_features_np.shape}\")\n",
    "print(f\"Shape of training labels tensor: {train_labels_np.shape}\")\n",
    "print(f\"Shape of validation features tensor: {val_features_np.shape}\")\n",
    "print(f\"Shape of validation labels tensor: {val_labels_np.shape}\")\n",
    "print(f\"Shape of test features tensor: {test_features_np.shape}\")\n",
    "print(f\"Shape of test labels tensor: {test_labels_np.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vW4DLdr-FDxJ",
    "outputId": "196d5dd2-224f-420b-d67f-d1230dc7231e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features tensor: torch.Size([11319, 1764])\n",
      "Shape of training labels tensor: torch.Size([11319])\n",
      "Shape of validation features tensor: torch.Size([2830, 1764])\n",
      "Shape of validation labels tensor: torch.Size([2830])\n",
      "Shape of test features tensor: torch.Size([3538, 1764])\n",
      "Shape of test labels tensor: torch.Size([3538])\n"
     ]
    }
   ],
   "source": [
    "# Convert the numpy arrays back to tensors.\n",
    "train_features_tensor = torch.from_numpy(train_features_np)\n",
    "train_labels_tensor = torch.from_numpy(train_labels_np)\n",
    "val_features_tensor = torch.from_numpy(val_features_np)\n",
    "val_labels_tensor = torch.from_numpy(val_labels_np)\n",
    "test_features_tensor = torch.from_numpy(test_features_np)\n",
    "test_labels_tensor = torch.from_numpy(test_labels_np)\n",
    "\n",
    "print(f\"Shape of training features tensor: {train_features_tensor.shape}\")\n",
    "print(f\"Shape of training labels tensor: {train_labels_tensor.shape}\")\n",
    "print(f\"Shape of validation features tensor: {val_features_tensor.shape}\")\n",
    "print(f\"Shape of validation labels tensor: {val_labels_tensor.shape}\")\n",
    "print(f\"Shape of test features tensor: {test_features_tensor.shape}\")\n",
    "print(f\"Shape of test labels tensor: {test_labels_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OK9D2yYFNuX"
   },
   "outputs": [],
   "source": [
    "# Create the datasets using the data tensors.\n",
    "# This combines the labels and feature tensors.\n",
    "# These can be used to create the dataloaders later.\n",
    "train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_features_tensor, val_labels_tensor)\n",
    "test_dataset = TensorDataset(test_features_tensor, test_labels_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoncLHfGIId8"
   },
   "source": [
    "2. CNN Model Implementation - HOG Features of Spectograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRkgbvJlIRjd"
   },
   "outputs": [],
   "source": [
    "# Define the CNN Model.\n",
    "class HOGFeatureCNN(nn.Module):\n",
    "    def __init__(self, num_classes=num_classes):\n",
    "        super(HOGFeatureCNN, self).__init__()\n",
    "\n",
    "        self.name = \"HOGFeatureCNN\"\n",
    "\n",
    "        # Reshape HOG features to 2D.\n",
    "        # The CNN expects input as [batch_size, channels, height, width]\n",
    "        self.reshape_size = (42, 42)  # 42*42 = 1764\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) # 1x42x42 -> 32x42x42\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 32x21x21 -> 64x21x21\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 64x10x10 -> 128x10x10\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Calculate size after convolutions and pooling\n",
    "        # After 3 pooling operations of 2x2, dimensions are reduced by factor of 8\n",
    "        fc_input_size = 128 * (self.reshape_size[0] // 8) * (self.reshape_size[1] // 8)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(fc_input_size, 512)\n",
    "        self.dropout = nn.Dropout(0.5) # for regularisation.\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape HOG features to 2D + add channel dimension\n",
    "        x = x.view(-1, 1, self.reshape_size[0], self.reshape_size[1])\n",
    "\n",
    "        # Convolutional blocks\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icXpasdQR2Tw"
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdD7AzssS_Je"
   },
   "outputs": [],
   "source": [
    "# Helper function to create a name for each model on the basis of its hyperparameters.\n",
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "3W3gfjyHOY-y"
   },
   "outputs": [],
   "source": [
    "# Function to train the model. Largely based on Archit's Lab 3 Submission.\n",
    "def train_net(model, batch_size, train_loader, val_loader, learning_rate=0.001, num_epochs=20):\n",
    "    # Fixed PyTorch random seed for reproducible results\n",
    "    torch.manual_seed(1000)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Optional: Add scheduler later - it controls the learning rate.\n",
    "    print(\"Loss Function and Optimizer set up.\")\n",
    "\n",
    "    # Arrays to store accuracy metrics\n",
    "    train_acc = np.zeros(num_epochs)\n",
    "    val_acc = np.zeros(num_epochs)\n",
    "\n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    print(\"Training Started.\")\n",
    "\n",
    "    # Iterate for number of epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "\n",
    "        # Process training batches\n",
    "        for _, data in enumerate(train_loader, 0):\n",
    "            recordings, labels = data\n",
    "\n",
    "            # Move data to GPU if available\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                recordings = recordings.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward and backward passes\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(recordings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Finished with adjusting parameters\")\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        correct_t, total_t = 0, 0\n",
    "        correct_v, total_v = 0, 0\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        with torch.no_grad():\n",
    "            for recordings, labels in train_loader:\n",
    "                if use_cuda and torch.cuda.is_available():\n",
    "                    recordings = recordings.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                output = model(recordings)\n",
    "                pred = output.max(1, keepdim=True)[1]\n",
    "                correct_t += pred.eq(labels.view_as(pred)).sum().item()\n",
    "                total_t += recordings.shape[0]\n",
    "\n",
    "        train_acc[epoch] = correct_t / total_t\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        with torch.no_grad():\n",
    "            for recordings, labels in val_loader:\n",
    "                if use_cuda and torch.cuda.is_available():\n",
    "                    recordings = recordings.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                output = model(recordings)\n",
    "                pred = output.max(1, keepdim=True)[1]\n",
    "                correct_v += pred.eq(labels.view_as(pred)).sum().item()\n",
    "                total_v += recordings.shape[0]\n",
    "\n",
    "        val_acc[epoch] = correct_v / total_v\n",
    "\n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch + 1}: Train acc: {train_acc[epoch]:.4f}, Validation acc: {val_acc[epoch]:.4f}\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print('Finished Training')\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    np.savetxt(f\"{model_path}_train_acc.csv\", train_acc)\n",
    "    np.savetxt(f\"{model_path}_val_acc.csv\", val_acc)\n",
    "\n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TM1nIiL4Tkmk"
   },
   "outputs": [],
   "source": [
    "# Create the data loaders.\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_K4HPu1oTl1k",
    "outputId": "c6ed5237-6699-4947-d1a3-045d55e0ed2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function and Optimizer set up.\n",
      "Training Started.\n",
      "Finished with adjusting parameters\n",
      "Epoch 1: Train acc: 0.0390, Validation acc: 0.0392\n",
      "Finished with adjusting parameters\n",
      "Epoch 2: Train acc: 0.0392, Validation acc: 0.0392\n",
      "Finished with adjusting parameters\n",
      "Epoch 3: Train acc: 0.0180, Validation acc: 0.0184\n",
      "Finished with adjusting parameters\n",
      "Epoch 4: Train acc: 0.0454, Validation acc: 0.0477\n",
      "Finished with adjusting parameters\n",
      "Epoch 5: Train acc: 0.0531, Validation acc: 0.0534\n",
      "Finished with adjusting parameters\n",
      "Epoch 6: Train acc: 0.0574, Validation acc: 0.0548\n",
      "Finished with adjusting parameters\n",
      "Epoch 7: Train acc: 0.0590, Validation acc: 0.0601\n",
      "Finished with adjusting parameters\n",
      "Epoch 8: Train acc: 0.0612, Validation acc: 0.0597\n",
      "Finished with adjusting parameters\n",
      "Epoch 9: Train acc: 0.0615, Validation acc: 0.0611\n",
      "Finished with adjusting parameters\n",
      "Epoch 10: Train acc: 0.0610, Validation acc: 0.0601\n",
      "Finished with adjusting parameters\n",
      "Epoch 11: Train acc: 0.0633, Validation acc: 0.0629\n",
      "Finished with adjusting parameters\n",
      "Epoch 12: Train acc: 0.0636, Validation acc: 0.0647\n",
      "Finished with adjusting parameters\n",
      "Epoch 13: Train acc: 0.0648, Validation acc: 0.0643\n",
      "Finished with adjusting parameters\n",
      "Epoch 14: Train acc: 0.0642, Validation acc: 0.0633\n",
      "Finished with adjusting parameters\n",
      "Epoch 15: Train acc: 0.0656, Validation acc: 0.0675\n",
      "Finished with adjusting parameters\n",
      "Epoch 16: Train acc: 0.0648, Validation acc: 0.0675\n",
      "Finished with adjusting parameters\n",
      "Epoch 17: Train acc: 0.0701, Validation acc: 0.0724\n",
      "Finished with adjusting parameters\n",
      "Epoch 18: Train acc: 0.0779, Validation acc: 0.0788\n",
      "Finished with adjusting parameters\n",
      "Epoch 19: Train acc: 0.0638, Validation acc: 0.0629\n",
      "Finished with adjusting parameters\n",
      "Epoch 20: Train acc: 0.0759, Validation acc: 0.0746\n",
      "Finished with adjusting parameters\n",
      "Epoch 21: Train acc: 0.0695, Validation acc: 0.0710\n",
      "Finished with adjusting parameters\n",
      "Epoch 22: Train acc: 0.0681, Validation acc: 0.0678\n",
      "Finished with adjusting parameters\n",
      "Epoch 23: Train acc: 0.0765, Validation acc: 0.0802\n",
      "Finished with adjusting parameters\n",
      "Epoch 24: Train acc: 0.0761, Validation acc: 0.0792\n",
      "Finished with adjusting parameters\n",
      "Epoch 25: Train acc: 0.0765, Validation acc: 0.0781\n",
      "Finished with adjusting parameters\n",
      "Epoch 26: Train acc: 0.0796, Validation acc: 0.0784\n",
      "Finished with adjusting parameters\n",
      "Epoch 27: Train acc: 0.0769, Validation acc: 0.0770\n",
      "Finished with adjusting parameters\n",
      "Epoch 28: Train acc: 0.0794, Validation acc: 0.0792\n",
      "Finished with adjusting parameters\n",
      "Epoch 29: Train acc: 0.0709, Validation acc: 0.0689\n",
      "Finished with adjusting parameters\n",
      "Epoch 30: Train acc: 0.0785, Validation acc: 0.0784\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Batch Size = 256, Learning Rate = 0.005, num_epochs = 30\n",
    "# Create an instance of the model.\n",
    "model = HOGFeatureCNN()\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    \"Using Cuda\"\n",
    "    model.cuda()\n",
    "\n",
    "# Train the model\n",
    "train_acc, val_acc= train_net(model, batch_size, train_loader, val_loader,\n",
    "                                   learning_rate = 0.005, num_epochs = 30)\n",
    "n = len(train_acc)\n",
    "plt.title(\"Training Curve\")\n",
    "plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
    "plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIMLNWvRMbAB"
   },
   "source": [
    "3. Data Preprocessing - Color Spectograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t17VF9hnMfu5",
    "outputId": "36bf93ce-b266-42fc-ddc6-b781e95f43c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\"\"\" EXECUTE FOR GOOGLE COLAB ONLY \"\"\"\n",
    "# Mount the drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOpfKs6JNYa5"
   },
   "outputs": [],
   "source": [
    "\"\"\" EXECUTE FOR GOOGLE COLAB ONLY \"\"\"\n",
    "# Now we move on to loading the .pt files defined for each class.\n",
    "# Define the directory of spectograms.\n",
    "spec_dir = '/content/drive/MyDrive/APS360_Team_15/Data/Xeno_Canto_Spectrograms'\n",
    "# Define a list to store the spectograms and associated labels.\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterare through each bird.\n",
    "for file in os.listdir(spec_dir):\n",
    "  # load the pt file.\n",
    "  pt_file = glob.glob(os.path.join(spec_dir, file))\n",
    "  # Error check\n",
    "  if(pt_file == []):\n",
    "    continue\n",
    "  # Extract features and create labels in tensors.\n",
    "  features_tensor = torch.load(pt_file[0])\n",
    "  label_value = int(os.path.splitext(file)[0])\n",
    "  labels_tensor = torch.full((features_tensor.shape[0],), label_value, dtype=torch.long)\n",
    "  # Add these tensors to their respective lists.\n",
    "  all_features.append(features_tensor)\n",
    "  all_labels.append(labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/7wj664s92gx_89p1xhcwbq800000gn/T/ipykernel_2193/679661104.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features_tensor = torch.load(pt_file[0])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" EXECUTE FOR LOCAL SETUP ONLY \"\"\"\n",
    "# Now we move on to loading the .pt files defined for each class.\n",
    "# Define the directory of spectograms.\n",
    "spec_dir = '../../Data/Xeno_Canto_Spectrograms'\n",
    "# Define a list to store the spectograms and associated labels.\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterare through each bird.\n",
    "for file in os.listdir(spec_dir):\n",
    "  # Check if the file is a .pt file.\n",
    "  if(file.endswith('.pt') == False):\n",
    "    continue\n",
    "  # load the pt file.\n",
    "  pt_file = glob.glob(os.path.join(spec_dir, file))\n",
    "  # Error check\n",
    "  if(pt_file == []):\n",
    "    continue\n",
    "\n",
    "  # Extract features and create labels in tensors.\n",
    "  features_tensor = torch.load(pt_file[0])\n",
    "  label_value = int(os.path.splitext(file)[0])\n",
    "  labels_tensor = torch.full((features_tensor.shape[0],), label_value, dtype=torch.long)\n",
    "\n",
    "  # Truncate to first 100 elements to uniformize the dataset.\n",
    "  if features_tensor.shape[0] > 100:\n",
    "    features_tensor = features_tensor[:100]\n",
    "    labels_tensor = labels_tensor[:100]\n",
    "    \n",
    "  # Add these tensors to their respective lists.\n",
    "  all_features.append(features_tensor)\n",
    "  all_labels.append(labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dn4nPgzbc8pM",
    "outputId": "ff242b87-521f-4e18-843a-fe50358ad39b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes for which data has been extracted: 105\n"
     ]
    }
   ],
   "source": [
    "# Print the number of classes for which data has been extracted.\n",
    "num_classes = len(all_labels)\n",
    "print(f\"Number of classes for which data has been extracted: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[315,\n",
       " 317,\n",
       " 333,\n",
       " 338,\n",
       " 352,\n",
       " 366,\n",
       " 375,\n",
       " 382,\n",
       " 400,\n",
       " 450,\n",
       " 458,\n",
       " 470,\n",
       " 481,\n",
       " 484,\n",
       " 491,\n",
       " 501,\n",
       " 510,\n",
       " 512,\n",
       " 513,\n",
       " 527,\n",
       " 536,\n",
       " 539,\n",
       " 543,\n",
       " 553,\n",
       " 559,\n",
       " 560,\n",
       " 669,\n",
       " 746,\n",
       " 749,\n",
       " 753,\n",
       " 756,\n",
       " 760,\n",
       " 764,\n",
       " 766,\n",
       " 769,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 783,\n",
       " 786,\n",
       " 790,\n",
       " 793,\n",
       " 794,\n",
       " 802,\n",
       " 803,\n",
       " 810,\n",
       " 811,\n",
       " 813,\n",
       " 819,\n",
       " 822,\n",
       " 824,\n",
       " 827,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 840,\n",
       " 847,\n",
       " 848,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 856,\n",
       " 860,\n",
       " 862,\n",
       " 864,\n",
       " 867,\n",
       " 868,\n",
       " 871,\n",
       " 873,\n",
       " 875,\n",
       " 877,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 888,\n",
       " 889,\n",
       " 897,\n",
       " 898,\n",
       " 900,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 908,\n",
       " 910,\n",
       " 912,\n",
       " 914,\n",
       " 922,\n",
       " 923,\n",
       " 926,\n",
       " 937,\n",
       " 944,\n",
       " 946,\n",
       " 947,\n",
       " 949,\n",
       " 950,\n",
       " 957,\n",
       " 958,\n",
       " 964,\n",
       " 965,\n",
       " 979,\n",
       " 987]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of class IDs.\n",
    "class_ids = [tensor[0].item() for tensor in all_labels]\n",
    "class_ids = sorted(set(class_ids))\n",
    "class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5DlEHFE6qR9",
    "outputId": "74cb5374-cd0e-4b2b-bfd8-6109e81867e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wnwiVYzdxp-",
    "outputId": "66ec98e3-e219-4958-b06d-f92fcfd2281f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features tensor: torch.Size([19176, 128, 128, 3])\n",
      "Shape of labels tensor: torch.Size([19176])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all the tensors into one tensor.\n",
    "features_tensor = torch.cat(all_features, dim=0)\n",
    "labels_tensor = torch.cat(all_labels, dim=0)\n",
    "\n",
    "# Encode the labels to make them suitable for training the model.\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels_tensor)\n",
    "# Create mapping dictionaries for the encoding.\n",
    "id_to_index = dict(zip(labels_tensor, encoded_labels))\n",
    "index_to_id = dict(zip(encoded_labels, labels_tensor))\n",
    "# Pickle dump these mappings for use later.\n",
    "with open('label_mappings.pkl', 'wb') as f:\n",
    "    pickle.dump({'id_to_index': id_to_index, 'index_to_id': index_to_id}, f)\n",
    "\n",
    "# Replace the labels tensor.\n",
    "labels_tensor = torch.from_numpy(encoded_labels)\n",
    "\n",
    "# Print out stats.\n",
    "print(f\"Shape of features tensor: {features_tensor.shape}\")\n",
    "print(f\"Shape of labels tensor: {labels_tensor.shape}\")\n",
    "\n",
    "# Convert the tensors into numpy for sci-kit learn functions.\n",
    "features_np = features_tensor.numpy()\n",
    "labels_np = labels_tensor.numpy()\n",
    "\n",
    "# First split: (training + validation) vs test - 80:20\n",
    "# We use a stratified split for uniform distributions of the classes.\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "temp_idx, test_idx = next(sss1.split(features_np, labels_np))\n",
    "\n",
    "# Get the temporary set.\n",
    "temp_features_np = features_np[temp_idx]\n",
    "temp_labels_np = labels_np[temp_idx]\n",
    "\n",
    "# Second split: training vs validation - 80:20\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "train_idx, val_idx = next(sss2.split(temp_features_np, temp_labels_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BReo00xlxLn",
    "outputId": "13c99074-fbc8-4e68-cd98-c51a2a3403a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features tensor: (12272, 128, 128, 3)\n",
      "Shape of training labels tensor: (12272,)\n",
      "Shape of validation features tensor: (3068, 128, 128, 3)\n",
      "Shape of validation labels tensor: (3068,)\n",
      "Shape of test features tensor: (3836, 128, 128, 3)\n",
      "Shape of test labels tensor: (3836,)\n"
     ]
    }
   ],
   "source": [
    "# Use the split indices to extract the data.\n",
    "test_features_np = features_np[test_idx]\n",
    "test_labels_np = labels_np[test_idx]\n",
    "train_features_np = temp_features_np[train_idx]\n",
    "train_labels_np = temp_labels_np[train_idx]\n",
    "val_features_np = temp_features_np[val_idx]\n",
    "val_labels_np = temp_labels_np[val_idx]\n",
    "\n",
    "print(f\"Shape of training features tensor: {train_features_np.shape}\")\n",
    "print(f\"Shape of training labels tensor: {train_labels_np.shape}\")\n",
    "print(f\"Shape of validation features tensor: {val_features_np.shape}\")\n",
    "print(f\"Shape of validation labels tensor: {val_labels_np.shape}\")\n",
    "print(f\"Shape of test features tensor: {test_features_np.shape}\")\n",
    "print(f\"Shape of test labels tensor: {test_labels_np.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ft9djYEol3Gu",
    "outputId": "bdfa5a04-8377-4a17-8277-d5904b6f472f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features tensor: torch.Size([12272, 128, 128, 3])\n",
      "Shape of training labels tensor: torch.Size([12272])\n",
      "Shape of validation features tensor: torch.Size([3068, 128, 128, 3])\n",
      "Shape of validation labels tensor: torch.Size([3068])\n",
      "Shape of test features tensor: torch.Size([3836, 128, 128, 3])\n",
      "Shape of test labels tensor: torch.Size([3836])\n"
     ]
    }
   ],
   "source": [
    "# Convert the numpy arrays back to tensors.\n",
    "train_features_tensor = torch.from_numpy(train_features_np)\n",
    "train_labels_tensor = torch.from_numpy(train_labels_np)\n",
    "val_features_tensor = torch.from_numpy(val_features_np)\n",
    "val_labels_tensor = torch.from_numpy(val_labels_np)\n",
    "test_features_tensor = torch.from_numpy(test_features_np)\n",
    "test_labels_tensor = torch.from_numpy(test_labels_np)\n",
    "\n",
    "print(f\"Shape of training features tensor: {train_features_tensor.shape}\")\n",
    "print(f\"Shape of training labels tensor: {train_labels_tensor.shape}\")\n",
    "print(f\"Shape of validation features tensor: {val_features_tensor.shape}\")\n",
    "print(f\"Shape of validation labels tensor: {val_labels_tensor.shape}\")\n",
    "print(f\"Shape of test features tensor: {test_features_tensor.shape}\")\n",
    "print(f\"Shape of test labels tensor: {test_labels_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "BqP37PcAmCUS"
   },
   "outputs": [],
   "source": [
    "# Create the datasets using the data tensors.\n",
    "# This combines the labels and feature tensors.\n",
    "# These can be used to create the dataloaders later.\n",
    "train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_features_tensor, val_labels_tensor)\n",
    "test_dataset = TensorDataset(test_features_tensor, test_labels_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOzB6BwamJv7"
   },
   "source": [
    "4. CNN Model Implementation - Color Spectrograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "AukrRRDQmPYd"
   },
   "outputs": [],
   "source": [
    "# Define the CNN Model - CNN1\n",
    "class SpecCNN(nn.Module):\n",
    "    def __init__(self, num_classes=num_classes):\n",
    "        super(SpecCNN, self).__init__()\n",
    "        self.name = \"SpecCNN1\"\n",
    "\n",
    "        # Input shape is [batch_size, 3, 128, 128] - note the channel dimension is 3, not 1\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # 3x128x128 -> 32x128x128\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 32x64x64 -> 64x64x64\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 64x32x32 -> 128x32x32\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Calculate size after convolutions and pooling\n",
    "        # After 3 pooling operations of 2x2, dimensions are reduced by factor of 8\n",
    "        # 128/8 = 16, so final feature map size is 128 x 16 x 16\n",
    "        fc_input_size = 128 * 16 * 16\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(fc_input_size, 512)\n",
    "        self.dropout = nn.Dropout(0.5)  # for regularization\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x is already shape [batch_size, 128, 128, 3]\n",
    "        # PyTorch expects [batch_size, channels, height, width], so permute the dimensions\n",
    "        x = x.permute(0, 3, 1, 2)  # Change from [B, H, W, C] to [B, C, H, W]\n",
    "\n",
    "        # Convolutional blocks\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # -> [B, 32, 64, 64]\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # -> [B, 64, 32, 32]\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # -> [B, 128, 16, 16]\n",
    "\n",
    "        # Flatten for fully connected layers\n",
    "        x = x.reshape(x.size(0), -1)  # -> [B, 128*16*16]\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "FbLElYJl_NDF"
   },
   "outputs": [],
   "source": [
    "# Helper function to create a name for each model on the basis of its hyperparameters.\n",
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "PtZusJiMnsHZ"
   },
   "outputs": [],
   "source": [
    "# Function to train the model. Largely based on Archit's Lab 3 Submission.\n",
    "def train_net(model, batch_size, train_loader, val_loader, learning_rate=0.001, num_epochs=20):\n",
    "    # Fixed PyTorch random seed for reproducible results\n",
    "    torch.manual_seed(1000)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Optional: Add scheduler later - it controls the learning rate.\n",
    "    print(\"Loss Function and Optimizer set up.\")\n",
    "\n",
    "    # Arrays to store accuracy metrics\n",
    "    train_acc = np.zeros(num_epochs)\n",
    "    val_acc = np.zeros(num_epochs)\n",
    "\n",
    "    # Create an output folder for performance files\n",
    "    output_folder = \"Audio_Model_Performance\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Training Started.\")\n",
    "\n",
    "    # Iterate for number of epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        # running_loss = 0.0\n",
    "        # batches = 0\n",
    "        \n",
    "        for _, data in enumerate(train_loader, 0):\n",
    "            recordings, labels = data\n",
    "\n",
    "            # Move data to GPU if available\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                recordings = recordings.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(recordings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # running_loss += loss.item()\n",
    "            # batches += 1\n",
    "\n",
    "        # epoch_loss = running_loss / batches\n",
    "        \n",
    "        print(f\"Finished adjusting parameters for epoch {epoch + 1}\")\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        correct_t, total_t = 0, 0\n",
    "        correct_v, total_v = 0, 0\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        with torch.no_grad():\n",
    "            for recordings, labels in train_loader:\n",
    "                if use_cuda and torch.cuda.is_available():\n",
    "                    recordings = recordings.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                output = model(recordings)\n",
    "                pred = output.max(1, keepdim=True)[1]\n",
    "                correct_t += pred.eq(labels.view_as(pred)).sum().item()\n",
    "                total_t += recordings.shape[0]\n",
    "\n",
    "        train_acc[epoch] = correct_t / total_t\n",
    "\n",
    "        # Calculate validation accuracy and collect predictions\n",
    "        with torch.no_grad():\n",
    "            for recordings, labels in val_loader:\n",
    "                if use_cuda and torch.cuda.is_available():\n",
    "                    recordings = recordings.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                output = model(recordings)\n",
    "                pred = output.max(1, keepdim=True)[1]\n",
    "                correct_v += pred.eq(labels.view_as(pred)).sum().item()\n",
    "                total_v += recordings.shape[0]\n",
    "                \n",
    "        val_acc[epoch] = correct_v / total_v\n",
    "\n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch + 1}: Train acc: {train_acc[epoch]:.4f}, Validation acc: {val_acc[epoch]:.4f}\")\n",
    "\n",
    "    print('Finished Training')\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    model_filename = get_model_name(model.name, batch_size, learning_rate, num_epochs - 1)\n",
    "    model_path = os.path.join(output_folder, model_filename)\n",
    "    \n",
    "    # Save accuracy metrics to CSV\n",
    "    train_acc_path = f\"{model_path}_train_acc.csv\"\n",
    "    val_acc_path = f\"{model_path}_val_acc.csv\"\n",
    "    np.savetxt(train_acc_path, train_acc)\n",
    "    np.savetxt(val_acc_path, val_acc)\n",
    "    \n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "r6BVuP1KoD70"
   },
   "outputs": [],
   "source": [
    "# Create the data loaders.\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "_s79ydDUor-s"
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hi6RQvGooU5N",
    "outputId": "443c53f0-92fb-4803-c506-4808b4cf998f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function and Optimizer set up.\n",
      "Training Started.\n",
      "Finished adjusting parameters for epoch 1\n",
      "Epoch 1: Train acc: 0.0262, Validation acc: 0.0261\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m train_acc, val_acc\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_acc)\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Curve\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[54], line 41\u001b[0m, in \u001b[0;36mtrain_net\u001b[0;34m(model, batch_size, train_loader, val_loader, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(recordings)\n\u001b[1;32m     40\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# running_loss += loss.item()\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# batches += 1\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# epoch_loss = running_loss / batches\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ECE421/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ECE421/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ECE421/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Batch Size = 32, lr = 0.001, num_epochs = 100\n",
    "# Create an instance of the model.\n",
    "model = SpecCNN()\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    \"Using Cuda\"\n",
    "    model.cuda()\n",
    "\n",
    "# Train the model\n",
    "train_acc, val_acc= train_net(model, batch_size, train_loader, val_loader,\n",
    "                                   learning_rate = 0.005, num_epochs = 50)\n",
    "n = len(train_acc)\n",
    "plt.title(\"Training Curve\")\n",
    "plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
    "plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ECE421",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
