{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import TensorDataset, Subset, Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading Individual Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to use a dataset to create a balanced dataset that makes\n",
    "# sure each class has the same number of samples.\n",
    "def create_balanced_dataset(test_dataset, target_samples_per_class=500):\n",
    "    # Gather labels from the test dataset.\n",
    "    test_labels = []\n",
    "    for i in range(len(test_dataset)):\n",
    "        _, label = test_dataset[i]  \n",
    "        # Extract the label from the dataset item.\n",
    "        test_labels.append(label.item())\n",
    "\n",
    "    # Count samples per class in the test dataset\n",
    "    class_counts = Counter(test_labels)\n",
    "    print(f\"Original class distribution: {dict(class_counts)}\")\n",
    "\n",
    "    # Identify classes that need oversampling\n",
    "    classes_to_oversample = {\n",
    "        cls: (target_samples_per_class - count)\n",
    "        for cls, count in class_counts.items()\n",
    "        if count < target_samples_per_class\n",
    "    }\n",
    "\n",
    "    # If no class is under the target, simply return the original dataset\n",
    "    if not classes_to_oversample:\n",
    "        print(\"No oversampling needed - all classes have enough samples.\")\n",
    "        return test_dataset\n",
    "\n",
    "    # Map each class to the list of indices that contain that class\n",
    "    class_indices_map = {cls: [] for cls in class_counts.keys()}\n",
    "    for i, lbl in enumerate(test_labels):\n",
    "        class_indices_map[lbl].append(i)\n",
    "\n",
    "    # Generate the new indices by oversampling\n",
    "    additional_indices = []\n",
    "    for cls, num_needed in classes_to_oversample.items():\n",
    "        # Randomly sample (with replacement) from the available indices of this class\n",
    "        oversampled = np.random.choice(class_indices_map[cls], size=num_needed, replace=True)\n",
    "        additional_indices.extend(oversampled)\n",
    "\n",
    "    # Combine original indices with the newly oversampled ones\n",
    "    all_indices = list(range(len(test_dataset))) + additional_indices\n",
    "\n",
    "    # Create a new Subset using these indices\n",
    "    balanced_dataset = Subset(test_dataset, all_indices)\n",
    "\n",
    "    # Optional: verify the new distribution\n",
    "    balanced_labels = []\n",
    "    for idx in all_indices:\n",
    "        _, label = test_dataset[idx]\n",
    "        balanced_labels.append(int(label))\n",
    "    balanced_counts = Counter(balanced_labels)\n",
    "    print(f\"Balanced class distribution: {dict(balanced_counts)}\")\n",
    "\n",
    "    return balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/7wj664s92gx_89p1xhcwbq800000gn/T/ipykernel_1239/2291915788.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  audio_dataset = torch.load(\"../../Data/audio_test_dataset.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: {5: 70, 35: 37, 20: 83, 11: 42, 29: 100, 28: 56, 6: 67, 10: 58, 19: 100, 44: 31, 12: 68, 34: 92, 21: 58, 37: 100, 8: 34, 31: 40, 40: 35, 25: 42, 22: 62, 42: 42, 0: 33, 30: 100, 14: 52, 23: 100, 27: 31, 7: 100, 18: 100, 45: 66, 41: 30, 9: 37, 2: 57, 13: 60, 3: 67, 43: 45, 15: 37, 26: 36, 4: 73, 32: 57, 33: 34, 38: 42, 46: 67, 24: 41, 1: 48, 39: 32, 17: 39, 36: 39, 16: 42}\n",
      "Balanced class distribution: {5: 500, 35: 500, 20: 500, 11: 500, 29: 500, 28: 500, 6: 500, 10: 500, 19: 500, 44: 500, 12: 500, 34: 500, 21: 500, 37: 500, 8: 500, 31: 500, 40: 500, 25: 500, 22: 500, 42: 500, 0: 500, 30: 500, 14: 500, 23: 500, 27: 500, 7: 500, 18: 500, 45: 500, 41: 500, 9: 500, 2: 500, 13: 500, 3: 500, 43: 500, 15: 500, 26: 500, 4: 500, 32: 500, 33: 500, 38: 500, 46: 500, 24: 500, 1: 500, 39: 500, 17: 500, 36: 500, 16: 500}\n",
      "Size of the balanced dataset: 23500\n"
     ]
    }
   ],
   "source": [
    "# Load the audio test dataset from the .pt file.\n",
    "audio_dataset = torch.load(\"../../Data/audio_test_dataset.pt\")\n",
    "# Create a balanced dataset with 500 samples per class.\n",
    "balanced_audio_dataset = create_balanced_dataset(audio_dataset, target_samples_per_class=500)\n",
    "# Print out the size of the dataset.\n",
    "print(f\"Size of the balanced dataset: {len(balanced_audio_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/7wj664s92gx_89p1xhcwbq800000gn/T/ipykernel_1239/3935245663.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  images_dataset = torch.load(\"../../Data/resnet_test_dataset.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: {28: 24, 20: 21, 17: 24, 34: 24, 18: 24, 37: 24, 39: 24, 0: 23, 9: 24, 33: 23, 46: 24, 13: 24, 4: 24, 5: 20, 14: 24, 11: 24, 23: 23, 21: 24, 19: 23, 2: 24, 36: 24, 26: 24, 27: 24, 12: 22, 15: 24, 45: 24, 44: 24, 32: 22, 41: 24, 35: 22, 42: 24, 43: 23, 16: 22, 30: 22, 31: 24, 22: 24, 3: 23, 38: 24, 24: 24, 8: 21, 25: 21, 7: 22, 1: 24, 10: 24, 6: 23, 29: 24, 40: 22}\n",
      "Balanced class distribution: {28: 500, 20: 500, 17: 500, 34: 500, 18: 500, 37: 500, 39: 500, 0: 500, 9: 500, 33: 500, 46: 500, 13: 500, 4: 500, 5: 500, 14: 500, 11: 500, 23: 500, 21: 500, 19: 500, 2: 500, 36: 500, 26: 500, 27: 500, 12: 500, 15: 500, 45: 500, 44: 500, 32: 500, 41: 500, 35: 500, 42: 500, 43: 500, 16: 500, 30: 500, 31: 500, 22: 500, 3: 500, 38: 500, 24: 500, 8: 500, 25: 500, 7: 500, 1: 500, 10: 500, 6: 500, 29: 500, 40: 500}\n",
      "Size of the balanced dataset: 23500\n"
     ]
    }
   ],
   "source": [
    "# Now load the image test dataset from the .pt file.\n",
    "images_dataset = torch.load(\"../../Data/resnet_test_dataset.pt\")\n",
    "# Create a balanced dataset with 500 samples per class.\n",
    "balanced_images_dataset = create_balanced_dataset(images_dataset, target_samples_per_class=500)\n",
    "# Print out the size of the dataset.\n",
    "print(f\"Size of the balanced dataset: {len(balanced_images_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creating Combined Dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images data tensor shape: torch.Size([23500, 1, 512])\n",
      "Images labels tensor shape: torch.Size([23500])\n"
     ]
    }
   ],
   "source": [
    "# Extract the images data and labels from the balanced dataset\n",
    "images_data = []\n",
    "images_labels = []\n",
    "for i in range(len(balanced_images_dataset)):\n",
    "    image, label = balanced_images_dataset[i]\n",
    "    images_data.append(image)\n",
    "    images_labels.append(label)\n",
    "# Convert to tensors\n",
    "images_data_tensor = torch.stack(images_data)\n",
    "images_labels_tensor = torch.tensor(images_labels)\n",
    "print(f\"Images data tensor shape: {images_data_tensor.shape}\")\n",
    "print(f\"Images labels tensor shape: {images_labels_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced audio data tensor shape: torch.Size([23500, 1, 128, 128])\n",
      "Balanced audio labels tensor shape: torch.Size([23500])\n"
     ]
    }
   ],
   "source": [
    "# Extract the audio data from the balanced dataset.\n",
    "audio_data = []\n",
    "audio_labels = []\n",
    "for i in range(len(balanced_audio_dataset)):\n",
    "    audio, label = balanced_audio_dataset[i]\n",
    "    audio_data.append(audio)\n",
    "    audio_labels.append(label)\n",
    "# Convert the data and labels to PyTorch tensors.\n",
    "audio_data_tensor = torch.stack(audio_data)\n",
    "audio_labels_tensor = torch.tensor(audio_labels)\n",
    "print(f\"Balanced audio data tensor shape: {audio_data_tensor.shape}\")\n",
    "print(f\"Balanced audio labels tensor shape: {audio_labels_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a class to create a dataset for the audio and image data.\n",
    "# We want to create random pairs of audio and image data, of the same class.\n",
    "class MultimodalFusionDataset(Dataset):\n",
    "    def __init__(self, image_data, image_labels, audio_data, audio_labels, transform=None, indices=None):\n",
    "        \"\"\"\n",
    "        Custom dataset for multimodal fusion of image and audio data.\n",
    "        \n",
    "        Args:\n",
    "            image_data: PyTorch tensor containing image data\n",
    "            image_labels: PyTorch tensor containing image labels\n",
    "            audio_data: PyTorch tensor containing audio data\n",
    "            audio_labels: PyTorch tensor containing audio labels\n",
    "            transform: Optional transform to be applied to the samples\n",
    "            indices: Optional indices to select a subset of the data\n",
    "        \"\"\"\n",
    "        self.image_data = image_data\n",
    "        self.image_labels = image_labels\n",
    "        self.audio_data = audio_data\n",
    "        self.audio_labels = audio_labels\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Convert tensors to numpy for processing\n",
    "        image_labels_np = image_labels.numpy()\n",
    "        audio_labels_np = audio_labels.numpy()\n",
    "        \n",
    "        # Create a list of all possible class indices - ensure they're the same for both modalities\n",
    "        image_classes = set(np.unique(image_labels_np))\n",
    "        audio_classes = set(np.unique(audio_labels_np))\n",
    "        common_classes = sorted(list(image_classes.intersection(audio_classes)))\n",
    "        \n",
    "        if len(common_classes) == 0:\n",
    "            raise ValueError(\"No common classes found between image and audio datasets\")\n",
    "        \n",
    "        # Organize samples by class\n",
    "        self.class_indices = {}\n",
    "        self.pairs = []\n",
    "        self.pair_labels = []\n",
    "        \n",
    "        for cls in common_classes:\n",
    "            img_indices = np.where(image_labels_np == cls)[0]\n",
    "            audio_indices = np.where(audio_labels_np == cls)[0]\n",
    "            \n",
    "            if len(img_indices) > 0 and len(audio_indices) > 0:\n",
    "                self.class_indices[cls] = {\n",
    "                    'image': img_indices,\n",
    "                    'audio': audio_indices\n",
    "                }\n",
    "                \n",
    "                # Shuffle the indices for random pairing\n",
    "                np.random.seed(42)  # For reproducibility\n",
    "                np.random.shuffle(img_indices)\n",
    "                np.random.shuffle(audio_indices)\n",
    "                \n",
    "                # Create pairs (one image with one audio) from the same class\n",
    "                n_pairs = min(len(img_indices), len(audio_indices))\n",
    "                for i in range(n_pairs):\n",
    "                    self.pairs.append((img_indices[i], audio_indices[i]))\n",
    "                    self.pair_labels.append(cls)\n",
    "        \n",
    "        # Check if we have any pairs\n",
    "        if len(self.pairs) == 0:\n",
    "            raise ValueError(\"No valid pairs could be created. Check your data and labels.\")\n",
    "        \n",
    "        # Convert to numpy arrays for easier indexing\n",
    "        self.pairs = np.array(self.pairs)\n",
    "        self.pair_labels = np.array(self.pair_labels)\n",
    "        \n",
    "        # If specific indices are provided, only use those\n",
    "        if indices is not None:\n",
    "            if len(indices) > 0:  # Make sure indices is not empty\n",
    "                self.pairs = self.pairs[indices]\n",
    "                self.pair_labels = self.pair_labels[indices]\n",
    "            else:\n",
    "                raise ValueError(\"Empty indices provided\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_idx, audio_idx = self.pairs[idx]\n",
    "        \n",
    "        image = self.image_data[img_idx]\n",
    "        audio = self.audio_data[audio_idx]\n",
    "        label = torch.tensor(self.pair_labels[idx], dtype=torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return {\n",
    "            'image': image,\n",
    "            'audio': audio,\n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "\n",
    "# Create stratified data loaders for training, validation, and testing\n",
    "# These will be created using the dataset framework we defined above,\n",
    "# and using the balanced datasets we created earlier.\n",
    "def create_stratified_data_loaders(image_data, image_labels, audio_data, audio_labels, batch_size=32):\n",
    "    \"\"\"\n",
    "    Create train, validation, and test data loaders with stratified splits.\n",
    "    \n",
    "    Args:\n",
    "        image_data: PyTorch tensor containing image data\n",
    "        image_labels: PyTorch tensor containing image labels\n",
    "        audio_data: PyTorch tensor containing audio data\n",
    "        audio_labels: PyTorch tensor containing audio labels\n",
    "        batch_size: Batch size for the data loaders\n",
    "        num_workers: Number of worker threads for the data loaders\n",
    "        \n",
    "    Returns:\n",
    "        train_loader, val_loader, test_loader\n",
    "    \"\"\"\n",
    "    # First, create the full dataset\n",
    "    try:\n",
    "        full_dataset = MultimodalFusionDataset(\n",
    "            image_data=image_data,\n",
    "            image_labels=image_labels,\n",
    "            audio_data=audio_data,\n",
    "            audio_labels=audio_labels\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"Error creating dataset: {e}\")\n",
    "        print(f\"Image labels shape: {image_labels.shape}, unique: {torch.unique(image_labels).shape}\")\n",
    "        print(f\"Audio labels shape: {audio_labels.shape}, unique: {torch.unique(audio_labels).shape}\")\n",
    "        raise\n",
    "    \n",
    "    # Get all pair labels\n",
    "    pair_labels = full_dataset.pair_labels\n",
    "    \n",
    "    # Create indices array\n",
    "    indices = np.arange(len(pair_labels))\n",
    "    \n",
    "    # First split: train+val vs test (80:20)\n",
    "    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    temp_idx, test_idx = next(sss1.split(indices, pair_labels))\n",
    "    \n",
    "    # Get the temporary set labels\n",
    "    temp_labels = pair_labels[temp_idx]\n",
    "    \n",
    "    # Second split: train vs val (80:20)\n",
    "    temp_indices = np.arange(len(temp_idx))\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    train_temp_idx, val_temp_idx = next(sss2.split(temp_indices, temp_labels))\n",
    "    \n",
    "    # Convert to original indices\n",
    "    train_idx = temp_idx[train_temp_idx]\n",
    "    val_idx = temp_idx[val_temp_idx]\n",
    "    \n",
    "    # Create the individual datasets\n",
    "    train_dataset = MultimodalFusionDataset(\n",
    "        image_data=image_data,\n",
    "        image_labels=image_labels,\n",
    "        audio_data=audio_data,\n",
    "        audio_labels=audio_labels,\n",
    "        indices=train_idx\n",
    "    )\n",
    "    \n",
    "    val_dataset = MultimodalFusionDataset(\n",
    "        image_data=image_data,\n",
    "        image_labels=image_labels,\n",
    "        audio_data=audio_data,\n",
    "        audio_labels=audio_labels,\n",
    "        indices=val_idx\n",
    "    )\n",
    "    \n",
    "    test_dataset = MultimodalFusionDataset(\n",
    "        image_data=image_data,\n",
    "        image_labels=image_labels,\n",
    "        audio_data=audio_data,\n",
    "        audio_labels=audio_labels,\n",
    "        indices=test_idx\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    \n",
    "    # Print split information\n",
    "    print(f\"Dataset split: {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} test samples\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: 15040 training, 3760 validation, 4700 test samples\n"
     ]
    }
   ],
   "source": [
    "# Use the extracted tensors to create stratified data loaders\n",
    "batch_size = 32\n",
    "train_loader, val_loader, test_loader = create_stratified_data_loaders(\n",
    "    image_data=images_data_tensor,\n",
    "    image_labels=images_labels_tensor,\n",
    "    audio_data=audio_data_tensor,\n",
    "    audio_labels=audio_labels_tensor,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fusion Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by defining the Fusion ANN Model.\n",
    "class FusionANN(nn.Module):\n",
    "    def __init__(self, image_embed_size, audio_embed_size, hidden_dim, num_classes, dropout_rate=0.5):\n",
    "        super(FusionANN, self).__init__()\n",
    "        \n",
    "        # Dimensionality of inputs\n",
    "        self.image_embed_size = image_embed_size\n",
    "        self.audio_embed_size = audio_embed_size\n",
    "        \n",
    "        # Fusion network\n",
    "        self.fusion_network = nn.Sequential(\n",
    "            nn.Linear(image_embed_size + audio_embed_size, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, image_features, audio_features):\n",
    "        # Concatenate features from both modalities\n",
    "        combined_features = torch.cat((image_features, audio_features), dim=1)\n",
    "        \n",
    "        # Pass through fusion network\n",
    "        output = self.fusion_network(combined_features)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the images model.\n",
    "class ImagesResNetANN(nn.Module):\n",
    "    def __init__(self, num_classes=47, dropout_rate=0.3):\n",
    "        super(ImagesResNetANN, self).__init__()\n",
    "        self.name = \"ImagesResNetANN_1\"\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 1, 512]\n",
    "        # Flatten the feature map to [batch_size, 512]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Audio CNN Model.\n",
    "class SpecCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_rate=0.3):\n",
    "        super(SpecCNN, self).__init__()\n",
    "        self.name = \"Spec_WAV10_CNN_5\"\n",
    "        \n",
    "        # Adding dropout with default rate of 0.3\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Following the architecture from the paper\n",
    "        # Adjusted for input channels = 1 (grayscale)\n",
    "        # Conv Group 1: [1, 128, 128] -> [64, 64, 64]\n",
    "        self.conv_group1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn_group1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Conv Group 2: [64, 64, 64] -> [128, 32, 32]\n",
    "        self.conv_group2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn_group2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Conv Group 3: [128, 32, 32] -> [256, 16, 16]\n",
    "        self.conv_group3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn_group3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # Conv Group 4: [256, 16, 16] -> [512, 8, 8]\n",
    "        self.conv_group4 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn_group4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # Conv Group 5: [512, 8, 8] -> [1024, 4, 4]\n",
    "        self.conv_group5 = nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn_group5 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        # 1x1 Convolution: [1024, 4, 4] -> [2048, 4, 4]\n",
    "        self.conv_1x1 = nn.Conv2d(1024, 2048, kernel_size=1)\n",
    "        self.bn_1x1 = nn.BatchNorm2d(2048)\n",
    "        \n",
    "        # Global Average Pooling: [2048, 4, 4] -> [2048, 1, 1]\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input: [batch_size, 1, 128, 128] (channels, height, width)\n",
    "        # No need to transform dimensions as input is already in correct format\n",
    "        \n",
    "        # Handle different input shapes (just in case)\n",
    "        if x.dim() == 3 and x.shape[0] == 1:  # If x has shape [1, H, W] (single grayscale image)\n",
    "            x = x.unsqueeze(0)  # Add batch dimension: [1, 1, H, W]\n",
    "            \n",
    "        # Apply convolutional layers with dropout\n",
    "        x = F.relu(self.bn_group1(self.conv_group1(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn_group2(self.conv_group2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn_group3(self.conv_group3(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn_group4(self.conv_group4(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn_group5(self.conv_group5(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn_1x1(self.conv_1x1(x)))\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = self.avg_pool(x)\n",
    "        \n",
    "        # Flatten: [batch, 2048, 1, 1] -> [batch, 2048]\n",
    "        x = x.reshape(x.size(0), -1)  # Use reshape instead of view\n",
    "        \n",
    "        # Apply dropout before the final fully connected layer\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load pre-trained models\n",
    "def load_pretrained_models(image_model_path, audio_model_path, device):\n",
    "    # Load image model\n",
    "    image_model = ImagesResNetANN()\n",
    "    image_model.load_state_dict(torch.load(image_model_path))\n",
    "    image_model.to(device)\n",
    "    image_model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    # Load audio model\n",
    "    audio_model = SpecCNN(num_classes = 47)\n",
    "    audio_model.load_state_dict(torch.load(audio_model_path))\n",
    "    audio_model.to(device)\n",
    "    audio_model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    return image_model, audio_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from the pre-trained models\n",
    "def extract_features(image_model, audio_model, dataloader, device):\n",
    "    image_features_list = []\n",
    "    audio_features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            images = batch['image'].to(device)\n",
    "            audio = batch['audio'].to(device)\n",
    "            labels = batch['label']\n",
    "            \n",
    "            # Extract features from the pre-trained models\n",
    "            image_features = image_model(images)\n",
    "            audio_features = audio_model(audio)\n",
    "            \n",
    "            image_features_list.append(image_features)\n",
    "            audio_features_list.append(audio_features)\n",
    "            labels_list.append(labels)\n",
    "    \n",
    "    return image_features_list, audio_features_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fusion_model(fusion_model, train_image_features, train_audio_features, train_labels,\n",
    "                       val_image_features, val_audio_features, val_labels,\n",
    "                       num_epochs, batch_size, learning_rate, device):\n",
    "    # Define loss function, optimizer, and learning rate scheduler.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(fusion_model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "    \n",
    "    # Training history lists.\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Get the number of batches.\n",
    "    num_train_batches = len(train_image_features)\n",
    "    num_val_batches = len(val_image_features)\n",
    "    \n",
    "    # Compute the total number of samples by summing batch sizes.\n",
    "    num_train_samples = sum(batch.shape[0] for batch in train_image_features)\n",
    "    num_val_samples = sum(batch.shape[0] for batch in val_image_features)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        fusion_model.train()\n",
    "        running_train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        \n",
    "        for batch_idx in tqdm(range(num_train_batches), desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            # Get batch data and move to the device.\n",
    "            batch_image_features = train_image_features[batch_idx].to(device)\n",
    "            batch_audio_features = train_audio_features[batch_idx].to(device)\n",
    "            batch_labels = train_labels[batch_idx].to(device)\n",
    "            \n",
    "            # Zero the gradients.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass.\n",
    "            outputs = fusion_model(batch_image_features, batch_audio_features)\n",
    "            \n",
    "            # Calculate loss.\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            \n",
    "            # Backward pass and update weights.\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss scaled by the current batch size.\n",
    "            running_train_loss += loss.item() * batch_labels.size(0)\n",
    "            \n",
    "            # Count correct predictions.\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == batch_labels).sum().item()\n",
    "        \n",
    "        train_loss = running_train_loss / num_train_samples\n",
    "        train_accuracy = correct_train / num_train_samples\n",
    "        \n",
    "        # Validation phase (using batch iteration similar to training)\n",
    "        fusion_model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx in range(num_val_batches):\n",
    "                batch_image_features = val_image_features[batch_idx].to(device)\n",
    "                batch_audio_features = val_audio_features[batch_idx].to(device)\n",
    "                batch_labels = val_labels[batch_idx].to(device)\n",
    "                \n",
    "                outputs = fusion_model(batch_image_features, batch_audio_features)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                running_val_loss += loss.item() * batch_labels.size(0)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == batch_labels).sum().item()\n",
    "        \n",
    "        val_loss = running_val_loss / num_val_samples\n",
    "        val_accuracy = correct_val / num_val_samples\n",
    "        \n",
    "        # Step the scheduler using validation loss.\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save statistics.\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Save the best model state.\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            best_model_state = fusion_model.state_dict().copy()\n",
    "            print(f\"New best model with validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    # Load the best model state.\n",
    "    if best_model_state is not None:\n",
    "        fusion_model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Return the model along with the training history.\n",
    "    history = {\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss': val_losses,\n",
    "        'train_acc': train_accuracies,\n",
    "        'val_acc': val_accuracies\n",
    "    }\n",
    "    \n",
    "    return fusion_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(fusion_model, test_image_features, test_audio_features, test_labels, device):\n",
    "    fusion_model.eval()\n",
    "    total_samples = 0\n",
    "    correct_total = 0\n",
    "    class_correct = None\n",
    "    class_total = None\n",
    "\n",
    "    num_batches = len(test_image_features)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Get batch data and move to the device\n",
    "            batch_image_features = test_image_features[batch_idx].to(device)\n",
    "            batch_audio_features = test_audio_features[batch_idx].to(device)\n",
    "            batch_labels = test_labels[batch_idx].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = fusion_model(batch_image_features, batch_audio_features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Update overall test accuracy\n",
    "            batch_size = batch_labels.size(0)\n",
    "            total_samples += batch_size\n",
    "            correct_total += (predicted == batch_labels).sum().item()\n",
    "            \n",
    "            # Initialize per-class counters on the first batch\n",
    "            if class_correct is None:\n",
    "                num_classes = outputs.size(1)\n",
    "                class_correct = [0] * num_classes\n",
    "                class_total = [0] * num_classes\n",
    "                \n",
    "            # Update per-class statistics\n",
    "            for i in range(batch_size):\n",
    "                label = batch_labels[i].item()\n",
    "                class_total[label] += 1\n",
    "                if predicted[i].item() == label:\n",
    "                    class_correct[label] += 1\n",
    "    \n",
    "    test_accuracy = correct_total / total_samples\n",
    "    class_accuracy = [class_correct[i] / (class_total[i] + 1e-8) for i in range(len(class_correct))]\n",
    "    return test_accuracy, class_accuracy\n",
    "\n",
    "# Function to plot training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fusion_model_training_history.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FOR MACBOOK LOCAL SETUP USERS ONLY \"\"\"\n",
    "use_mps = True\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"mps\") if use_mps and torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/7wj664s92gx_89p1xhcwbq800000gn/T/ipykernel_1239/3139589982.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image_model.load_state_dict(torch.load(image_model_path))\n",
      "/var/folders/s8/7wj664s92gx_89p1xhcwbq800000gn/T/ipykernel_1239/3139589982.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  audio_model.load_state_dict(torch.load(audio_model_path))\n",
      "100%|██████████| 470/470 [00:07<00:00, 64.03it/s]\n",
      "100%|██████████| 117/117 [00:01<00:00, 65.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we run and train the model.\n",
    "\n",
    "# Load pre-trained models\n",
    "image_model_path = \"Models/best_images_model.pt\"\n",
    "audio_model_path = \"Models/T_0.9394_V_0.6755.pt\"\n",
    "image_model, audio_model = load_pretrained_models(image_model_path, audio_model_path, device)\n",
    "\n",
    "# Extract features from the training and validation sets\n",
    "train_image_features, train_audio_features, train_labels = extract_features(image_model, audio_model, train_loader, device)\n",
    "val_image_features, val_audio_features, val_labels = extract_features(image_model, audio_model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image features list shape: 470\n",
      "Train audio features list shape: 470\n",
      "Train labels list shape: 470\n",
      "Train image features shape: torch.Size([32, 47])\n",
      "Train audio features shape: torch.Size([32, 47])\n",
      "Train labels shape: torch.Size([32])\n",
      "Validation image features list shape: 117\n",
      "Validation audio features list shape: 117\n",
      "Validation labels list shape: 117\n",
      "Validation image features shape: torch.Size([32, 47])\n",
      "Validation audio features shape: torch.Size([32, 47])\n",
      "Validation labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train image features list shape: {len(train_image_features)}\")\n",
    "print(f\"Train audio features list shape: {len(train_audio_features)}\")\n",
    "print(f\"Train labels list shape: {len(train_labels)}\")\n",
    "\n",
    "print(f\"Train image features shape: {train_image_features[0].shape}\")\n",
    "print(f\"Train audio features shape: {train_audio_features[0].shape}\")\n",
    "print(f\"Train labels shape: {train_labels[0].shape}\")\n",
    "\n",
    "print(f\"Validation image features list shape: {len(val_image_features)}\")\n",
    "print(f\"Validation audio features list shape: {len(val_audio_features)}\")\n",
    "print(f\"Validation labels list shape: {len(val_labels)}\")\n",
    "\n",
    "print(f\"Validation image features shape: {val_image_features[0].shape}\")\n",
    "print(f\"Validation audio features shape: {val_audio_features[0].shape}\")\n",
    "print(f\"Validation labels shape: {val_labels[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ECE421/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 315.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 2.1660, Train Acc: 0.4294, Val Loss: 0.6105, Val Acc: 0.8723\n",
      "New best model with validation accuracy: 0.8723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 376.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train Loss: 0.7227, Train Acc: 0.7852, Val Loss: 0.3238, Val Acc: 0.9217\n",
      "New best model with validation accuracy: 0.9217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 388.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train Loss: 0.5009, Train Acc: 0.8477, Val Loss: 0.2506, Val Acc: 0.9346\n",
      "New best model with validation accuracy: 0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 384.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train Loss: 0.3872, Train Acc: 0.8803, Val Loss: 0.2031, Val Acc: 0.9460\n",
      "New best model with validation accuracy: 0.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 340.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train Loss: 0.3231, Train Acc: 0.8991, Val Loss: 0.1724, Val Acc: 0.9509\n",
      "New best model with validation accuracy: 0.9509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 370.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train Loss: 0.2822, Train Acc: 0.9098, Val Loss: 0.1533, Val Acc: 0.9567\n",
      "New best model with validation accuracy: 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 388.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train Loss: 0.2394, Train Acc: 0.9269, Val Loss: 0.1335, Val Acc: 0.9615\n",
      "New best model with validation accuracy: 0.9615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 381.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Train Loss: 0.2200, Train Acc: 0.9309, Val Loss: 0.1250, Val Acc: 0.9639\n",
      "New best model with validation accuracy: 0.9639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 339.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Train Loss: 0.1989, Train Acc: 0.9370, Val Loss: 0.1172, Val Acc: 0.9666\n",
      "New best model with validation accuracy: 0.9666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 383.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train Loss: 0.1789, Train Acc: 0.9441, Val Loss: 0.1075, Val Acc: 0.9685\n",
      "New best model with validation accuracy: 0.9685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 380.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Train Loss: 0.1654, Train Acc: 0.9483, Val Loss: 0.0997, Val Acc: 0.9712\n",
      "New best model with validation accuracy: 0.9712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 379.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Train Loss: 0.1539, Train Acc: 0.9516, Val Loss: 0.0877, Val Acc: 0.9733\n",
      "New best model with validation accuracy: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 346.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Train Loss: 0.1444, Train Acc: 0.9537, Val Loss: 0.0858, Val Acc: 0.9736\n",
      "New best model with validation accuracy: 0.9736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 300.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Train Loss: 0.1296, Train Acc: 0.9591, Val Loss: 0.0812, Val Acc: 0.9768\n",
      "New best model with validation accuracy: 0.9768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 304.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Train Loss: 0.1209, Train Acc: 0.9622, Val Loss: 0.0732, Val Acc: 0.9781\n",
      "New best model with validation accuracy: 0.9781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 302.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Train Loss: 0.1133, Train Acc: 0.9644, Val Loss: 0.0690, Val Acc: 0.9805\n",
      "New best model with validation accuracy: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 281.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Train Loss: 0.1043, Train Acc: 0.9679, Val Loss: 0.0656, Val Acc: 0.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 300.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Train Loss: 0.0982, Train Acc: 0.9693, Val Loss: 0.0639, Val Acc: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 321.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Train Loss: 0.0927, Train Acc: 0.9711, Val Loss: 0.0570, Val Acc: 0.9842\n",
      "New best model with validation accuracy: 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 353.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Train Loss: 0.0854, Train Acc: 0.9731, Val Loss: 0.0536, Val Acc: 0.9850\n",
      "New best model with validation accuracy: 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 340.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Train Loss: 0.0800, Train Acc: 0.9761, Val Loss: 0.0509, Val Acc: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 319.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Train Loss: 0.0784, Train Acc: 0.9759, Val Loss: 0.0518, Val Acc: 0.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 294.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Train Loss: 0.0721, Train Acc: 0.9790, Val Loss: 0.0450, Val Acc: 0.9856\n",
      "New best model with validation accuracy: 0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 320.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Train Loss: 0.0675, Train Acc: 0.9802, Val Loss: 0.0422, Val Acc: 0.9866\n",
      "New best model with validation accuracy: 0.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 325.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Train Loss: 0.0619, Train Acc: 0.9830, Val Loss: 0.0431, Val Acc: 0.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 313.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Train Loss: 0.0582, Train Acc: 0.9824, Val Loss: 0.0438, Val Acc: 0.9861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 324.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Train Loss: 0.0600, Train Acc: 0.9823, Val Loss: 0.0392, Val Acc: 0.9874\n",
      "New best model with validation accuracy: 0.9874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 339.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Train Loss: 0.0552, Train Acc: 0.9816, Val Loss: 0.0381, Val Acc: 0.9885\n",
      "New best model with validation accuracy: 0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 374.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Train Loss: 0.0531, Train Acc: 0.9838, Val Loss: 0.0427, Val Acc: 0.9872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 372.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Train Loss: 0.0489, Train Acc: 0.9862, Val Loss: 0.0373, Val Acc: 0.9872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 367.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Train Loss: 0.0437, Train Acc: 0.9868, Val Loss: 0.0351, Val Acc: 0.9899\n",
      "New best model with validation accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 327.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Train Loss: 0.0497, Train Acc: 0.9843, Val Loss: 0.0344, Val Acc: 0.9896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 306.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Train Loss: 0.0446, Train Acc: 0.9856, Val Loss: 0.0357, Val Acc: 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 322.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Train Loss: 0.0420, Train Acc: 0.9880, Val Loss: 0.0295, Val Acc: 0.9896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 348.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Train Loss: 0.0370, Train Acc: 0.9888, Val Loss: 0.0290, Val Acc: 0.9901\n",
      "New best model with validation accuracy: 0.9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 348.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Train Loss: 0.0394, Train Acc: 0.9880, Val Loss: 0.0292, Val Acc: 0.9912\n",
      "New best model with validation accuracy: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 314.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Train Loss: 0.0353, Train Acc: 0.9905, Val Loss: 0.0300, Val Acc: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 342.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Train Loss: 0.0367, Train Acc: 0.9892, Val Loss: 0.0268, Val Acc: 0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 277.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Train Loss: 0.0343, Train Acc: 0.9898, Val Loss: 0.0262, Val Acc: 0.9923\n",
      "New best model with validation accuracy: 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Training: 100%|██████████| 470/470 [00:02<00:00, 184.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Train Loss: 0.0319, Train Acc: 0.9906, Val Loss: 0.0229, Val Acc: 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 320.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Train Loss: 0.0304, Train Acc: 0.9916, Val Loss: 0.0223, Val Acc: 0.9944\n",
      "New best model with validation accuracy: 0.9944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 338.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 - Train Loss: 0.0298, Train Acc: 0.9918, Val Loss: 0.0219, Val Acc: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 361.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Train Loss: 0.0277, Train Acc: 0.9918, Val Loss: 0.0261, Val Acc: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 368.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 - Train Loss: 0.0283, Train Acc: 0.9918, Val Loss: 0.0244, Val Acc: 0.9931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 371.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Train Loss: 0.0256, Train Acc: 0.9916, Val Loss: 0.0239, Val Acc: 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 348.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Train Loss: 0.0268, Train Acc: 0.9924, Val Loss: 0.0244, Val Acc: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 324.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Train Loss: 0.0259, Train Acc: 0.9915, Val Loss: 0.0250, Val Acc: 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 353.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Train Loss: 0.0261, Train Acc: 0.9924, Val Loss: 0.0213, Val Acc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 300.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Train Loss: 0.0236, Train Acc: 0.9932, Val Loss: 0.0200, Val Acc: 0.9947\n",
      "New best model with validation accuracy: 0.9947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Training: 100%|██████████| 470/470 [00:01<00:00, 364.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.0216, Train Acc: 0.9941, Val Loss: 0.0195, Val Acc: 0.9933\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC6OUlEQVR4nOzdeXhTdfbH8U/SNm3SnW60LKUgO7IvgiAoCoI7uC+IAqOiKKKjg/s24oqMG44ji7uMoqg/EUVlU1DZdQRZZCnQFmihLXRvcn9/pAmUtlBKk7Tp+/U8eZLc3Jt7UjvTy8k552syDMMQAAAAAAAA4EVmXwcAAAAAAACAhoekFAAAAAAAALyOpBQAAAAAAAC8jqQUAAAAAAAAvI6kFAAAAAAAALyOpBQAAAAAAAC8jqQUAAAAAAAAvI6kFAAAAAAAALyOpBQAAAAAAAC8jqQUcApMJlO1bosXLz6l8zz22GMymUw1Onbx4sW1EkNdN3r0aLVo0aLK1/fv3y+LxaKrr766yn1yc3Nls9l08cUXV/u8s2fPlslk0o4dO6ody9FMJpMee+yxap/PJS0tTY899pjWrVtX4bVT+X05VS1atNCFF17ok3MDADyHa566g2ueI3x5zeNSUlKixo0by2Qy6ZNPPvFpLEB9FOjrAID6bMWKFeWeP/nkk1q0aJF++OGHcts7dOhwSucZO3aszj///Bod2717d61YseKUY6jv4uLidPHFF2vevHk6ePCgoqOjK+zz0UcfqaCgQGPGjDmlcz388MO66667Tuk9TiQtLU2PP/64WrRooa5du5Z77VR+XwAAqAzXPPUH1zze9X//93/au3evJGnGjBm6/PLLfRoPUN+QlAJOwRlnnFHueVxcnMxmc4Xtx8rPz5fNZqv2eZo2baqmTZvWKMaIiIgTxtNQjBkzRnPnztX777+vO+64o8LrM2fOVEJCgi644IJTOk+rVq1O6fhTdSq/LwAAVIZrnvqFax7vmTFjhiwWiwYOHKhvv/1Wu3fv9nlMlbHb7SotLVVwcLCvQwHKoX0P8LBBgwapU6dOWrp0qfr16yebzaabb75ZkjRnzhwNGTJEiYmJslqtat++vf7xj38oLy+v3HtUVprsapNasGCBunfvLqvVqnbt2mnmzJnl9quslH306NEKCwvT1q1bNXz4cIWFhalZs2a65557VFRUVO743bt36/LLL1d4eLiioqJ03XXXaeXKlTKZTJo9e/ZxP/v+/fs1fvx4dejQQWFhYYqPj9c555yjZcuWldtvx44dMplMeuGFFzR16lSlpKQoLCxMffv21c8//1zhfWfPnq22bdsqODhY7du31zvvvHPcOFyGDh2qpk2batasWRVe27hxo3755ReNGjVKgYGBWrhwoS655BI1bdpUISEhOu2003TLLbcoMzPzhOeprJQ9NzdX48aNU0xMjMLCwnT++edr8+bNFY7dunWrbrrpJrVu3Vo2m01NmjTRRRddpN9//929z+LFi9WrVy9J0k033eRumXCVxFf2++JwOPTcc8+pXbt2Cg4OVnx8vEaNGqXdu3eX28/1+7py5UoNGDBANptNLVu21DPPPCOHw3HCz14dhYWFmjx5slJSUmSxWNSkSRPdfvvtys7OLrffDz/8oEGDBikmJkZWq1XNmzfXyJEjlZ+f795n+vTp6tKli8LCwhQeHq527drpgQceqJU4AQAnh2sernmkhnXNk5aWpgULFuiiiy7S3//+dzkcjip/Vz744AP17dtXYWFhCgsLU9euXTVjxoxy+yxYsECDBw9WZGSkbDab2rdvrylTppSLedCgQRXe+9j/Dq7fs+eee05PPfWUUlJSFBwcrEWLFqmwsFD33HOPunbtqsjISDVq1Eh9+/bV559/XuF9HQ6HXnnlFXXt2lVWq1VRUVE644wz9MUXX0hyJj8bNWpU7trM5ZxzzlHHjh2r8VNEQ0dSCvCC9PR0XX/99br22ms1f/58jR8/XpK0ZcsWDR8+XDNmzNCCBQs0ceJE/fe//9VFF11Urfddv3697rnnHt199936/PPP1blzZ40ZM0ZLly494bElJSW6+OKLNXjwYH3++ee6+eab9dJLL+nZZ59175OXl6ezzz5bixYt0rPPPqv//ve/SkhI0FVXXVWt+A4cOCBJevTRR/XVV19p1qxZatmypQYNGlTpvIfXXntNCxcu1LRp0/T+++8rLy9Pw4cPV05Ojnuf2bNn66abblL79u01d+5cPfTQQ3ryyScrtA9Uxmw2a/To0VqzZo3Wr19f7jXXRZvr4vmvv/5S3759NX36dH377bd65JFH9Msvv6h///4qKSmp1ud3MQxDl156qd59913dc889+uyzz3TGGWdo2LBhFfZNS0tTTEyMnnnmGS1YsECvvfaaAgMD1adPH23atEmSsz3BFe9DDz2kFStWaMWKFRo7dmyVMdx22226//77dd555+mLL77Qk08+qQULFqhfv34VLjozMjJ03XXX6frrr9cXX3yhYcOGafLkyXrvvfdO6nMf72fxwgsv6IYbbtBXX32lSZMm6e2339Y555zj/gfCjh07dMEFF8hisWjmzJlasGCBnnnmGYWGhqq4uFiSs/Vg/PjxGjhwoD777DPNmzdPd999d4V/4AAAvIdrHq55GtI1z+zZs2W323XzzTfr3HPPVXJysmbOnCnDMMrt98gjj+i6665TUlKSZs+erc8++0w33nijdu7c6d5nxowZGj58uBwOh9544w19+eWXuvPOOysk007Gyy+/rB9++EEvvPCCvv76a7Vr105FRUU6cOCA7r33Xs2bN08ffvih+vfvrxEjRlRIeo4ePVp33XWXevXqpTlz5uijjz7SxRdf7J4rdtddd+ngwYP64IMPyh23YcMGLVq0SLfffnuNY0cDYgCoNTfeeKMRGhpabtvAgQMNScb3339/3GMdDodRUlJiLFmyxJBkrF+/3v3ao48+ahz7P9fk5GQjJCTE2Llzp3tbQUGB0ahRI+OWW25xb1u0aJEhyVi0aFG5OCUZ//3vf8u95/Dhw422bdu6n7/22muGJOPrr78ut98tt9xiSDJmzZp13M90rNLSUqOkpMQYPHiwcdlll7m3b9++3ZBknH766UZpaal7+6+//mpIMj788EPDMAzDbrcbSUlJRvfu3Q2Hw+Heb8eOHUZQUJCRnJx8whi2bdtmmEwm484773RvKykpMRo3bmyceeaZlR7j+m+zc+dOQ5Lx+eefu1+bNWuWIcnYvn27e9uNN95YLpavv/7akGT861//Kve+//znPw1JxqOPPlplvKWlpUZxcbHRunVr4+6773ZvX7lyZZX/DY79fdm4caMhyRg/fny5/X755RdDkvHAAw+4t7l+X3/55Zdy+3bo0MEYOnRolXG6JCcnGxdccEGVry9YsMCQZDz33HPlts+ZM8eQZLz55puGYRjGJ598Ykgy1q1bV+V73XHHHUZUVNQJYwIA1D6ueY6Pax7/v+ZxOBzGaaedZjRp0sT939IVz9H/G9i2bZsREBBgXHfddVW+16FDh4yIiAijf//+5f57H2vgwIHGwIEDK2w/9r+D6/esVatWRnFx8XE/h+t3dcyYMUa3bt3c25cuXWpIMh588MHjHj9w4ECja9eu5bbddtttRkREhHHo0KHjHgsYhmFQKQV4QXR0tM4555wK27dt26Zrr71WjRs3VkBAgIKCgjRw4EBJztLqE+natauaN2/ufh4SEqI2bdqU+9alKiaTqcK3k507dy537JIlSxQeHl5hgOQ111xzwvd3eeONN9S9e3eFhIQoMDBQQUFB+v777yv9fBdccIECAgLKxSPJHdOmTZuUlpama6+9tlypdnJysvr161eteFJSUnT22Wfr/fffd1fcfP3118rIyHB/YyhJ+/bt06233qpmzZq5405OTpZUvf82R1u0aJEk6brrriu3/dprr62wb2lpqZ5++ml16NBBFotFgYGBslgs2rJly0mf99jzjx49utz23r17q3379vr+++/LbW/cuLF69+5dbtuxvxs15fp299hYrrjiCoWGhrpj6dq1qywWi/72t7/p7bff1rZt2yq8V+/evZWdna1rrrlGn3/+ebXaDAAAnsU1D9c8UsO45lmyZIm2bt2qG2+80f3f0tVieHRr6cKFC2W3249bNbR8+XLl5uZq/Pjxtbqa4MUXX6ygoKAK2z/++GOdeeaZCgsLc/83nzFjRrmf+9dffy1JJ6x2uuuuu7Ru3Tr99NNPkpztm++++65uvPFGhYWF1dpngf8iKQV4QWJiYoVthw8f1oABA/TLL7/oqaee0uLFi7Vy5Up9+umnkqSCgoITvm9MTEyFbcHBwdU61mazKSQkpMKxhYWF7udZWVlKSEiocGxl2yozdepU3XbbberTp4/mzp2rn3/+WStXrtT5559faYzHfh7XIEbXvllZWZKcFxDHqmxbVcaMGaOsrCx3P/ysWbMUFhamK6+8UpKzf37IkCH69NNPdd999+n777/Xr7/+6p71UJ2f79GysrIUGBhY4fNVFvOkSZP08MMP69JLL9WXX36pX375RStXrlSXLl1O+rxHn1+q/PcwKSnJ/brLqfxeVSeWwMBAxcXFldtuMpnUuHFjdyytWrXSd999p/j4eN1+++1q1aqVWrVqpX/961/uY2644QbNnDlTO3fu1MiRIxUfH68+ffpo4cKFpxwnAKBmuObhmqehXPO45kFddtllys7OVnZ2tiIjI9W/f3/NnTvXPStz//79knTc4efV2acmKvs5fPrpp7ryyivVpEkTvffee1qxYoVWrlypm2++udz/Jvbv36+AgIAT/r5dcsklatGihV577TVJzpbGvLw8WvdQbay+B3hBZd94/PDDD0pLS9PixYvd3xRKqjDs2ZdiYmL066+/VtiekZFRrePfe+89DRo0SNOnTy+3/dChQzWOp6rzVzcmSRoxYoSio6M1c+ZMDRw4UP/3f/+nUaNGub/N+d///qf169dr9uzZuvHGG93Hbd26tcZxl5aWKisrq9zFT2Uxv/feexo1apSefvrpctszMzMVFRVV4/NLzjkfx17spKWlKTY2tkbvW9NYSktLtX///nKJKcMwlJGR4R5mKkkDBgzQgAEDZLfbtWrVKr3yyiuaOHGiEhISdPXVV0tyfiN50003KS8vT0uXLtWjjz6qCy+8UJs3b3Z/ywsA8B6uebjmaQjXPDk5OZo7d64klbt2OdoHH3yg8ePHu693du/erWbNmlW679H7HE9ISEi5uWMuVVWLV/a/x/fee08pKSmaM2dOudePHfwfFxcnu92ujIyMSpNbLmazWbfffrseeOABvfjii3r99dc1ePBgtW3b9rifBXChUgrwEdcfgWOXZf33v//ti3AqNXDgQB06dMhdvuvy0UcfVet4k8lU4fP99ttvWrFiRY3iadu2rRITE/Xhhx+WGyC5c+dOLV++vNrvExISomuvvVbffvutnn32WZWUlJQrY6/t/zZnn322JOn9998vt/3YoZCucx973q+++kp79uwpt+3Yb1SPx9VGcezQzpUrV2rjxo0aPHjwCd+jtrjOdWwsc+fOVV5eXqWxBAQEqE+fPu5v4NasWVNhn9DQUA0bNkwPPvigiouL9ccff3ggegBATXDNc/K45jmiLl7zfPDBByooKNCTTz6pRYsWVbjFxsa6W/iGDBmigICACgnLo/Xr10+RkZF64403KgxJP1qLFi20efPmcgmkrKysk/qdMJlMslgs5RJSGRkZFVbfcw2nP17cLmPHjpXFYtF1112nTZs26Y477qh2PACVUoCP9OvXT9HR0br11lv16KOPKigoSO+//36FFVJ86cYbb9RLL72k66+/Xk899ZROO+00ff311/rmm28kOb8ZOZ4LL7xQTz75pB599FENHDhQmzZt0hNPPKGUlBSVlpaedDxms1lPPvmkxo4dq8suu0zjxo1Tdna2HnvssZMqZZec5eyvvfaapk6dqnbt2pWbz9CuXTu1atVK//jHP2QYhho1aqQvv/yyxm1hQ4YM0VlnnaX77rtPeXl56tmzp3766Se9++67Ffa98MILNXv2bLVr106dO3fW6tWr9fzzz1f4tq9Vq1ayWq16//331b59e4WFhSkpKUlJSUkV3rNt27b629/+pldeeUVms1nDhg3Tjh079PDDD6tZs2a6++67a/S5qpKRkaFPPvmkwvYWLVrovPPO09ChQ3X//fcrNzdXZ555pn777Tc9+uij6tatm2644QZJzrkcP/zwgy644AI1b95chYWF7ou7c889V5I0btw4Wa1WnXnmmUpMTFRGRoamTJmiyMjIKr+1BAB4H9c8XPP42zXPjBkzFB0drXvvvbdCa6gkjRo1SlOnTtX69evVpUsXPfDAA3ryySdVUFCga665RpGRkdqwYYMyMzP1+OOPKywsTC+++KLGjh2rc889V+PGjVNCQoK2bt2q9evX69VXX5XkHF3w73//W9dff73GjRunrKwsPffcc4qIiKh27BdeeKE+/fRTjR8/Xpdffrl27dqlJ598UomJidqyZYt7vwEDBuiGG27QU089pb179+rCCy9UcHCw1q5dK5vNpgkTJrj3jYqK0qhRozR9+nQlJydXe1VNQBKr7wG1qaqVaDp27Fjp/suXLzf69u1r2Gw2Iy4uzhg7dqyxZs2aCiuMVLUSTWWrnB27KkdVK9EcG2dV50lNTTVGjBhhhIWFGeHh4cbIkSON+fPnV1iRpTJFRUXGvffeazRp0sQICQkxunfvbsybN6/KFUKef/75Cu+hSlZqeeutt4zWrVsbFovFaNOmjTFz5swK71kd3bp1q3QlOMMwjA0bNhjnnXeeER4ebkRHRxtXXHGFkZqaWiGe6qxEYxiGkZ2dbdx8881GVFSUYbPZjPPOO8/4888/K7zfwYMHjTFjxhjx8fGGzWYz+vfvbyxbtqzS1VY+/PBDo127dkZQUFC596nsv6PdbjeeffZZo02bNkZQUJARGxtrXH/99cauXbvK7VfV72t1f77JycmGpEpvN954o2EYzhWT7r//fiM5OdkICgoyEhMTjdtuu804ePCg+31WrFhhXHbZZUZycrIRHBxsxMTEGAMHDjS++OIL9z5vv/22cfbZZxsJCQmGxWIxkpKSjCuvvNL47bffThgnAODUcM1THtc8R/j7Nc/69esNScbEiROr3Mf1eSdMmODe9s477xi9evUyQkJCjLCwMKNbt24VVhScP3++MXDgQCM0NNSw2WxGhw4djGeffbbcPm+//bbRvn17IyQkxOjQoYMxZ86ck/o9MwzDeOaZZ4wWLVoYwcHBRvv27Y3//Oc/Vf4sX3rpJaNTp06GxWIxIiMjjb59+xpffvllhfdcvHixIcl45plnqvy5AJUxGcZx6gMBoBJPP/20HnroIaWmptb6QEYAAIC6gmseoHruueceTZ8+Xbt27ap0gDxQFdr3AByXq1y4Xbt2Kikp0Q8//KCXX35Z119/PRdnAADAb3DNA5y8n3/+WZs3b9brr7+uW265hYQUThpJKQDHZbPZ9NJLL2nHjh0qKipS8+bNdf/99+uhhx7ydWgAAAC1hmse4OT17dtXNptNF154oZ566ilfh4N6iPY9AAAAAAAAeN3xl5EAAAAAAAAAPICkFAAAAAAAALyOpBQAAAAAAAC8rsENOnc4HEpLS1N4eLhMJpOvwwEAAHWcYRg6dOiQkpKSZDY33O/zuIYCAADVVd3rpwaXlEpLS1OzZs18HQYAAKhndu3a1aCXhecaCgAAnKwTXT81uKRUeHi4JOcPJiIiwsfRAACAui43N1fNmjVzX0M0VFxDAQCA6qru9VODS0q5ys0jIiK4oAIAANXW0FvWuIYCAAAn60TXTw13MAIAAAAAAAB8hqQUAAAAAAAAvI6kFAAAAAAAALyuwc2UAgDUX3a7XSUlJb4OA34mKChIAQEBvg4DAACgwSEpBQCo8wzDUEZGhrKzs30dCvxUVFSUGjdu3OCHmQMAAHgTSSkAQJ3nSkjFx8fLZrOROECtMQxD+fn52rdvnyQpMTHRxxEBAAA0HCSlAAB1mt1udyekYmJifB0O/JDVapUk7du3T/Hx8bTyAQAAeAmDzgEAdZprhpTNZvNxJPBnrt8vZpYBAAB4D0kpAEC9QMsePKm+/X4tXbpUF110kZKSkmQymTRv3rwTHrNkyRL16NFDISEhatmypd544w3PBwoAAHAcJKUAAADqmby8PHXp0kWvvvpqtfbfvn27hg8frgEDBmjt2rV64IEHdOedd2ru3LkejhQAAKBqzJQCAKCeGDRokLp27app06b5OhT42LBhwzRs2LBq7//GG2+oefPm7t+d9u3ba9WqVXrhhRc0cuRID0UJAABwfFRKAQBQy0wm03Fvo0ePrtH7fvrpp3ryySdPKbbRo0fr0ksvPaX3QP2zYsUKDRkypNy2oUOHatWqVVXO0SoqKlJubm65GwAAQG2iUgoAgFqWnp7ufjxnzhw98sgj2rRpk3uba7U3l5KSEgUFBZ3wfRs1alR7QaJBycjIUEJCQrltCQkJKi0tVWZmphITEyscM2XKFD3++OPeChEAADRAVEoBAFDLGjdu7L5FRkbKZDK5nxcWFioqKkr//e9/NWjQIIWEhOi9995TVlaWrrnmGjVt2lQ2m02nn366Pvzww3LvO2jQIE2cONH9vEWLFnr66ad18803Kzw8XM2bN9ebb755SrEvWbJEvXv3VnBwsBITE/WPf/xDpaWl7tc/+eQTnX766bJarYqJidG5556rvLw8SdLixYvVu3dvhYaGKioqSmeeeaZ27tx5SvGg9hw7zN0wjEq3u0yePFk5OTnu265duzweIwAAaFiolKplW/YeUlZesVrFhSkuPNjX4QCAXzIMQwUldq+f1xoUUGurtN1///168cUXNWvWLAUHB6uwsFA9evTQ/fffr4iICH311Ve64YYb1LJlS/Xp06fK93nxxRf15JNP6oEHHtAnn3yi2267TWeddZbatWt30jHt2bNHw4cP1+jRo/XOO+/ozz//1Lhx4xQSEqLHHntM6enpuuaaa/Tcc8/psssu06FDh7Rs2TIZhqHS0lJdeumlGjdunD788EMVFxfr119/rXer2vmrxo0bKyMjo9y2ffv2KTAwUDExMZUeExwcrOBgrmUAAD7icEj2YikoxNeR1B+GIR1Kl3LTJVu0FBovBYf5OqrjIilVyx75/A+t2Jall6/ppou7JPk6HADwSwUldnV45Buvn3fDE0Nls9TOn86JEydqxIgR5bbde++97scTJkzQggUL9PHHHx83KTV8+HCNHz9ekjPR9dJLL2nx4sU1Skq9/vrratasmV599VWZTCa1a9dOaWlpuv/++/XII48oPT1dpaWlGjFihJKTkyVJp59+uiTpwIEDysnJ0YUXXqhWrVpJcg7TRt3Qt29fffnll+W2ffvtt+rZs2e1WkcBAPAIh8OZRDnwl5T1l3RgW/lbaaFki5Wimh9zSy67byZZQmsnFnuJlLdfKjgoBYZIwRFScLgUGCzVxS/ZivOkfRtVmvE/lab9Lu39Q4GZGxRYlFNutxJziPICo5UbGK1sU5QOKEr7jQjtdUQorTRC99x2q2Ji4nz0IUhK1TqbJUCSVFjs/W/wAQD1R8+ePcs9t9vteuaZZzRnzhzt2bNHRUVFKioqUmjo8S+0Onfu7H7sahPct29fjWLauHGj+vbtW6666cwzz9Thw4e1e/dudenSRYMHD9bpp5+uoUOHasiQIbr88ssVHR2tRo0aafTo0Ro6dKjOO+88nXvuubryyisrnVWEU3f48GFt3brV/Xz79u1at26dGjVqpObNm2vy5Mnas2eP3nnnHUnSrbfeqldffVWTJk3SuHHjtGLFCs2YMaNCiygAANVWWiTl7JYO7pCyU523nN3O6qYTsRc7jzuwXSotOP6++ZnOW9qaSl8uCo5RYXCsSoNCVRIQqtKgMJUEOh+XBLoe21QaGKrA0jyFFGcppChLIcUHFFxU9rgoS5aSnErf32EKlD0oTKVBYbIHhckeFOq8DwxVsSlYRbKoUEEqMCwqMIKUZ1iUZw9SniNIh+yBkkyKCCxVWECpwgJKFGYukc1cIquKFWIqUYiKZDGK5TCkYsOsYiNAxQ6TihwBKnKYVOgwq8BuUoHdrNJSu+KKdqp5yXYlGRkyy1Cgyid2Sg2z9ilKUcqTzVSkIEehoorTFVWcruaVfL7UA5coJiZOhmHIZDK52/ulqlv8axNJqVoWUpaU8kVbCQA0FNagAG14YqhPzltbjk02vfjii3rppZc0bdo0nX766QoNDdXEiRNVXHz8C7tjq1xMJpMcDkeNYnJdjBy7zfW+AQEBWrhwoZYvX65vv/1Wr7zyih588EH98ssvSklJ0axZs3TnnXdqwYIFmjNnjh566CEtXLhQZ5xxRo3iQdVWrVqls88+2/180qRJkqQbb7xRs2fPVnp6ulJTU92vp6SkaP78+br77rv12muvKSkpSS+//LJGjhzp9dgBoF4oOCg57JI50HkLCJLMQZLZS2OZ7aXOZE1J4ZH7knxn5VBJgVSY7Yyx4KCUf0AqcD0/cGR7Ya4ko8Jbu7YYhiGHITlkVmlQmByWMJmCw2UOiVCQLUKBIWWVQsHhzhaw4rwjyafsVGeFUy0oVYDSTPHa6WisrfZ4bTcaa6fRWNuNxso1bEoyZampab+amjLL7l2P9ynCVKDgoiwFF2XVTiyGWTkKVbBKFGYqlCSZjVKZi7MVVJxdK+eoTfuNSG10NNefRnNtMydrl6WlskKSFWINVXhIoOIspWockKt4c45iTIfUyMhWpOOgwu0HFVpyQNaiLMUnNvN6IupoJKVqmesfLPlUSgGAx5hMplpro6srli1bpksuuUTXX3+9JMnhcGjLli1ebYHr0KGD5s6dWy45tXz5coWHh6tJkyaSnD/7M888U2eeeaYeeeQRJScn67PPPnMnRbp166Zu3bpp8uTJ6tu3rz744AOSUh4waNCgcheQx5o9e3aFbQMHDtSaNZV/ywwAdU5p8ZHkSkm+ZGvknI9jsdXueUoKpf1/Snv/kPZtkPb+z/k4b38VB5jKElSBziSVJVRK7ie1Pk9qNVgKO8k2qJJCaedP0tbvpK3fS7lpziSUo/TEx9aQ6ah7V4rNUlQgFe2XDp3ce+UrROmK0y4jTqmOGO12xKpAJ55H6JBZu404bTcaa48RK7vKf/EXaglQpDVIccGBcpiTtMtkUppZWmUyyWQyyWySAkwmhRl5SnBkKNKRI6sKZDPyZXMUyGrky2oUyGrkyVr2PMSRryKzVTnmaOUGRCnHHK1sc5RyA6KUXfb4kMLlMJnkMCQ57LI4ChRsz5fVkadgR75CjHyF2PNkMwpkVYHCzCUKCyhRqLnUWf1kKpbVVKIQo0jBKpbFKJIkFZksKpLlSDWVI0iH7RYdtgfqkD1QuaWBCjCbFBpoyBZoyBZgyBpoyBrgUEiAQyFmKSTALotZKo1MkT2+g0yNOyo0OlGdQwLVLzhQgQH1cx07/7qirwNcSSkqpQAAJ+O0007T3LlztXz5ckVHR2vq1KnKyMjwSFIqJydH69atK7etUaNGGj9+vKZNm6YJEybojjvu0KZNm/Too49q0qRJMpvN+uWXX/T9999ryJAhio+P1y+//KL9+/erffv22r59u958801dfPHFSkpK0qZNm7R582aNGjWq1uMHANQzDoezsufwPilvX9n9fuct/8AxFT7Zzvviw5W/lyVMCo2TwuKPuo93JoOCI088+8dwSNk7pb0bnMmnrK2ScTL/djOcrWeuFrWiHOl/nzhvMklJ3ZwJqtPOk5p0l8yVVFkf3KHiP79V0cavZd2zQoH247evFRpBKpRFBQp2P85VqLKNMOdNocoxwnRQrudhyg+IUL7Jprziyr/AMJmkxEirUmJtirUGqDAvR8X52SopyJW94JCC7XkKU77CTAUKU6HCla8CBWuXEafd7lusDipcR9JcR4QFByo8JNB9Hx4S5L6PKNve1hakSGuQIqzO+yjrkedB9TTBgpNHUqqWWV0zpUhKAQBOwsMPP6zt27dr6NChstls+tvf/qZLL71UOTmVzzc4FYsXL1a3bt3KbXO1fc2fP19///vf1aVLFzVq1EhjxozRQw89JEmKiIjQ0qVLNW3aNOXm5io5OVkvvviihg0bpr179+rPP//U22+/raysLCUmJuqOO+7QLbfcUuvxAwCqoaTQObPn4A4pP6tia1f+sUmgapbImMxSoNW5IprrPshacVvR4bIE1H7nPKAaVf6YJGuU8z3zsyR7kTNZVXxYOri9Bu9XuWyFaZPRXBvszbTRaK4/Hc21xWgie0CwWsdY1SbeqrZxVrWODdZpMSFqGmVRgFHqbO87lCH99b205Vsp43fn3KO0NdKSZ+UIaaTcJmcpLa6/0ktCZdu1WMkHliupdJcskixl599rRGmxvasWO7roT6O5CgyLOwkVEBSssBBLucROqCVQJXaHDhWVKq+oVIeLSnW40HlfZC9r4S+7M5uk5JhQnRYfpjYJYWodH67T4sPUKi7M/W/XyuQVlSrrcLH2Hy5SZtlNDkNtggLUxRIga1DZzVJ2K3seYglQqMVZ9QNUh8k4Xu23H8rNzVVkZKRycnIUERFR6+8/deFmvfz9Ft1wRrKevLRTrb8/ADQ0hYWF2r59u1JSUhQSwpLA8Izj/Z55+tqhvuDnAFThwDZn21VBtlSU60yYFB2q/GYvkayRkrWRZI123mxHPbZGO18LDj8qwVN2CyxL/gRYjlQDuRJPB7ZVXL0sZ7cqmyfkUyFR5aucQuMkW8wxP4NGzkSUNdq5v2uGk2E4f76H91eotjIO71NxToYKD+cov8SugmK78oud90WlFYsF9itKf5bN4dnoaK59itKx1T4BZpPsjsp/fpZAs1rFhaltQpiaNbIpp6BEmYeLVJqTrtNyf1bXwpU6w/hNEab8So8vNcxabbTRLwE9lNqonwITT1er+HC1jAtV48gQRZQln8Jq0JJVXOpwJ6qK7Q41ibIqpBZnYgLVVd3rBiqlahntewAAAICfy8uU/vhM+m2OtHvlyR1blOMcEl1TrkqlwGBnhdPxEk+WcKlRijMJVC7pE10xKWYJc773MUocDm3PzNOmjEPalHFIhwsKFRFYqvBjVhILPWqeTrCKZbKEqtQaK7stTqXWODmsMTICLDKbTDKZnHk1s8kka1CAQoMDZbMEKDjQXPWQZZNJBeYwbS82aVuOTdv3x2lbZp627T+sbZl5OlRYdSVWXHiwWsU5q4VOiwtTQkSIzrAE6Oyy6h6bJUAhQUcqfkKCAmSSlJZToM17D2nz3sPavPeQtuw9rC37DqmwxKGN6bnamJ57bJD6Vn0l9VWgStUr8C8Ntfyus0xrFaF87Y7urbzmg2Rre65aN01Sn1BLJdGeGkugWZZAi6I98N6AJ5CUqmXWIOf/kZOUAgAAAPxIcb60ab7023+d7VqudjSTWWoxQIpuUbZKWYRzpTL3qmXhzuRQcLhzOHZhThVtdGXtdfkHnNVWx6665ko+GQ6pJM95k5zvHdNSatRKatRSiml15HFo7IlnLB2loNiujRm5+iMtVxvScvS/PbnatPeQiksrW9XVJJVrQqtKbtntrxOeP9Bsks0SoLDgQNmCAxUaHKjQshaznVn52pNd9ewlk0lqGm3VaXFhzuST6xYXrkhbUJXHHU/TaJuaRtt0TrsE9za7w9Dug/nuRFVadoGibRbFhlkUGx6smNBgxYVbFBsWrEhrULkkW2yNogD8G0mpWuaeKcXqewAAAIDn5GVK+zdJmZuk/ZudK6hlbnbOHgqJOqYlLKpihVBwuBRkKz8H6eh2uYAgyV4qbV8i/f6xtPHL8sO3k7pJna+SOo6QwhOqirJ2GGXDtUsKpNLCI/e22BMmnuwOQzkFJTqQV6QDeRXvD+YXKyuvWGnZBdq2/7Aq61gLCw5Uh8QIdUiKUOPIkLL2uFJ3i1xe2eN8d9tcqUrsRlnohoyyj2DIkGGo7ByGHIYzEeb6Qr/UYSi3sFS5x6l6irQGqWVcqFrGhpXdh6plXJiSY2xeaVMLMJuUHBOq5JhQndfBw//dgQaApFQtC6F9DwAAADg1hlG2WttR84MOpTuTTvs3OxNR+VlVH384w3k7FaYAZ2WTvejItqhkZyKq85VSbOtTe/+TisXkbNcLDD7ubiV2hzbvPaTfdueU3bK1KeOQSquYjVSZuPBgdUyKKLtFqkNihJo3ssnswcHVdofhTGwV2XW4qFT5xc6ZSPlFzoRXqd1QcoxNKbGhahRqqbrFD0C9Q1KqljFTCgAAAKiGQ3ulPauktHVSblqF4dWyF5/4PSKbS3FtnbfYNs77sATnQOwKrXEHy7fMFR8uX3lUUuBsl3Mx7JLd7qyw6jTCmYxq2uuk2uFq4nBRqbLzixVgNjlvJtORx0dtM5lM2rb/sNbvztHvu7O1fneONqTnVtFqJ0WEBComLFjRtiA1Cg1Wo9Dy93HhwWqfGK74cO8vKhJgNikiJEgRITVrswNQf5GUqmWu9r0C2vcAAAAAp+J8KX2dtHuVtGe185az68THBUccWa0tLF6KaX0kARXbWrKE1m6chiGVFh2Z5WQvkiKaOFv5POBwUan+2JOj34+6bc/M06msjx4REqjOTaN0etNIdWkaqY5JkWocGaKgk1zFDQC8gaRULXNVShVSKQUAAAB/U3RYOrDNWdVkL5UcJc6B3+UeH3WftdVZDbV3g7PyqByTFN9eatJdii5bIS40viwJFed8HOTlqh2TyXnOoBDJWntvaxiGDuaXaMveQ/p9T47+tydHvx0nARUcaHbmxxyOSmc8udgsAeqUFKnOTSPLklBRSo6x0d4GoN4gKVXLmCkFAACAeq3osHRwu5T1l3TgL2cSKmub8/HhvTV/37DGUtOeUpMezvukbs5h436iuNShPdkFSj2Q77xl5ZU9LtCuA/k6XFT58O6kyBB1auJMLHVqEqnTm0QqJuzI7CjDMGR3GLK77h2GHA5nwirKZlGAB2c9AYCnkZSqZbTvAQAAoF4oKXQODN/7x5Hb/j+dA8WPx9roSEtbQJBzGLjrdvTzgCApvLHUpKczCRXRxOPzmDypoNiuPdkFztvBAqUd9XhPdoHScgpO2HbXJMqqjkkROr1JpDo1dSagYsOOP7zcZDIpMMDEP9wA+CX+v62WHWnfq3zAIAAA1TVo0CB17dpV06ZNkyS1aNFCEydO1MSJE6s8xmQy6bPPPtOll156SueurfcBUAfYS6XcPdK+jdLe/zmTT/s2SJlbKmmpK2NtJMW0khq1lBqV3ce0dN5bo70bv4fZHYay8oq0L7dI+w8Vad+hQu3LLdK+ssdp2YVKyy5QVt6JB69bgwLUvJFNzWNszvuyW7NGNjWNtrq7KgAATiSlapkrKVVsd6jU7lAgAwUBoMG56KKLVFBQoO+++67CaytWrFC/fv20evVqde/e/aTed+XKlQoNrd2hvo899pjmzZundevWlduenp6u6GjP/sNz9uzZmjhxorKzsz16HsDvOezO1euyU4+57XTe5+5xzniqjDVaSugkJXR03uI7OJNRfpZ4kqRSu0N/ZhzSqh0HtDo1Wzsy87TvUKEyDxfLfrzBTUcJCw5UkyirmkRb1STKqqSjHjdvZFNsmIV5TgBwEkhK1TJX+54kFZY6FEZSCgAanDFjxmjEiBHauXOnkpOTy702c+ZMde3a9aQTUpIUFxdXWyGeUOPGjb12LgDV5HBI2TuOarf7n3OAePbOqpNOLgEW54p18R3KElBliajwxvW6pe54DheVal1qtlbuOKDVOw9qbepB5VUxYsNkkmJCgxUfHqz4iLL78BDFRwQrMdKZdGoSZVWENZCkEwDUIpJStSw40CyTybmabEGxXWHB/IgBoKG58MILFR8fr9mzZ+vRRx91b8/Pz9ecOXP09NNPKysrS3fccYeWLVumAwcOqFWrVnrggQd0zTXXVPm+x7bvbdmyRWPGjNGvv/6qli1b6l//+leFY+6//3599tln2r17txo3bqzrrrtOjzzyiIKCgjR79mw9/vjjkuT+R9asWbM0evToCu17v//+u+666y6tWLFCNptNI0eO1NSpUxUWFiZJGj16tLKzs9W/f3+9+OKLKi4u1tVXX61p06YpKKhmS6mnpqZqwoQJ+v7772U2m3X++efrlVdeUUJCgiRp/fr1mjhxolatWiWTyaTWrVvr3//+t3r27KmdO3fqjjvu0I8//qji4mK1aNFCzz//vIYPH16jWACvyz9Q1m73x1EtdxulkrzK9zcHSVHNpKjmR92SjzwOayyZ/fPLUsMwlHm4WNsz87Q987A2pOVq1c6D2pieW2HluvCQQHVvHq2eydFqnxihhAhn4ikm1EKHAwD4ABmTWmYymWQNClB+sZ1h5wDgKYYhleR7/7xBtmpVFAQGBmrUqFGaPXu2HnnkEXfC5+OPP1ZxcbGuu+465efnq0ePHrr//vsVERGhr776SjfccINatmypPn36nPAcDodDI0aMUGxsrH7++Wfl5uZWOmsqPDxcs2fPVlJSkn7//XeNGzdO4eHhuu+++3TVVVfpf//7nxYsWOBuNYyMjKzwHvn5+Tr//PN1xhlnaOXKldq3b5/Gjh2rO+64Q7Nnz3bvt2jRIiUmJmrRokXaunWrrrrqKnXt2lXjxo074ec5lmEYuvTSSxUaGqolS5aotLRU48eP11VXXaXFixdLkq677jp169ZN06dPV0BAgNatW+dOgN1+++0qLi7W0qVLFRoaqg0bNrgTaECdYRjOtrvMTdL+zc4h45mbpf2bpPzMyo8JCJbi2x9pt0voKMW0dlY8mf17XlFOQYm2Z+ZpR2aetmXmuR9vz8yrcmW7ptFW9UyOVo8WjdSrRbRax4ezWh0A1CEkpTzAnZQqISkFAB5Rki89neT98z6QJlmqN9Pp5ptv1vPPP6/Fixfr7LPPluRs3RsxYoSio6MVHR2te++9173/hAkTtGDBAn388cfVSkp999132rhxo3bs2KGmTZtKkp5++mkNGzas3H4PPfSQ+3GLFi10zz33aM6cObrvvvtktVoVFhamwMDA47brvf/++yooKNA777zjnmn16quv6qKLLtKzzz7rrlyKjo7Wq6++qoCAALVr104XXHCBvv/++xolpb777jv99ttv2r59u5o1ayZJevfdd9WxY0etXLlSvXr1Umpqqv7+97+rXbt2kqTWrVu7j09NTdXIkSN1+umnS5Jatmx50jEAta4gW9r8jbRtcVkCaotUfKjq/SObS407lW+5a9RSCvD/S/j84lL9b0+u1u/K1vrdztuuAwVV7m8yORNQKbFhOi0uTN2To9QzuZEaR4Z4MWoAwMny/79oPuBaVYOkFAA0XO3atVO/fv00c+ZMnX322frrr7+0bNkyffvtt5Iku92uZ555RnPmzNGePXtUVFSkoqKiag8y37hxo5o3b+5OSElS3759K+z3ySefaNq0adq6dasOHz6s0tJSRUREnNRn2bhxo7p06VIutjPPPFMOh0ObNm1yJ6U6duyogIAjlRqJiYn6/fffT+pcR5+zWbNm7oSUJHXo0EFRUVHauHGjevXqpUmTJmns2LF69913de655+qKK65Qq1atJEl33nmnbrvtNn377bc699xzNXLkSHXu3LlGsQCn5PB+adNX0oYvpO1LKs5+MgU4E01xbZ232LZSXBtn9VNww6juK7E7tCnjkDP5tCtbv+3O0ea9hyq03klSQkSwWsSEqmVcqFJiQ92PmzWyKTjQvyvFAMAfkZTyANewc9r3AMBDgmzOqiVfnPckjBkzRnfccYdee+01zZo1S8nJyRo8eLAk6cUXX9RLL72kadOm6fTTT1doaKgmTpyo4uITLzkuOdvbjnXs8N2ff/5ZV199tR5//HENHTpUkZGR+uijj/Tiiy+e1OcwDKPKwb5Hbz92dpTJZJLD4Tipc53onEdvf+yxx3Tttdfqq6++0tdff61HH31UH330kS677DKNHTtWQ4cO1VdffaVvv/1WU6ZM0YsvvqgJEybUKB7gpOTsljb+n7TxSyl1uWQc9b+DuPZSu+FS485SXDtnQirQ4rtYfcTuMLTiryx9uma3FvyRofxKrpsbR4SoS7NIdW4apa7NotSpSaQirTWbUQcAqJtISnmAtaxSqpBKKQDwDJOp2m10vnTllVfqrrvu0gcffKC3335b48aNcydUli1bpksuuUTXX3+9JOeMqC1btqh9+/bVeu8OHTooNTVVaWlpSkpytjKuWLGi3D4//fSTkpOT9eCDD7q37dy5s9w+FotFdvvx/1516NBBb7/9tvLy8tzVUj/99JPMZrPatGlTrXhPluvz7dq1y10ttWHDBuXk5JT7GbVp00Zt2rTR3XffrWuuuUazZs3SZZddJklq1qyZbr31Vt16662aPHmy/vOf/5CUgufkpku/zZE2fiHtWV3+taRuUvuLpPYXS7GtKz++gdiUcUifrtmteev2aG9ukXt7REigujSLUpemUercNFJdmkUpIYLWOwDwdz5NSk2ZMkWffvqp/vzzT1mtVvXr10/PPvus2rZte9zjlixZokmTJumPP/5QUlKS7rvvPt16661eivrErLTvAQAkhYWF6aqrrtIDDzygnJwcjR492v3aaaedprlz52r58uWKjo7W1KlTlZGRUe2k1Lnnnqu2bdtq1KhRevHFF5Wbm1su+eQ6R2pqqj766CP16tVLX331lT777LNy+7Ro0ULbt2/XunXr1LRpU4WHhys4OLjcPtddd50effRR3XjjjXrssce0f/9+TZgwQTfccIO7da+m7Ha71q1bV26bxWLRueeeq86dO+u6667TtGnT3IPOBw4cqJ49e6qgoEB///vfdfnllyslJUW7d+/WypUrNXLkSEnSxIkTNWzYMLVp00YHDx7UDz/8UO2fLVBt9lJp60Jp9dvSlm+OqogySc37liWiLnSufteA7TtUqC/WpenTNXu0IT3XvT3SGqSLuiTqsm5N1b15VJUVmQAA/+XTpNSSJUt0++23q1evXiotLdWDDz6oIUOGaMOGDVXO1Ni+fbuGDx+ucePG6b333tNPP/2k8ePHKy4uzn0h6mshtO8BAMqMGTNGM2bM0JAhQ9S8+ZF/mD788MPavn27hg4dKpvNpr/97W+69NJLlZOTU633NZvN+uyzzzRmzBj17t1bLVq00Msvv6zzzz/fvc8ll1yiu+++W3fccYeKiop0wQUX6OGHH9Zjjz3m3mfkyJH69NNPdfbZZys7O1uzZs0qlzyTJJvNpm+++UZ33XWXevXqJZvNppEjR2rq1Kmn9LORpMOHD6tbt27ltiUnJ2vHjh2aN2+eJkyYoLPOOktms1nnn3++XnnlFUlSQECAsrKyNGrUKO3du1exsbEaMWKEHn/8cUnOZNftt9+u3bt3KyIiQueff75eeumlU44XkCQd3CGteVda9750KP3I9ub9pM5XSG0vkMJPLWFbXzkchtJzC7Uzy7kq3sINe7VsS6bsZQOiggJMOrttvEZ0b6qz28UxBwoAGjiTUdlQCh/Zv3+/4uPjtWTJEp111lmV7nP//ffriy++0MaNG93bbr31Vq1fv75C20JlcnNzFRkZqZycnJMe9Fpdt7y7St/8sVdPXdpJ15+R7JFzAEBDUVhYqO3btyslJUUhIbRywDOO93vmjWuH+qDB/xxKi6Q/v5LWvCNtW3Rkuy1G6nqt1G2Uc0B5A1Bqdyj1QL52ZuVrZ1aedh71eNfBAhWXVpwl1615lEZ0a6ILOycpOrThzdACgIamutcNdWqmlOvb4UaNGlW5z4oVKzRkyJBy24YOHaoZM2aopKSkwpBV12pGLrm5ufI0ZkoBAAD4AYdD2r1S2vC59NtHUn5W2QsmqdXZUvdRzqooPx9Uvi+3UGtSs7V210GtTc3W77tzjjumItBsUrNGNjVvZFOXZlG6tGuSWsY1jJUEAQAnp84kpQzD0KRJk9S/f3916tSpyv0yMjIqzK9ISEhQaWmpMjMzlZiYWO61KVOmuEv5vYXV9wAAAOope6m08yfnwPKN/ycdzjjyWnii1O165y26hc9C9KTCErv+SMvV2tSDWrsrW+tSs7Unu6DCftagACXH2MpuoWreyKYWMaFKjrEpMTJEgQFmH0QPAKhv6kxS6o477tBvv/2mH3/88YT7HjsE0dWBWNlwxMmTJ2vSpEnu57m5ue5VfDwlhEHnAAAA9UdpkbRtsbThC2nTfKngwJHXgiOkNudLnUZIp50nBdSZy+daYRiGNu89rMWb9mnxpv1atfOASuzlp3uYTVKbhHB1ax6lbs2i1a15lFrFhclsZjA5AODU1Im/qhMmTNAXX3yhpUuXqmnTpsfdt3HjxsrIyCi3bd++fQoMDFRMTEyF/YODgyusIuRprL4HAABQD+z4UVo1S9r8jVR86Mh2W4zU7gKp/cVSyllSoHevJT3tUGGJftqaqcWb9mvJ5v1Kzyks93psmEVdy5JP3ZpHqXPTKIUF14l/NgAA/IxP/7oYhqEJEybos88+0+LFi5WSknLCY/r27asvv/yy3LZvv/1WPXv2rDBPyleYKQUAAFCHOezSoqelZS8c2RaeJLW/0JmIat7X7yqiNmUc0g9/7tPiTfu0eudBlTqOVEMFB5rVt1WMBrWJ08C28WoRY6u0AwEAgNrm07+2t99+uz744AN9/vnnCg8Pd1dARUZGymq1SnK23+3Zs0fvvPOOJOdKe6+++qomTZqkcePGacWKFZoxY4Y+/PBDn32OYzFTCgBqn8NRcTUnoLbw+9WAHN4vzR0jbV/ifN71eqnHaKlJD8nsX3OQDMPQ0i2Zmr54q37edqDcaymxoRrYJk6D2sbpjJYx7vETAAB4k0+TUtOnT5ckDRo0qNz2WbNmafTo0ZKk9PR0paamul9LSUnR/Pnzdffdd+u1115TUlKSXn75ZY0cOdJbYZ8QM6UAoPZYLBaZzWalpaUpLi5OFouFb/BRawzDUHFxsfbv3y+z2SyLxb9XUWvwUn+RPh4tHUqTgmzSRS9Lna/wdVS1zu4wtOB/GZq+ZKv+t8e58nSg2aQBrWN1drt4DWwTp+SYUB9HCQBAHWjfO5HZs2dX2DZw4ECtWbPGAxHVDpurUqqEb10B4FSZzWalpKQoPT1daWlpvg4Hfspms6l58+Yy+1mlDMoYhvTzdGnhw5KjVIptI135rhTfzteR1aqiUrvmrd2jfy/Zpm2ZeZKcYyWu6d1cYwekKCnK6uMIAQAoz7+a5esI90wp2vcAoFZYLBY1b95cpaWlstv5/1bUroCAAAUGBlKB568Kc6Uv7pA2fO583nGEdPHLUnC4b+OqRXlFpfrw11S9tWy7MnKdQ8sjrUG6sV8Lje7XQo1CqQAEANRNJKU8IKSsUiq/pNTHkQCA/zCZTAoKCqozi1oAqAf2bpD+e4OUtVUyB0lD/yn1/pvkJwnIjJxCffDLTr3z805l55dIkhIigjW2f0td06c5K+YBAOo8/lJ5gKtSikHnAAAAPrJ+jvR/E6WSfCmiiXTF21KzXr6O6pQ5HIZ++itT7/28U99t3Cd72Sp6LWJsunVgK13WvYmCAxlaDgCoH0hKeYC7fY+ZUgAAAN5lL5W+eUD69d/O5y3Plka+JYXG+jauU3Qwr1ifrN6t93/ZqR1Z+e7tvVs00qh+yRrWKVEBZv+oAAMANBwkpTzAamH1PQAAAK8rOiR9crO05Vvn84H3O2/m+lk5ZBiG1qRm6/1fdur/fktXcanzC8/w4ECN6N5E1/ZJVtvG/jMbCwDQ8JCU8gDa9wAAALwsZ4/0wVXS3t+lwBBpxJtSh0t8HdVJMwxDm/Ye0o9bMjV3zR5tTM91v9YxKULXn5Gsi7skKZR5UQAAP8BfMw8ICTpSKWUYBqv5AAAAeFL6emdC6lC6FBonXfOR1LSnr6OqtvScAv24JVM/bs3UT1uzlHm4yP1acKBZF3ZO0vVnNFfXZlFcVwIA/ApJKQ9wte9JUlGpw52kAgAAQC3btMDZsleSJ8W1k679rxSd7Ouojiu3sEQ//5Wln7ZmatnWTG3bn1fudWtQgHqnNNKgtnG6rFsTRdksPooUAADPIinlASGBZvfjgmI7SSkAAABP+OXf0oJ/SIZDajnIucKeNcrXUR3X64u36sVvN7tXzZMks0nq3DRK/U+LVf/WserWPIoV9AAADQJJKQ8IDDDLEmBWsd2hghK7on0dEAAAgD9x2J0r7P3yhvN5txukC1+SAoJ8G9cJ/HflLj23YJMkKSU2VP1Pi9WZp8Wqb6sYRVrrduwAAHgCSSkPCQk6kpQCAABALSk6LM0dK23+2vn83MekMydKdXzW0pLN+zX5s98lSXecfZruHdrWxxEBAOB7JKU8xGoJUG5hKSvwAQAA1Jb8A9I7l0gZvzlX2Lvs31LHS30d1Qn9kZaj8e+tlt1h6LJuTXTPkDa+DgkAgDqBpJSHWMvmSBVSKQUAAFA7lr/iTEjZYp0r7DXr5euITigtu0A3z16pvGK7+raM0bMjO7OCHgAAZcwn3gU14RpuTvseAABALdlU1rJ3/jP1IiGVW1iim2ev1N7cIrWOD9MbN/SQJZDLbwAAXPir6CFWS1lSivY9AACAU3dgu7R/o2QKkFqf6+toTqi41KHx763RnxmHFBcerFk39WKYOQAAxyAp5SFWKqUAAABqz+YFzvvkfpK1bq9tbBiGJn/6u37cmimbJUCzRvdS02ibr8MCAKDOISnlIcyUAgAAqEWu1r22w3wbRzX86/stmrtmtwLMJr12XXd1ahLp65AAAKiTSEp5CO17AAAAtaQwR9r5k/Nxm/N9G8sJfLxql6Z9t0WS9OQlnXR223gfRwQAQN1FUspDXJVS+VRKAQAAnJqt30mOUim2jRTTytfRVGnZlv2a/OnvkqTbz26la/s093FEAADUbSSlPMRVKVVIpRQAAMCpqQeteyv+ytJt761RqcPQJV2TdO+Qtr4OCQCAOi/Q1wH4KwadAwAA1AJ7qbRlofNxm7qXlCqxOzTtu816ffFfMgypT0ojPXd5Z5lMJl+HBgBAnUdSykNCSEoBAACcul0/S4XZkrWR1Ky3r6MpJzUrX3d+tFbrdmVLkq7q2UyPXtxBwYEBvg0MAIB6gvY9Dzky6Nzh40gAAIA/ev3115WSkqKQkBD16NFDy5YtO+7+r732mtq3by+r1aq2bdvqnXfe8VKkp8jVutdmqGSuO8mez9bu1vCXl2ndrmyFhwTq1Wu76dnLO8tm4TtfAACqi7+aHuJq3yukUgoAANSyOXPmaOLEiXr99dd15pln6t///reGDRumDRs2qHnzisO1p0+frsmTJ+s///mPevXqpV9//VXjxo1TdHS0LrroIh98gpPgTkrVjVX3DhWW6JHP/9Bna/dIknomR2va1V3VNNrm48gAAKh/qJTyEGZKAQAAT5k6darGjBmjsWPHqn379po2bZqaNWum6dOnV7r/u+++q1tuuUVXXXWVWrZsqauvvlpjxozRs88+6+XIT1LmFunAX1KARTptsK+j0drUg7rg5R/12do9Mpukiee21kd/O4OEFAAANUSllIeEuNv3SEoBAIDaU1xcrNWrV+sf//hHue1DhgzR8uXLKz2mqKhIISEh5bZZrVb9+uuvKikpUVBQkMfiPSWb5jvvW/SXgsN9FobdYeiNJX/ppYWbVeow1CTKqn9d3VU9WzTyWUwAAPgDKqU8hEopAADgCZmZmbLb7UpISCi3PSEhQRkZGZUeM3ToUL311ltavXq1DMPQqlWrNHPmTJWUlCgzM7PSY4qKipSbm1vu5nWbFjjvfbjqXn5xqUbN/EXPf7NJpQ5DF3RO1Py7BpCQAgCgFpCU8hBmSgEAAE8ymUzlnhuGUWGby8MPP6xhw4bpjDPOUFBQkC655BKNHj1akhQQUPnw8ClTpigyMtJ9a9asWa3Gf0L5B5wr70lSW9/MkzIMQ/fP/V0/bc2SzRKg5y/vrFev6aZIax2tLAMAoJ4hKeUhVovzR0ulFAAAqE2xsbEKCAioUBW1b9++CtVTLlarVTNnzlR+fr527Nih1NRUtWjRQuHh4YqNja30mMmTJysnJ8d927VrV61/luPa8q1kOKSETlJUxeHt3vDWsu36cn2aAs0mzRrdS1f0bFZl4g8AAJw8klIeEhLETCkAAFD7LBaLevTooYULF5bbvnDhQvXr1++4xwYFBalp06YKCAjQRx99pAsvvFBmc+WXg8HBwYqIiCh38yofr7r309ZMTfl6oyTp4Qs7qE/LGJ/EAQCAP2PQuYcwUwoAAHjKpEmTdMMNN6hnz57q27ev3nzzTaWmpurWW2+V5Kxy2rNnj9555x1J0ubNm/Xrr7+qT58+OnjwoKZOnar//e9/evvtt335MapWWixt/d75uO1wr59+98F83fHBGjkMaWT3phrVN9nrMQAA0BCQlPIQq4WZUgAAwDOuuuoqZWVl6YknnlB6ero6deqk+fPnKznZmTxJT09Xamqqe3+73a4XX3xRmzZtUlBQkM4++2wtX75cLVq08NEnOIGdP0rFh6SwBCmpm1dPXVhi1y3vrtbB/BKd3iRS/7ysEy17AAB4CEkpD3FVSpXYDZXYHQoKoFMSAADUnvHjx2v8+PGVvjZ79uxyz9u3b6+1a9d6Iapa4l51b6hURXuhJxiGocmf/q4/0nLVKNSiN27o4R7JAAAAah+ZEg85+gKGaikAAIBqMgxps2ue1DCvnnr28h36bO0eBZhNevXabmoSZfXq+QEAaGhISnlIcKBZ5rJKb+ZKAQAAVNO+DVJ2qhQYIrUc5LXT/rwtS0995Rxs/sDw9urXqvJVCQEAQO0hKeUhJpPpyLBzVuADAACoHteqey0HSRabV06Zll2g299fI7vD0KVdk3TzmS28cl4AABo6klIe5Bp2TqUUAABANW12zZM63yunKyyx67b3Visrr1gdEiM0ZURnBpsDAOAlJKU8KIRKKQAAgOo7vE/avcr52AtJKcMw9PC8/2n97hxF2YL07xt6uL9UBAAAnkdSyoPc7XtUSgEAAJzY5m8kGVJSNyki0eOne++XVH28erfMJunVa7qrWSPvtAsCAAAnklIe5PqmjdX3AAAAqsHduuf5VfcO5BXr6bLB5v8Y1k79WzPYHAAAbyMp5UFH2vccPo4EAACgjisplP76wfm4redb995dsVMFJXZ1ahKhcQNaevx8AACgIpJSHkT7HgAAQDVtXyqV5EsRTaTGnT16qsISu95esUOSdMtZrRhsDgCAj5CU8iCSUgAAANW0+WvnfZvzJQ8niT5evVsH8orVNNqqYZ0ae/RcAACgaiSlPMg9U4rV9wAAAKpmGNKmsnlSbYd79FR2h6G3lm2TJI3tn6LAAC6HAQDwFf4Ke1AIlVIAAAAnlr5eOpQmBYVKLfp79FTf/pGhnVn5irIF6cpezTx6LgAAcHyBvg7An9G+BwAAUA32Yim5vxQaKwWFeOw0hmHojaXOKqlRZyTLZuFSGAAAX+IvsQdZLc5CtALa9wAAAKrWrLd001eSw7MrFv+6/YDW78pWcKBZo/q18Oi5AADAidG+50GuSqlCKqUAAABOzOzZS9M3y6qkLu/RVLFhwR49FwAAODGSUh7ETCkAAIC6YcveQ/r+z30ymaSxA1r6OhwAACCSUh7lWn2P9j0AAADfclVJDe3QWCmxoT6OBgAASCSlPIpB5wAAAL6XkVOoeev2SJL+NpAqKQAA6gqSUh5kszBTCgAAwNdmLd+uEruh3i0aqXvzaF+HAwAAypCU8iDXTKl82vcAAAB84lBhiT74OVWS9LezqJICAKAuISnlQbTvAQAA+NaHv6bqUFGpWsWF6px28b4OBwAAHIWklAe5Bp0XUikFAADgdcWlDs38cYck6ZazWslsNvk2IAAAUA5JKQ+iUgoAAMB3vlyfpozcQsWHB+uSbkm+DgcAAByDpJQHhZCUAgAA8AnDMPTm0m2SpNFntlBwYICPIwIAAMciKeVB7va9EoccDsPH0QAAADQcizfv16a9hxRqCdB1fZJ9HQ4AAKgESSkPcrXvSVJRqcOHkQAAADQsby5xVkld07u5Iq1BPo4GAABUhqSUB4UclZSihQ8AAMA7ftudrRXbshRoNunm/im+DgcAAFSBpJQHBZhNsgQ6f8QkpQAAALxj9vIdkqSLuyQpKcrq22AAAECVSEp5mHsFvmKSUgAAAJ5mGIZ+3JIpSbq8Z1MfRwMAAI6HpJSHuZJShVRKAQAAeFzqgXztO1SkoACTujeP9nU4AADgOEhKeZhrBT7a9wAAADzv1+0HJEmdm0aVm+8JAADqHpJSHhZC+x4AAIDXrNzhTEr1atHIx5EAAIATISnlYdYgBp0DAAB4y8odByVJvVNo3QMAoK4jKeVhrvY9ZkoBAAB41r5DhdqemSeTSeqRTKUUAAB1HUkpD2P1PQAAAO9YVVYl1TYhXJHWIB9HAwAAToSklIdZLYGSaN8DAADwNNeQ894pVEkBAFAfkJTyMGZKAQAAeIcrKcWQcwAA6geSUh5G+x4AAIDn5RaWaGNGriQqpQAAqC9ISnlYiIWkFAAAgKet3nlQhiE1b2RTQkSIr8MBAADVQFLKw9yVUrTvAQAAeMxK5kkBAFDvkJTyMJJSAAAAnrdyR1lSinlSAADUGySlPMxa1r5XSFIKAADAIwpL7Fq/K0eS1ItKKQAA6g2fJqWWLl2qiy66SElJSTKZTJo3b95x91+8eLFMJlOF259//umdgGsghEHnAAAAHvXb7hwV2x2KDQtWixibr8MBAADVFOjLk+fl5alLly666aabNHLkyGoft2nTJkVERLifx8XFeSK8WkH7HgAAgGf9uj1LktQ7JVomk8nH0QAAgOryaVJq2LBhGjZs2EkfFx8fr6ioqNoPyAOOJKUcPo4EAADAP/2646AkqRfzpAAAqFfq5Uypbt26KTExUYMHD9aiRYuOu29RUZFyc3PL3bzJPVOK9j0AAIBaZ3cYWrOTpBQAAPVRvUpKJSYm6s0339TcuXP16aefqm3btho8eLCWLl1a5TFTpkxRZGSk+9asWTMvRnzUTCna9wAAAGrdxvRcHS4qVXhwoNonRpz4AAAAUGf4tH3vZLVt21Zt27Z1P+/bt6927dqlF154QWeddValx0yePFmTJk1yP8/NzfVqYoqZUgAAAJ7z6/YDkqTuydEKMDNPCgCA+qReVUpV5owzztCWLVuqfD04OFgRERHlbt5E+x4AAIDnrNzhTEr1TqF1DwCA+qbeJ6XWrl2rxMREX4dRJSqlAAAAPMMwDJJSAADUYz5t3zt8+LC2bt3qfr59+3atW7dOjRo1UvPmzTV58mTt2bNH77zzjiRp2rRpatGihTp27Kji4mK99957mjt3rubOneurj3BCrqRUqcNQid2hoIB6nwcEAACoE7Zn5inzcLEsgWZ1bhrp63AAAMBJ8mlSatWqVTr77LPdz12zn2688UbNnj1b6enpSk1Ndb9eXFyse++9V3v27JHValXHjh311Vdfafjw4V6PvbpCLEeSUAUldpJSAAAAtcRVJdW1aZSCAwN8HA0AADhZPk1KDRo0SIZhVPn67Nmzyz2/7777dN9993k4qtplCTArwGyS3WGosNiuiJAgX4cEAADgF34pG3LeKyXax5EAAICaoGzHw0wmE3OlAAAAPMBVKdWrBfOkAACoj0hKeUFIWVIqnxX4AAAAakVGTqF2HSiQ2ST1SKZSCgCA+oiklBdYy+ZKUSkFAABqy+uvv66UlBSFhISoR48eWrZs2XH3f//999WlSxfZbDYlJibqpptuUlZWlpeirX2/llVJtU+MUDjjEQAAqJdISnmBq32vkEopAABQC+bMmaOJEyfqwQcf1Nq1azVgwAANGzas3AIxR/vxxx81atQojRkzRn/88Yc+/vhjrVy5UmPHjvVy5LVnZdk8qd4ptO4BAFBfkZTyAmZKAQCA2jR16lSNGTNGY8eOVfv27TVt2jQ1a9ZM06dPr3T/n3/+WS1atNCdd96plJQU9e/fX7fccotWrVrl5chrj2ueVG/mSQEAUG+RlPKCEJJSAACglhQXF2v16tUaMmRIue1DhgzR8uXLKz2mX79+2r17t+bPny/DMLR371598sknuuCCC6o8T1FRkXJzc8vd6oqc/BJt2ntIktSTpBQAAPUWSSkvsFrKklK07wEAgFOUmZkpu92uhISEctsTEhKUkZFR6TH9+vXT+++/r6uuukoWi0WNGzdWVFSUXnnllSrPM2XKFEVGRrpvzZo1q9XPcSpW7Twgw5BaxoYqLjzY1+EAAIAaIinlBe6ZUlRKAQCAWmIymco9NwyjwjaXDRs26M4779Qjjzyi1atXa8GCBdq+fbtuvfXWKt9/8uTJysnJcd927dpVq/GfCteQ815USQEAUK8F+jqAhoCZUgAAoLbExsYqICCgQlXUvn37KlRPuUyZMkVnnnmm/v73v0uSOnfurNDQUA0YMEBPPfWUEhMTKxwTHBys4OC6WYX0a9mQ814MOQcAoF6jUsoLQtztew4fRwIAAOo7i8WiHj16aOHCheW2L1y4UP369av0mPz8fJnN5S/7AgKc1yeGYXgmUA8pKLbr9905khhyDgBAfUdSyguolAIAALVp0qRJeuuttzRz5kxt3LhRd999t1JTU93teJMnT9aoUaPc+1900UX69NNPNX36dG3btk0//fST7rzzTvXu3VtJSUm++hg1snbXQZU6DCVEBKtZI6uvwwEAAKeA9j0vYKYUAACoTVdddZWysrL0xBNPKD09XZ06ddL8+fOVnJwsSUpPT1dqaqp7/9GjR+vQoUN69dVXdc899ygqKkrnnHOOnn32WV99hBpbuf2gJOc8qapmaAEAgPqBpJQXsPoeAACobePHj9f48eMrfW327NkVtk2YMEETJkzwcFSet7JsyHkf5kkBAFDv0b7nBSG07wEAAJyyUrtDa1LLKqVISgEAUO+RlPICZkoBAACcuj/ScpVfbFekNUht4sN9HQ4AADhFJKW8wGpx/piZKQUAAFBza8uqpHokR8tsZp4UAAD1HUkpL3BXSjFTCgAAoMYO5JdIkpKiQnwcCQAAqA0kpbzAanHOk6d9DwAAoOZcVec2C2v1AADgD0hKeQGVUgAAAKcuv7hU0pFFZAAAQP1GUsoLGHQOAABw6vKLXZVSJKUAAPAHJKW8wDXonKQUAABAzRWQlAIAwK+QlPKCENr3AAAATpnrCz4r7XsAAPgFklJe4LpwKip1yOEwfBwNAABA/eRq37NSKQUAgF8gKeUFR184FZZSLQUAAFATtO8BAOBfSEp5QUjgkQsnWvgAAABqxrX6njUo0MeRAACA2kBSygvMZpOCAxl2DgAAcCoKSxySqJQCAMBfkJTyElcLXyFJKQAAgBpxV0qRlAIAwC+QlPISq3sFPoePIwEAAKif3IPOWX0PAAC/QFLKS9xJKSqlAAAATprdYaiolPY9AAD8CUkpLwkhKQUAAFBjR49AsFkYdA4AgD8gKeUlrtkHrL4HAABw8vKPuoZyLSADAADqN/6ie4mrfY9B5wAAACev4Kh5UmazycfRAACA2kBSykto3wMAAKi5/BLnynvMkwIAwH+QlPIS2vcAAABqzl0pRVIKAAC/QVLKS2xUSgEA0KC1aNFCTzzxhFJTU30dSr10dPseAADwDySlvIRKKQAAGrZ77rlHn3/+uVq2bKnzzjtPH330kYqKinwdVr3hGnRO+x4AAP6DpJSXMFMKAICGbcKECVq9erVWr16tDh066M4771RiYqLuuOMOrVmzxtfh1Xn5JbTvAQDgb0hKeYmVpBQAAJDUpUsX/etf/9KePXv06KOP6q233lKvXr3UpUsXzZw5U4Zh+DrEOqnQXSkV6ONIAABAbeGvupdYLc78XyHtewAANGglJSX67LPPNGvWLC1cuFBnnHGGxowZo7S0ND344IP67rvv9MEHH/g6zDonv9i5+h4zpQAA8B8kpbyESikAABq2NWvWaNasWfrwww8VEBCgG264QS+99JLatWvn3mfIkCE666yzfBhl3UX7HgAA/oeklJcwUwoAgIatV69eOu+88zR9+nRdeumlCgoKqrBPhw4ddPXVV/sgurqvgEHnAAD4HZJSXsLqewAANGzbtm1TcnLycfcJDQ3VrFmzvBRR/eK6hqJSCgAA/8Ggcy9xte8VUikFAECDtG/fPv3yyy8Vtv/yyy9atWqVDyKqX9zte8yUAgDAb5CU8hJmSgEA0LDdfvvt2rVrV4Xte/bs0e233+6DiOoX2vcAAPA/JKW8JMRCUgoAgIZsw4YN6t69e4Xt3bp104YNG3wQUf3iXn3PwvQJAAD8BUkpL3FXShU7fBwJAADwheDgYO3du7fC9vT0dAUGkmg5kYIS5zWUjfY9AAD8BkkpL2GmFAAADdt5552nyZMnKycnx70tOztbDzzwgM477zwfRlY/FLgrpUhKAQDgL/hazkusR7XvGYYhk8nk44gAAIA3vfjiizrrrLOUnJysbt26SZLWrVunhIQEvfvuuz6Oru7LZ/U9AAD8DkkpLwkpq5SyOwyV2A1ZAklKAQDQkDRp0kS//fab3n//fa1fv15Wq1U33XSTrrnmGgUFBfk6vDrPPeic9j0AAPwGSSkvOXr54oISuyyBdE4CANDQhIaG6m9/+5uvw6iXXIvF2Bh0DgCA3+CvupcEBZgUYDbJ7jBUWGJXpJVvRAEAaIg2bNig1NRUFRcXl9t+8cUX+yii+uFI+x5f7AEA4C9ISnmJyWSSLShAh4pK3eXnAACg4di2bZsuu+wy/f777zKZTDIMQ5Lccybtdq4PjqfAnZTi8hUAAH9Ro6+adu3apd27d7uf//rrr5o4caLefPPNWgvMH4WUDebMJykFAECDc9dddyklJUV79+6VzWbTH3/8oaVLl6pnz55avHixr8Or00rtDhXbHZKYKQUAgD+pUVLq2muv1aJFiyRJGRkZOu+88/Trr7/qgQce0BNPPFGrAfoT11wp10wEAADQcKxYsUJPPPGE4uLiZDabZTab1b9/f02ZMkV33nmnr8Or046+dmL1PQAA/EeNklL/+9//1Lt3b0nSf//7X3Xq1EnLly/XBx98oNmzZ9dmfH7FlZQqJCkFAECDY7fbFRYWJkmKjY1VWlqaJCk5OVmbNm3yZWh1nqt1z2SSglksBgAAv1GjpvySkhIFBwdLkr777jv3YM527dopPT299qLzM672PWZKAQDQ8HTq1Em//fabWrZsqT59+ui5556TxWLRm2++qZYtW/o6vDrNNfrAFhTgnsEFAADqvxp91dSxY0e98cYbWrZsmRYuXKjzzz9fkpSWlqaYmJhaDdCfWIOcP27a9wAAaHgeeughORzOuUhPPfWUdu7cqQEDBmj+/Pl6+eWXfRxd3ZbPkHMAAPxSjf6yP/vss7rsssv0/PPP68Ybb1SXLl0kSV988YW7rQ8VMVMKAICGa+jQoe7HLVu21IYNG3TgwAFFR0dT/XMCrmsnG/OkAADwKzVKSg0aNEiZmZnKzc1VdHS0e/vf/vY32Wy2WgvO37gGczJTCgCAhqW0tFQhISFat26dOnXq5N7eqFEjH0ZVf7hGH1hZeQ8AAL9So/a9goICFRUVuRNSO3fu1LRp07Rp0ybFx8fXaoD+JCSImVIAADREgYGBSk5Olt3ONUBN5BeXSmLlPQAA/E2NklKXXHKJ3nnnHUlSdna2+vTpoxdffFGXXnqppk+fXqsB+hPa9wAAaLgeeughTZ48WQcOHPB1KPUO7XsAAPinGiWl1qxZowEDBkiSPvnkEyUkJGjnzp165513GNR5HCSlAABouF5++WUtW7ZMSUlJatu2rbp3717uhqq5qsxJSgEA4F9qNFMqPz9f4eHhkqRvv/1WI0aMkNls1hlnnKGdO3fWaoD+xD1TivY9AAAanEsvvdTXIdRbrtX3QpgpBQCAX6lRUuq0007TvHnzdNlll+mbb77R3XffLUnat2+fIiIiajVAfxJCpRQAAA3Wo48+6usQ6i3a9wAA8E81at975JFHdO+996pFixbq3bu3+vbtK8lZNdWtW7daDdCfHGnfc/g4EgAAgPrDNejcZqnR96kAAKCOqtFf9ssvv1z9+/dXenq6unTp4t4+ePBgXXbZZbUWnL9xte+x+h4AAA2P2WyWyWSq8nVW5qtaQbHzCz1W3wMAwL/U+Oumxo0bq3Hjxtq9e7dMJpOaNGmi3r1712ZsfsdVKVVI+x4AAA3OZ599Vu55SUmJ1q5dq7fffluPP/64j6KqHwpKnJVSVmZKAQDgV2rUvudwOPTEE08oMjJSycnJat68uaKiovTkk0/K4aA1rSrMlAIAoOG65JJLyt0uv/xy/fOf/9Rzzz2nL7744qTf7/XXX1dKSopCQkLUo0cPLVu2rMp9R48eLZPJVOHWsWPHU/lIXpPP6nsAAPilGiWlHnzwQb366qt65plntHbtWq1Zs0ZPP/20XnnlFT388MO1HaPfsNG+BwAAjtGnTx999913J3XMnDlzNHHiRD344INau3atBgwYoGHDhik1NbXS/f/1r38pPT3dfdu1a5caNWqkK664ojY+gse5klK07wEA4F9q1L739ttv66233tLFF1/s3talSxc1adJE48eP1z//+c9aC9CfuGdKUSkFAAAkFRQU6JVXXlHTpk1P6ripU6dqzJgxGjt2rCRp2rRp+uabbzR9+nRNmTKlwv6RkZGKjIx0P583b54OHjyom2666dQ+gJcUsvoeAAB+qUZJqQMHDqhdu3YVtrdr104HDhw45aD8lXv1PSqlAABocKKjo8sNOjcMQ4cOHZLNZtN7771X7fcpLi7W6tWr9Y9//KPc9iFDhmj58uXVeo8ZM2bo3HPPVXJycpX7FBUVqaioyP08Nze32jHWNnelFDOlAADwKzVKSnXp0kWvvvqqXn755XLbX331VXXu3LlWAvNHzJQCAKDheumll8olpcxms+Li4tSnTx9FR0dX+30yMzNlt9uVkJBQbntCQoIyMjJOeHx6erq+/vprffDBB8fdb8qUKXVmAPuR9r0ar9EDAADqoBr9ZX/uued0wQUX6LvvvlPfvn1lMpm0fPly7dq1S/Pnz6/tGP0G7XsAADRco0ePrtX3OzrBJTkrr47dVpnZs2crKipKl1566XH3mzx5siZNmuR+npubq2bNmtUo1lNVUOxcfY/2PQAA/EuNBp0PHDhQmzdv1mWXXabs7GwdOHBAI0aM0B9//KFZs2bVdox+w1VyXlzqkN1h+DgaAADgTbNmzdLHH39cYfvHH3+st99+u9rvExsbq4CAgApVUfv27atQPXUswzA0c+ZM3XDDDbJYLMfdNzg4WBEREeVuvuL6Qo/2PQAA/EuNklKSlJSUpH/+85+aO3euPv30Uz311FM6ePDgSV1UNTRHX0gVUi0FAECD8swzzyg2NrbC9vj4eD399NPVfh+LxaIePXpo4cKF5bYvXLhQ/fr1O+6xS5Ys0datWzVmzJhqn68uYPU9AAD8U42TUrVh6dKluuiii5SUlCSTyaR58+ad8JglS5aoR48eCgkJUcuWLfXGG294PtBaEhx45MdNCx8AAA3Lzp07lZKSUmF7cnKyUlNTT+q9Jk2apLfeekszZ87Uxo0bdffddys1NVW33nqrJGfr3ahRoyocN2PGDPXp00edOnWq2YfwEdciMbTvAQDgX3yalMrLy3MPTa+O7du3a/jw4RowYIDWrl2rBx54QHfeeafmzp3r4Uhrh9lsUkiQ80fOCnwAADQs8fHx+u233ypsX79+vWJiYk7qva666ipNmzZNTzzxhLp27aqlS5dq/vz57tX00tPTKyS6cnJyNHfu3HpXJVVc6lBp2dgDWxCDzgEA8Cc+/cs+bNgwDRs2rNr7v/HGG2revLmmTZsmSWrfvr1WrVqlF154QSNHjvRQlLXLGhSgwhIH7XsAADQwV199te68806Fh4frrLPOkuSsAL/rrrt09dVXn/T7jR8/XuPHj6/0tdmzZ1fYFhkZqfz8/JM+j68dXV1O+x4AAP7lpJJSI0aMOO7r2dnZpxLLCa1YsUJDhgwpt23o0KGaMWOGSkpKFBQUVOGYoqIiFRUVuZ/n5uZ6NMYTsQYF6KBKaN8DAKCBeeqpp7Rz504NHjxYgYHOSzCHw6FRo0ad1EyphsZVXR5gNiko4MSrCwIAgPrjpJJSkZGRJ3y9svkFtSUjI6PCqjIJCQkqLS1VZmamEhMTKxwzZcoUPf744x6L6WSFlH3DR/seAAANi8Vi0Zw5c/TUU09p3bp1slqtOv30090td6hcfnGpJMkWFCCTiaQUAAD+5KSSUrNmzfJUHNV27MWIYRiVbneZPHmyJk2a5H6em5urZs2aeS7AE3CtwEelFAAADVPr1q3VunVrX4dRb7iumWjdAwDA//h00PnJaty4sTIyMspt27dvnwIDA6scEBocHKyIiIhyN19yJaWYKQUAQMNy+eWX65lnnqmw/fnnn9cVV1zhg4jqB1d1OUkpAAD8T71KSvXt21cLFy4st+3bb79Vz549K50nVRe5LqiolAIAoGFZsmSJLrjgggrbzz//fC1dutQHEdUP+a6kVBBJKQAA/I1Pk1KHDx/WunXrtG7dOknS9u3btW7dOvcSxpMnTy43o+rWW2/Vzp07NWnSJG3cuFEzZ87UjBkzdO+99/oi/BoJcbXvFTt8HAkAAPCmw4cPy2KxVNgeFBTk84VY6jJXUspGpRQAAH7Hp0mpVatWqVu3burWrZskadKkSerWrZseeeQRSVJ6ero7QSVJKSkpmj9/vhYvXqyuXbvqySef1Msvv6yRI0f6JP6aYKYUAAANU6dOnTRnzpwK2z/66CN16NDBBxHVD66RBzbLSY1CBQAA9YBP/7oPGjTIPai8MrNnz66wbeDAgVqzZo0Ho/Is17d8zJQCAKBhefjhhzVy5Ej99ddfOueccyRJ33//vT744AN98sknPo6u7nJVSoXQvgcAgN/hKycvc11QuZY3BgAADcPFF1+sefPm6emnn9Ynn3wiq9WqLl266IcffvD5Qix1meuaifY9AAD8D0kpL3MPOmemFAAADc4FF1zgHnaenZ2t999/XxMnTtT69etlt1NFXZkCZkoBAOC36tXqe/6AmVIAADRsP/zwg66//nolJSXp1Vdf1fDhw7Vq1Spfh1Vnua6ZrCSlAADwO1RKeZkrKcVMKQAAGo7du3dr9uzZmjlzpvLy8nTllVeqpKREc+fOZcj5CbhmSlmZKQUAgN+hUsrLQtzteySlAABoCIYPH64OHTpow4YNeuWVV5SWlqZXXnnF12HVG7TvAQDgv6iU8jLa9wAAaFi+/fZb3XnnnbrtttvUunVrX4dT7+S72/e4bAUAwN9QKeVlJKUAAGhYli1bpkOHDqlnz57q06ePXn31Ve3fv9/XYdUbVEoBAOC/SEp5mdXi/JEzUwoAgIahb9+++s9//qP09HTdcsst+uijj9SkSRM5HA4tXLhQhw4d8nWIdVpBSakkZkoBAOCPSEp5WUgQM6UAAGiIbDabbr75Zv3444/6/fffdc899+iZZ55RfHy8Lr74Yl+HV2e5B51TKQUAgN8hKeVltO8BAIC2bdvqueee0+7du/Xhhx/6Opw6jfY9AAD8F0kpL3N9y0f7HgAACAgI0KWXXqovvvjC16HUWa4v8khKAQDgf0hKeZmV9j0AAIBqc7XvhTBTCgAAv0NSysuObt8zDMPH0QAAANRtR9r3An0cCQAAqG0kpbwspKz03GFIxXaHj6MBAACouwzDUH6xc/U92vcAAPA/JKW87OjljAuLSUoBAABUpdjukKOssJzV9wAA8D8kpbwsKMCsQLNJEivwAQAAHM/RMzitzJQCAMDvkJTygaPnSgEAAKByriHnQQEmBQVw2QoAgL/hr7sPuMrPXTMSAAAAUJErKUWVFAAA/omklA+4klKFVEoBAABUyXWtxMp7AAD4J5JSPuBu32PQOQAAQJXclVIMOQcAwC+RlPKBEGZKAQAAnJBr1AHtewAA+CeSUj7AoHMAAIATc62+Z6NSCgAAv0RSygfcM6WKSUoBAABUxfUFHu17AAD4J5JSPkClFAAAwImx+h4AAP6NpJQPMFMKAADgxGjfAwDAv5GU8gGrxfljL6B9DwAAoEpHVt8L9HEkAADAE0hK+YCrBL2QSikAAIAquarKqZQCAMA/kZTyAWZKAQAAnFhBcakkZkoBAOCvSEr5QEjZt3207wEAAFTtSPseSSkAAPwRSSkfoFIKAADgxPJp3wMAwK+RlPIBZkoBAACcWCGr7wEA4NdISvmAqwSdSikAAICqudr3QpgpBQCAXyIp5QOuCytmSgEAAFTtSPteoI8jAQAAnkBSygeOzJRy+DgSAACAusu1+h7tewAA+CeSUj5gc6++V+rjSAAAAOou16gDVt8DAMA/kZTygRBW3wMAADgh16gDKzOlAADwSySlfMA96JyZUgAAAFXKZ/U9AAD8GkkpH3B921fITCkAAIBKGYZB+x4AAH6OpJQPuJJSxXaHSu0kpgAAAI5VVOqQYTgfs/oeAAD+iaSUDxz9bV9hKUkpAACAY+UfNeaAmVIAAPgnklI+EBx45MfOXCkAAICK8stWKbYEmhVgNvk4GgAA4AkkpXzAZDIpJtQiSUo9kOfjaAAAAOqeAoacAwDg90hK+UjvlEaSpBV/Zfk4EgAAgLrHNeTcRuseAAB+i6SUj/RtFSNJWrGNpBQAAMCxXDOlQqiUAgDAb5GU8pF+ZUmpVTsOqqiUuVIAAABHo30PAAD/R1LKR1rFhSkuPFhFpQ6tTc32dTgAAAB1iqtSyhYU6ONIAACAp5CU8hGTyaS+LZ3VUsuZKwUAAE7S66+/rpSUFIWEhKhHjx5atmzZcfcvKirSgw8+qOTkZAUHB6tVq1aaOXOml6I9ea6ZUlYqpQAA8FskpXzINVfqZ5JSAADgJMyZM0cTJ07Ugw8+qLVr12rAgAEaNmyYUlNTqzzmyiuv1Pfff68ZM2Zo06ZN+vDDD9WuXTsvRn1yCopLJUlWBp0DAOC3qIf2IVel1NpdB1VQbOebQAAAUC1Tp07VmDFjNHbsWEnStGnT9M0332j69OmaMmVKhf0XLFigJUuWaNu2bWrUyLkCcIsWLbwZ8knLZ6YUAAB+j0opH0qOsSkpMkQldkOrdh7wdTgAAKAeKC4u1urVqzVkyJBy24cMGaLly5dXeswXX3yhnj176rnnnlOTJk3Upk0b3XvvvSooKPBGyDXiSkrxpR0AAP6LSikfMplMOqNVjD5ds0fL/8rSgNZxvg4JAADUcZmZmbLb7UpISCi3PSEhQRkZGZUes23bNv34448KCQnRZ599pszMTI0fP14HDhyocq5UUVGRioqK3M9zc3Nr70NUQ2EJlVIAAPg7KqV8rF+rWEnSCuZKAQCAk2Aymco9NwyjwjYXh8Mhk8mk999/X71799bw4cM1depUzZ49u8pqqSlTpigyMtJ9a9asWa1/huNxV0oxUwoAAL9FUsrHXMPOf9+To0OFJT6OBgAA1HWxsbEKCAioUBW1b9++CtVTLomJiWrSpIkiIyPd29q3by/DMLR79+5Kj5k8ebJycnLct127dtXeh6iGI+17FPYDAOCvSEr5WJMoq5JjbLI7DK3cwVwpAABwfBaLRT169NDChQvLbV+4cKH69etX6TFnnnmm0tLSdPjwYfe2zZs3y2w2q2nTppUeExwcrIiIiHI3byooca6+R/seAAD+i6RUHeBahY8WPgAAUB2TJk3SW2+9pZkzZ2rjxo26++67lZqaqltvvVWSs8pp1KhR7v2vvfZaxcTE6KabbtKGDRu0dOlS/f3vf9fNN98sq9Xqq49xXAUMOgcAwO9RD10H9G0Vo49W7tJyklIAAKAarrrqKmVlZemJJ55Qenq6OnXqpPnz5ys5OVmSlJ6ertTUVPf+YWFhWrhwoSZMmKCePXsqJiZGV155pZ566ilffYQTYqYUAAD+j6RUHeCqlNqQnqvs/GJF2Sw+jggAANR148eP1/jx4yt9bfbs2RW2tWvXrkLLX11WwOp7AAD4Pdr36oD4iBCdFh8mw5B+3sZcKQAAgHza9wAA8HskpeoIV7XUz9to4QMAAHDNlLKx+h4AAH6LpFRt+/0T6at7pKy/Tuqwfq2cSanlf2V6IioAAIB6xdW+x0wpAAD8F0mp2rZqlrTyLSn155M6rE9ZpdTmvYe1/1CRJyIDAACoN/KLSyUxUwoAAH9GUqq2JXZx3qevP6nDGoVa1K5xuCRa+AAAQMPmcBgqLHFIYqYUAAD+jKRUbUvq6rxPX3fSh/ZrFStJWkFSCgAANGCFpXb3Y9r3AADwXySlaltiV+d9xu+Sw37cXY/Vt2yu1Iq/SEoBAICGy7XynkRSCgAAf0ZSqrbFtJKCQqWSfClzy0kd2julkcwmaXtmnjJyCj0UIAAAQN3mWnkvJMgss9nk42gAAICnkJSqbeYAKbGz8/FJtvBFWoPUqUmkJGnFNlbhAwAADZNr5T2bJdDHkQAAAE8iKeUJrmHnaetO+lBXC9/yrbTwAQCAhsnVvkfrHgAA/o2klCe45kqd5Ap8ktS3ZdlcKYadAwCABiq/uFQSK+8BAODvSEp5gmsFvozfJIfjpA7t1aKRAs0m7T5YoF0H8ms/NgAAgDrONVPKRlIKAAC/RlLKE2JaS4FWqfiwdOCvkzo0NDhQXZpFSWIVPgAA0DC5ZkrRvgcAgH8jKeUJAYFS49Odj2swV6qfa67UXww7BwAADY97phSVUgAA+DWSUp7iauE7yRX4pPJzpQzDqL2YAAAA6gHa9wAAaBhISnmKawW+Ggw7754cLUugWXtzi7QtM6+WAwMAAKjbjqy+F+jjSAAAgCeRlPKUo1fgO8lh5yFBAerePEoSc6UAAEDD45opRaUUAAD+jaSUp8S1lQKCpaJc6eD2kz68b8tYSSSlAABAw1NQXCqJmVIAAPg7nyelXn/9daWkpCgkJEQ9evTQsmXLqtx38eLFMplMFW5//vmnFyOupoAgqXEn5+MazJXqd5pzrtTP27LkcDBXCgAANBxH2vdISgEA4M98mpSaM2eOJk6cqAcffFBr167VgAEDNGzYMKWmph73uE2bNik9Pd19a926tZciPkmuFr4arMDXpWmUrEEBysor1uZ9h2o1LAAAgLqMQecAADQMPk1KTZ06VWPGjNHYsWPVvn17TZs2Tc2aNdP06dOPe1x8fLwaN27svgUE1NELllMYdm4JNKtni2hJtPABAICGhZlSAAA0DD5LShUXF2v16tUaMmRIue1DhgzR8uXLj3tst27dlJiYqMGDB2vRokWeDPPUJHV13qevl4yTb8Hr28rZwrecpBQAAGhAXO17IbTvAQDg13yWlMrMzJTdbldCQkK57QkJCcrIyKj0mMTERL355puaO3euPv30U7Vt21aDBw/W0qVLqzxPUVGRcnNzy928Jq69FGCRCrOlgztO+vD+pzmHnS/dvF/7cgtrNzYAAIA66kj7XqCPIwEAAJ7k80HnJpOp3HPDMCpsc2nbtq3GjRun7t27q2/fvnr99dd1wQUX6IUXXqjy/adMmaLIyEj3rVmzZrUa/3EFWqT4Ds7HNWjhO71JpLo3j1JRqUP/XrqtloMDAACom/JLnKvv0b4HAIB/81lSKjY2VgEBARWqovbt21eheup4zjjjDG3ZsqXK1ydPnqycnBz3bdeuXTWOuUbcLXzrTvpQk8mkiee2kSS99/NO7TtEtRQAAPB/rkopK0kpAAD8ms+SUhaLRT169NDChQvLbV+4cKH69etX7fdZu3atEhMTq3w9ODhYERER5W5e5Rp2XoMV+CRpQOvYI9VSS6iWAgAA/s+dlGKmFAAAfs2njfqTJk3SDTfcoJ49e6pv37568803lZqaqltvvVWSs8ppz549eueddyRJ06ZNU4sWLdSxY0cVFxfrvffe09y5czV37lxffozjS+zqvHcNO6+iNbEqJpNJd53bRjfO/FXv/7JTtwxsqfjwkNqPEwAAoI7IZ/U9AAAaBJ8mpa666iplZWXpiSeeUHp6ujp16qT58+crOTlZkpSenq7U1FT3/sXFxbr33nu1Z88eWa1WdezYUV999ZWGDx/uq49wYgkdJXOgVHBAytklRTU/6bc4q3WsujWP0trUbL25ZJseurCDBwIFAACoG/Jp3wMAoEEwGYZh+DoIb8rNzVVkZKRycnK818r3Rn8p43fpqvek9hfV6C2WbN6vG2f+qpAgs5bedzbVUgAAeIlPrh3qIG/9HOwOQ60emC9JWvPweWoUavHYuQAAgGdU97rB56vvNQiuFr4azpWSjlRLFZY49CazpQAAgJ8qKGvdk5gpBQCAvyMp5Q2nsAKfi8lk0l2DW0uS3vtlp/YfKjr1uAAAAOqY/OJSSc4xnCFBXKoCAODP+EvvDUdXSp1Ct+TANnHq2qysWmrpX7USGgAAQF1y9Mp7ppNcIAYAANQvJKW8IaGjZAqQ8jOl3LQav43JZNLEc53VUu/+TLUUAADwPwWsvAcAQINBUsobgqxSXDvn41No4ZPKV0v9ZxmzpQAAgH9xrbwXwjwpAAD8Hkkpb3HPlVp/Sm9jMpl0V1m11DsrdijzMNVSAADAf7ja96iUAgDA/5GU8pZaWIHPZVCbOHVxz5aiWgoAAPgPV6WU1RLo40gAAICnkZTylsQuzvtTbN+Tys+WoloKAAD4E/dMKdr3AADweySlvKXx6ZLJLB3eKx3KOOW3O7pa6j9USwEAAD9RUFwqSbLSvgcAgN8jKeUtFpsU29b5uBZa+EwmkyYOdlVL7aRaCgAA+IUj7XskpQAA8HckpbzJ3cJ3asPOXQa1jVOXppEqKLFTLQUAAPyCKylF+x4AAP6PpJQ3uVfgW1crb+ecLdVGkrNaKotqKQAAUM8VlrD6HgAADQVJKW9yVUrVQvuey9HVUs98/acMw6i19wYAAPA2V6VUCEkpAAD8Hkkpb2rcWZJJOpQmHd5XK29pMpl0//ntZDJJH6/erdcX/1Ur7wsAAOALR9r3An0cCQAA8DSSUt4UHCbFOoeT19ZcKUnqd1qsHr2wgyTp+W826dM1u2vtvQEAALzJtfoe7XsAAPg/klLe5oEWPkkafWaK/nZWS0nSfZ/8ph+3ZNbq+wMAAHhDQQmr7wEA0FCQlPK2xK7O+1oadn60f5zfThd1SVKpw9Ct763WhrTcWj8HAACAJ7na96ysvgcAgN8jKeVt7hX4aq99z8VsNumFKzqrT0ojHS4q1U2zf9We7IJaPw8AAICnFBSz+h4AAA0FSSlva3y68z5nl5SXVetvHxwYoDdH9VSbhDDtzS3S6Jm/Kie/pNbPAwAA4AnuSimSUgAA+D2SUt4WEik1auV87IEWPkmKtAZp9k29lRARrC37Dmvcu6tUWDafAQAAoC5zXbPYLKy+BwCAvyMp5QuuYeceSkpJUlKUVbNv6q3w4ED9uv2A7vl4vRwOw2PnAwAAqA3MlAIAoOEgKeULHpwrdbT2iRH69w09FBRg0le/pWvK1xs9ej4AAIBTlV9cKon2PQAAGgKSUr7gWoEvbZ3HT9XvtFg9f7mzMus/y7Zr5o/bPX5OAACAmiooYdA5AAANBUkpX0js7LzP3int+9Pjp7u0WxPdd35bSdKTX23Qa4u2yk4rHwAAqGNK7A6V2J3XKCSlAADwfySlfMEaLZ12rvPxf0dJRYc9fsrbBrbS6H4tZBjS899s0vVv/aKMnEKPnxcAAKC6Co5amCWEmVIAAPg9klK+cul0KTxRytwkfTFBMjxbuWQymfToRR30/OWdZbMEaMW2LJ3/r6X65o8Mj54XAACgugrKhpybTVJwIJepAAD4O/7a+0pYvHTF25I5UPrjU+mXNzx+SpPJpCt6NtP/Teiv05tEKju/RLe8u1oPfva7e/llAABQP7z++utKSUlRSEiIevTooWXLllW57+LFi2UymSrc/vzT82METoZr5T2bJVAmk8nH0QAAAE8jKeVLzftIQ/7pfPztQ1Lqz145bcu4MM29rZ9uOaulJOn9X1J10Ss/6s+MXK+cHwAAnJo5c+Zo4sSJevDBB7V27VoNGDBAw4YNU2pq6nGP27Rpk9LT09231q1beyni6nFVSrHyHgAADQNJKV/rc4vUcYTkKJU+Hi0d3ueV01oCzZo8vL3eHdNbceHB2rLvsC5+9Se9vXyHDA+3EgIAgFMzdepUjRkzRmPHjlX79u01bdo0NWvWTNOnTz/ucfHx8WrcuLH7FhBQt5I/BSWlkiQr86QAAGgQSEr5mskkXfyKFNtWOpQufXKzZC/12ukHtI7T13cN0Dnt4lVc6tCjX/yhsW+vUtbhIq/FAAAAqq+4uFirV6/WkCFDym0fMmSIli9fftxju3XrpsTERA0ePFiLFi067r5FRUXKzc0td/O0I+17JKUAAGgISErVBcFh0lXvSZYwaccy6YcnvXr62LBgzbixpx67qIMsgWZ9/+c+DfvXMv28LcurcQAAgBPLzMyU3W5XQkJCue0JCQnKyKh8AZPExES9+eabmjt3rj799FO1bdtWgwcP1tKlS6s8z5QpUxQZGem+NWvWrFY/R2Xyad8DAKBBISlVV8S1kS551fn4p2nSxv/z6ulNJpNGn5miz28/U6fFh2nfoSJd+5+f9dqirXI4aOcDAKCuOXYQuGEYVQ4Hb9u2rcaNG6fu3burb9++ev3113XBBRfohRdeqPL9J0+erJycHPdt165dtRp/ZVwLr1ApBQBAw0BSqi7peJl0xu3Ox/Nuk7L+8noI7RMj9MUdZ2pE9yZyGNLz32zSTbNX6kBesddjAQAAFcXGxiogIKBCVdS+ffsqVE8dzxlnnKEtW7ZU+XpwcLAiIiLK3TzNXSnFTCkAABoEklJ1zXmPS837SkW50pwbpOI8r4dgswTqxSu66LmRnRUcaNaSzfs1/F/LtGrHAa/HAgAAyrNYLOrRo4cWLlxYbvvChQvVr1+/ar/P2rVrlZiYWNvhnZIj7XuBPo4EAAB4A0mpuiYgSLp8lhQaL+37Q/q/uyUfrIZnMpl0Za9m+vyOM9UyLlQZuYW66s2f9e8lf9HOBwCAj02aNElvvfWWZs6cqY0bN+ruu+9Wamqqbr31VknO1rtRo0a59582bZrmzZunLVu26I8//tDkyZM1d+5c3XHHHb76CJUqKHYu9mKjUgoAgAaBr6HqoohE6YpZ0tsXS7/NkZr0kPrc4pNQ2jWO0Bd39NeDn/2uz9elacrXf+rX7Qf04pVdFGWz+CQmAAAauquuukpZWVl64oknlJ6erk6dOmn+/PlKTk6WJKWnpys1NdW9f3Fxse69917t2bNHVqtVHTt21FdffaXhw4f76iNUqqCEQecAADQkJsPwQRmOD+Xm5ioyMlI5OTlemY1wSn56WVr4sPPxwPulgf+QzL4pbjMMQx/8mqrHv9yg4lKHmkRZ9cq13dS9ebRP4gEAwFvq1bWDB3nj5/D4l39o1k87dNugVrr//HYeOQcAAPC86l430L5Xl/WbIPW70/l4ybPS3Jul4nyfhGIymXRdn2R9els/tYixaU92ga58Y4We/+ZP/bX/sE9iAgAA/qWgbKYU7XsAADQMJKXqMpNJGvKkdPGrkjlI+uMzafYF0qGMEx/rIZ2aROqLCf01/PTGKnUYem3RXxr84hIN/9cyvb54q3Yd8E3SDAAA1H+07wEA0LCQlKoPut8gjZonWaOltDXSm2dL6et9Fk5ESJBeu7a7Xrmmmwa2iVOg2aQN6bl6bsEmDXhukS557Se9tWyb0nMKfBYjAACof1yr79lYfQ8AgAaBv/j1RYv+0rgfpA+ukjI3SzPPl0a8KbW/yCfhmEwmXdQlSRd1SdKBvGIt+F+G/u+3NP28LUvrd2Vr/a5sPfXVRvVqEa0LOyfpgs6Jig0L9kmsAACgfnC171ktfG8KAEBDQFKqPmnUUhr7nfTxaOmvH6Q510uDH5X63+1s9fNVWKEWXdunua7t01z7DhXq69+dCaqVOw66b0/+3wad3S5eI7s31Tnt4mUJ5GITAACUl19cKkmyBnGJCsA/2O12lZSU+DoMoNYFBQUpIODU2+35i1/fhERK134sfTNZ+vVN6fvHnZVTF/1LCvR9JVJ8eIhu7NdCN/ZrobTsAs3/PV2fr0vT73tytHDDXi3csFfRtiBd0rWJLu/RVB2TImTyYUINAADUHQUlDkmSjZlSAOo5wzCUkZGh7OxsX4cCeExUVJQaN258Sv+mJylVHwUESsOfl2LbSF/fL63/UDqwXbpithSR6Ovo3JKirBo7oKXGDmipzXsPae7q3fp07R7tP1Sk2ct3aPbyHWqbEK7LezTVJd2SFB8e4uuQAQCADxWUVUqRlAJQ37kSUvHx8bLZbHwRD79iGIby8/O1b98+SVJiYs3zECSl6rPe46SYVtJ/R0u7fpZe6S71vUPqN0EKifB1dOW0SQjX5OHt9fehbbVsa6Y+Wb1bCzfs1aa9h/TP+Rv1zII/dVbrWF3arYnO65DAgFMAABog16DzkCCSUgDqL7vd7k5IxcTE+DocwCOsVqskad++fYqPj69xKx//8q/vWp3jnDM17zZpzypp6XPSqpnSwPukHjdJgRZfR1hOYIBZZ7eN19lt45WTX6Ivf0vT3DW7tTY1W4s27deiTftlswRoSIcEXdK1ifq3jlVQAPOnAABoCArcq++RlAJQf7lmSNlsNh9HAniW63e8pKSEpFSDFtfGmZja+IX0/RNS1lbp6/ukn1+XznlY6jhCMte9xE6kLUjXn5Gs689I1l/7D+uzNXv0+fo92nWgQPPWpWneujRF24J0QedEXdK1iXo0j5bZTNkrAAD+qqDk/9u78zApqnOP49/qdaZn32Bm2IZFQfYIqOACRoLg8ojgFXxcIKA+aOCKS1AxCBoj3CQgMSqJkS1qBI3g5caI4oaEJeIyikgQkJ3BgQFm756e7rp/VE8zzTrI0D0Mv8/znKeqq6qrTteZoQ/vnPNWTVBKXVQROftpyp40dvXxM97wIhXy4xgGdLwB7l0D1z0DiU3h4DZ4czT8pR9s+SjWNTyhtlmJPHR1ez755ZUsurcPI/vkkZno4mCFn1fW7OC//rSay3/7EdPe+Q/f7C4mEDRjXWURERGpR1XVQapD3+/xmr4nItJo9OvXj/Hjx8e6GtJA6c9QjY3dCT1HQddhsPoFWPkHKPgKXh5sTfXrPwVyusW6lsdlGAYXtkzjwpZp/OraC1i1pYj/zd/Du+v3svtQJX9avoU/Ld9CUpyDnq3S6NU6nV556XRtnoLboQ6siIjI2apm6h5AvKbviYhE3clGvYwYMYJ58+ad8nkXLVqE0+n8kbWKtGrVKi6//HJ+9rOfsXTp0no5p8SWglKNlSsB+v4Sev4cPvkdrJ0NWz60Su6F0OlG6DQYUlvGuqbH5bDbuOL8LK44P4vf+Dvz4X8K+d/83fxr035KvdXhHFQALoeN7s1T6dU6jV556fRolUZSXP38wyciIiJnXoXfevKew2bgcmgwv4hItBUUFITXFy5cyOOPP87GjRvD22oSW9fw+/11Cjalp6fXWx3nzJnDuHHjeOmll9ixYwctW8bu/7N1/fxyYvrGb+wSMmHQ/8DYtdD5JjBssOcLWDYJZnaBl/rD6ueheFesa3pCcU4713TJ4c+39+SryQP4v7GXMem6jgzslE1Ggouq6iCfbjvA8x9tYeTctXR74j0GzvyECX//ipfXbCd/5yG8/sDJLyQiIiIxUTNSSqOkRERiIzs7O1xSUlIwDCP82uv1kpqayuuvv06/fv2Ii4vjlVdeoaioiFtuuYXmzZvj8Xjo0qULr732WsR5j5y+l5eXx9NPP82oUaNISkqiZcuWvPjiiyetX3l5Oa+//jr33HMP11133TFHbS1ZsoSePXsSFxdHZmYmQ4YMCe/z+XxMmDCBFi1a4Ha7Oe+885g9ezYA8+bNIzU1NeJcb731VsTosSlTptC9e3fmzJlDmzZtcLvdmKbJ0qVLueyyy0hNTSUjI4PrrruOLVu2RJxr165dDB8+nPT0dBISEujZsyf//ve/2bZtGzabjc8++yzi+D/+8Y+0atUK02z8aWs0Uupckd4abpoNA6fBhv+F9W/Btn/BrrVWeXcitLjYSore8QZIzol1jY/LYbfRpXkKXZqnMPqy1pimydb95azddoBPtx5k7bYD7DhQwX/2lvKfvaW8/pkVcHPYDNpnJ9G1eQpdmqXSpVkK7bOT9NdYERGRBqCiJiilfFIi0giZphl+mEO0xTvt9ZZ0/eGHH2b69OnMnTsXt9uN1+ulR48ePPzwwyQnJ/P2229z++2306ZNGy6++OLjnmf69On8+te/ZuLEifz973/nnnvu4YorrqBDhw7Hfc/ChQtp37497du357bbbmPcuHFMmjQp/NnefvtthgwZwmOPPcbLL79MVVUVb7/9dvj9d9xxB6tXr+bZZ5+lW7dubN26lf3795/S59+8eTOvv/46b775Zvhpc+Xl5TzwwAN06dKF8vJyHn/8cW688Uby8/Ox2WyUlZXRt29fmjVrxpIlS8jOzuaLL74gGAySl5dH//79mTt3Lj179gxfZ+7cuYwcOfKcSJavoNS5JjELet1pldIfrCf2fbMIdqyGnf+2ytJHoGVv6DIUOg62Rls1YIZh0CYrkTZZiQzrZQ3f/KHEy1c7D7FudzFf7ypm3e5iDpRXsX5PCev3lPAaOwFw2W20yUrg/KZJnN80kfOaJnF+0yRapnuw60l/IiIiUXP4yXsKSolI41PpD9Dx8Xdjcu1vn7y63p5qOn78+IjRRwAPPfRQeH3cuHEsXbqUN95444RBqWuuuYZ7770XsAJdzzzzDB9//PEJg1KzZ8/mtttuA2DgwIGUlZXxwQcf0L9/fwB+85vfMHz4cJ544onwe7p1s/Ipf/fdd7z++ussW7YsfHybNm1O5aMDUFVVxcsvv0xWVlZ429ChQ4+qZ5MmTfj222/p3Lkzf/vb39i3bx9r164NT2Vs165d+Pg777yTMWPGMGPGDNxuN1999RX5+fksWrTolOt3NlJQ6lyW1BQuussqJXvg2yWwfjHsXAM7VlnlnxOg7ZXW1L8O10JccqxrXSdNk+MY0CmbAZ2yAesvE7sPVbIuFKCqCVYVV/rDI6pqcztstM1KDAeqOmQn0bNVOikezRkWERE5E8IjperpP04iIlL/ao/mAQgEAkybNo2FCxeye/dufD4fPp+PhISEE56na9eu4fWaaYKFhYXHPX7jxo18+umn4UCNw+Fg2LBhzJkzJxxkys/P56677jrm+/Pz87Hb7fTt27dOn/N4WrVqFRGQAtiyZQuTJk1izZo17N+/n2AwCMCOHTvo3Lkz+fn5/OQnPzlubq3BgwczduxYFi9ezPDhw5kzZw5XXnkleXl5p1XXs4W+9cWSnAuXjLFK8S4rOLXu71CQD5vft4ojDs6/2gpQnTcAnHGxrnWdGYZB8zQPzdM8DOpiTU00TZNdByvZuLeU7wpL2fRDGd/9UMrmwjJ81UG+LSjh24KSWueAzrkp9GmXwaVtM+mVl668FyIiIvWkJqeURkqJSGMU77Tz7ZNXx+za9eXIYNP06dN55plnmDlzJl26dCEhIYHx48dTVVV1wvMcmSDcMIxwMOdYZs+eTXV1Nc2aNQtvM00Tp9PJwYMHSUtLOyoRe20n2gdgs9mOyt/k9/uPOu5Ywbbrr7+eFi1a8Je//IXc3FyCwSCdO3cO34OTXdvlcnH77bczd+5chgwZwt/+9jdmzpx5wvc0JgpKydFSmkOfcVbZvxm++bsVoCraBN/+r1XcydDhOmj7U8hsBxntwJ0U65qfEsMwaJHuoUW6h/4dm4a3B4ImOw9U8N0PpWwqtAJV3+wuZsu+8vAoqz8v/x6X3cZPWqbSp20ml7bLoFuLVJx25acSERH5MSpDT99TTikRaYwMw6i3KXQNyYoVK7jhhhvC0+qCwSCbNm3iggsuqLdrVFdX89e//pXp06czYMCAiH1Dhw7l1VdfZezYsXTt2pUPPviAn//850edo0uXLgSDQZYvXx4eWVVbVlYWpaWllJeXhwNP+fn5J61bUVERGzZs4M9//jOXX345AP/6178ijunatSsvvfQSBw4cOO5oqTvvvJPOnTvzwgsv4Pf7j5oi2Zg1vt8KqV+Z7aDfI9D3Ydj7tRWc+mYRlOyCr/5mlRqJ2ZB5nhWgymh3eD21FdjPnh81u80gLzOBvMwEBnQ6vP2HEi+rtuxn5eYiVm3ez55iL//eeoB/bz3AM+9DgsvOha3SaNfEym/VNiuBtlmJNElynxMJ6kRERE5HhZ6+JyJy1mnXrh1vvvkmq1atIi0tjRkzZrB37956DUr94x//4ODBg4wePZqUlJSIfTfddBOzZ89m7NixTJ48mauuuoq2bdsyfPhwqqureeedd5gwYQJ5eXmMGDGCUaNGhROdb9++ncLCQm6++WYuvvhiPB4PEydOZNy4cXz66afHfLrfkdLS0sjIyODFF18kJyeHHTt28Mgjj0Qcc8stt/D0008zePBgpk6dSk5ODl9++SW5ubn07t0bgAsuuIBLLrmEhx9+mFGjRp10dFVjcvZECiS2DANyulml/xNWQvT1i61AVdFmKN8HZXutsm1F5HttTkhtaT0BML0NpLW21tNaQ1reWTMNsGlyHDf+pDk3/qQ5pmmyvaiClVv2s2pzEau27OdghZ8Vm/azYlPkExwS3Q7aZCXQJtMKUrXJSqR1ZgItMzwkuvUrKCIiApq+JyJyNpo0aRJbt27l6quvxuPxcPfddzN48GCKi4vr7RqzZ8+mf//+RwWkwBop9fTTT/PFF1/Qr18/3njjDX79618zbdo0kpOTueKKK8LHzpo1i4kTJ3LvvfdSVFREy5YtmThxIgDp6em88sor/PKXv+TFF1+kf//+TJkyhbvvvvuEdbPZbCxYsID//u//pnPnzrRv355nn32Wfv36hY9xuVy89957PPjgg1xzzTVUV1fTsWNHnn/++YhzjR49mlWrVjFq1KjTuFtnH8M8cuJkI1dSUkJKSgrFxcUkJ58dSbvPCpUHoWiLFaDav8laFm22tlVXnvi9yc0OB6qaXABZHaBJR0jKtoJhZ4Fg0GTD3hK+3lXM9/vK2LKvnO/3lbHjQAXBE/yGpSe4aJHuoVW6h5ah0iLdQ8sMD9nJcXoCoIhIA6C+g+VM34c/frCJ6cu+45aLWjB1SNeTv0FEpIHyer1s3bqV1q1bExd3dvwBXmLvN7/5DQsWLGDdunWxrkqdnehnva79Bg3TkPoRnwbNe1qltmAQSnbDwa1w4Hs4sLXW+jaoKrX2l+yG7ZFzb4lLtYJTTUJBqiYXQNYFkJARrU9VZzabQafcFDrlRkbvfdUBdhRVsGVfOVv2lfF9aLnjQAUHyqvC5audh446p8tuo1WGh7ZZibRrkkjbJgm0y0qiTVYCCRphJSIijUyF3xopFaecUiIicg4pKytjw4YN/PGPf+TXv/51rKsTdfqfrZxZNhuktrBK6ysi95kmVBRZgaoD31sjq/ZtgML/wIEt4D0EO1ZZpTZP5rGnAqa3hoSsBjW6yu2wc17TJM5renQS+FKvnx0HKth5oIId4VLJjqJydh2spCoQZFNhGZsKy2B95HtzU+Jo2ySRtqHcVc3S4mmaHEdOSjxpHqdyWImIyFlH0/dERORcNHbsWF577TUGDx58zk3dAwWlJJYMAxIyrdKiV+Q+vxf2fwf7/gOF31qBqsJv4dB2qNhvlV1rjz6nK9HKU5WWZ42satbDKolNovGJTklSnPOYo6vAegLgnkOVfL+/nM2FZWzZV8bmwjK+31fG/rIq9hR72VPsPSp/FYDLYSMnJS4UpIojOyWOnGRrmZXkpkmStdRfokVEpCGpqLKevtcYn04lIiJyPPPmzatTUvXGSt/60jA54yCnq1Vq85VZI6oObq01FXArHNwGxbugqgx++MYq//nH4feltIRmFx4OUuV0A3diVD/SqbDbDFqE8kv1PT8rYt/B8iq+318WClZZuasKir38UOJlf1kVVdVBthdVsL2o4oTXSI5zRASpmiS5aZLsJjslnhZp8bRI95CR4NKoKxERiYpKfxCAeP3RRERE5JyhoJScXdyJkNvdKkeq9sGhHYenA+79GnZ/Dvs2QvEOq3z7lnWsYbPyVOX+xBpF5Yi3AmGOUHHGh5Y1rz3gSQdPhjUaK4aBmrQEFz0S0unRKv2ofb7qAIUlPgqKvRQUV/JDiZeCYi97i73sLfGyr9RHYamPquogJd5qSrzVbNlXftxrxTvttEiPp0WaFSBrHgpWtUjzkJMSR6qmCoqISD2pDI2Uitf0PRERkXOGglLSeDjckHmeVWrzlkBBvhWg2vUZ7P4CSvccHlF1quxua8qhJ93Kb5WQaS09GZDUNJTfqg0k5Vg5taLI7bCHR1gdj2malFRWs6/MS2GJj31lPgpLfBSWeiks9VFwyMvOgxXsLfFS6Q/w3Q9lfPdD2THP5bQbZCW6yUpykxUacVVTmiS5yUx0Ee904HLYcDtsuBw2XHZb+LXDHt37IyIiDVeFckqJiIiccxSUksYvLtlKsl470XrJHis4VZBvBa2qK608VtWh4q+ste4Ff4WVlL3aCwHf4ScGnogj/nBC9vCyDaS3heRcsMWm020YBikeJykeJ+2aHJ2AvYavOsCeQ95wMvadByvYdaCSnQet1wcr/PgDZji/FRSfcl1shpUDK8HliMiBlZsaT3btnFgp8frLuYhII1cTlNL0PRERkXOHglJybkrOtcoF19X9PaZpBafKQ4nWKw6E1ous1+X7obTAmjp4cLsV6Cr81irHEpcC8enWiKv4tFrrtbbFpVrHxSVbS3eyNbUwClPm3A47rTMTaJ2ZcMz9vuoA+8uq2FfqC00L9NZat5b7y3z4qoP4/AGqAkGqqoMEzcPnCJrg9Qfx+qsoKq/i24KS49Yn1eOkSZKb9AQXGQnWMj3BRUbi4dcZida2NI8Lu03TCkVEziZef81IKXVPRUREzhX61hepK8MAV4JV0lqd+NiAH4p3WgGqmhxXB76Hoi1WUvagH7zFVjm49dTqYXNGBqnikq1RWQ6Xlf/K7ramMjriam1zgTsJUppDSgtIbWG9/zS4HXaapcbTLDX+lN5XHQiGA1S+amtZ6q2ulf+q0lqWeNlzyFqvqApwqMLPoQp/na5htxlkJLhokmwlcm+abE0vbBJO6G6tp3qcxDvtyoslItIAhEdKuTS1W0RE5FyhoJTImWB3Hp6ud6RgACoPWiOtKg8cXh617SB4D1nTC73F4CsBM2gFtCqKrHI63ClWcKomSFWzTMyOHJ1Vz4ndHXYrl5THFbm9Y27yMY83TZNSXzUFh6yRWEXlPg6UV3Gg3BpddaCsZt3afqjSTyBoUhgasQXHH30FVl6s5DgnKfFOkkMlJd5JSryD5DgnCW6HNdqrOoDPHzy8Xh0MvbbWbQZkJLrJTHCRkWiN3MpMtNYzQtuS4xwKgImIHMfh6XvqnoqInM369etH9+7dmTlzJgB5eXmMHz+e8ePHH/c9hmGwePFiBg8efFrXrq/zSPToW18k2mx2Kzl6Quapvc80oaosNMKqVqDKW3I411W1L5QLqyq0LbSs9lnHF++EQzutwJevGH4oPnmyd8N2eESWO+VwwMqddHjkmKvWeu3tzgTAhGD1ESUQ+dqwQ3IzKyiW0CQiQbxhWEGj5Gwn7bOPnwOrRnUgSFF5VUTy9sISHz+UhhK7h7btK/VRHTTxB0yKQgGuM81pN0h0O4hz2ol32nE77cQ7beHXcS47cQ478S4bKfFOUuNdpHqcpHlcpCU4SfW4SI23lpqeKCKNTc3T95ToXEQkNq6//noqKyt5//33j9q3evVq+vTpw+eff86FF154Suddu3YtCQnHTgnyY02ZMoW33nqL/Pz8iO0FBQWkpaXV67WOp7KyktzcXAzDYPfu3cTHn9oMErEoKCVytjAMK+DjToLTm3kHvjIo3hUKUu04HKwq3gnl+w4HvYJ+a3SW95BVosHusgJUKc0htWVoymFo2mFiU3AnWqO3XInW9MQjOOw2mibH0TQ5jhPdKNM0Ka8KUFLpp7jSf3jpraa41rbKqgBup/W0QLfDbi2dR6/7A0GKyqwRW9ayiqIyX2hZRZmvGn/A5GCFH6jbNMQTSY5zhEZjHX7iYVaim8zQsmZbRqILu2Gwr8xHQbGXH4qtaZLh6ZIlXvaGXtttBpmJ1lMTM0PnCp+/Zluim8Q4BwkuB3FOm0Z+iUi9ME2TSr+eviciEkujR49myJAhbN++nVatItOVzJkzh+7du59yQAogKyurvqp4UtnZ2VG71ptvvknnzp0xTZNFixZx6623Ru3aRzJNk0AggMNx9oV4zr4ai8jpcydCkw5WOR7TtEZZRYzKOnT4dVUZVJVbS1+t9dqv/RVWMM3mOEGxWyO6indD6R5r/eDWuuXasrus4FTtQJU7ETBqjcjyR47QClivjWA1iWaQxGCAXDNg7TMDoSmSQWs9GLBGinnSwZNxuCRkWktnBrhC2+KSIcdpTd20JVl1szutz2h34g3aKKo0qSwrprp0H4GyfZjl+zHL92OvLMJWWYTDewCn7yCuqmLKjAQOGKkUkkZBIIVd/iS2+5LYVpXEPjOVEm8cJd5qthVVnPQ2GYbVnHWx40AFOw6c/Jw15/U47XjcDjwuOx5XzdJOovtw0CwzyZrWWBPkykx0keg+9lRG0zTxVQepqApQ6Q9QWVVNZVUQu82wRovFuxQME2mEfLUehBGnoJSISExcd911NGnShHnz5jF58uTw9oqKChYuXMjTTz9NUVERY8eOZcWKFRw4cIC2bdsyceJEbrnlluOe98jpe5s2bWL06NF8+umntGnThj/84Q9Hvefhhx9m8eLF7Nq1i+zsbG699VYef/xxnE4n8+bN44knngAI9wnnzp3LyJEjj5q+t27dOu677z5Wr16Nx+Nh6NChzJgxg8TERABGjhzJoUOHuOyyy5g+fTpVVVUMHz6cmTNn4nQ6T3i/Zs+ezW233YZpmsyePfuooNT69euZMGECK1aswDRNunfvzrx582jbti1gBfqmT5/O5s2bSU9PZ+jQoTz33HNs27aN1q1b8+WXX9K9e3cADh06RFpaGh999BH9+vXj448/5sorr2Tp0qU89thjfP3117z77ru0bNmSBx54gDVr1lBeXs4FF1zA1KlT6d+/f7hePp+PSZMm8dprr1FYWEjLli155JFHGDVqFOeddx5jxozhoYceCh//zTff0LVrVzZt2hSue31SUEpEjs0wrCf9OeMhqWl0rhnwW08wPLTz8Eiu4tD6oZ3WUw59ZdZURbACWJWhPFxnUsluq5yGOKDZ6dbDANzWatCZQJU7gyp7PF7cVJouyk0XZQEnJQEnxX4HB/wOKkwXPtMBhh1PnIuEODeJ8S4S41wkxbtJ8sSR7HGT7InDDAYor6ikorKCcq8Pr7cSn9eLz+fFV+WjuspHtb+KwkAiBWY6e8009vozKKhKZx8JoQrWjdthIzPRjcdlp9IfwOsPhANRJwuguRw20jxWgCrF44xYN7D+c+sP1BSTqkAQf2hbVSBIdcAkzmkFz+Jd1tRJa90KqsU7re01ATbr2MP7agJwCo6J1J/KUD4psILdIiKNTs2TvGPB6alTjliHw8Edd9zBvHnzePzxx8P9nDfeeIOqqipuvfVWKioq6NGjBw8//DDJycm8/fbb3H777bRp04aLL774pNcIBoMMGTKEzMxM1qxZQ0lJyTFzTSUlJTFv3jxyc3NZt24dd911F0lJSUyYMIFhw4bxzTffsHTp0vBUw5SUo2dIVFRUMHDgQC655BLWrl1LYWEhd955J2PHjmXevHnh4z766CNycnL46KOP2Lx5M8OGDaN79+7cddddx/0cW7ZsYfXq1SxatAjTNBk/fjzff/89bdpYOYV3797NFVdcQb9+/fjwww9JTk5m5cqVVFdbU9VnzZrFAw88wLRp0xg0aBDFxcWsXLnypPfvSBMmTOD3v/89bdq0ITU1lV27dnHNNdfw1FNPERcXx/z587n++uvZuHEjLVu2BOCOO+5g9erVPPvss3Tr1o2tW7eyf/9+DMNg1KhRzJ07NyIoNWfOHC6//PIzEpACBaVEpCGxO60pe6ktT3xcwF9rRFbNstQaneUrA0zrKYU2e3ikUnhUls1Ra5/dymdl2A6v2454bQasxPM1yeXL9x9er73NV2qNygpUh5Z+a3kszgRIyABPKLeYJzPydVyqNRqtbC+UFUJpaFm2F0p/AH85Nn85cf5y4oBjp4gHjvx/XTVQFirHcdJMZwbH/OYI2OPwebKpjGtCmasppY50yqsNyv0m5VVBykLLUl8QXwCCpkGg1BY6oYkBGJhgs5YG4LCBy2HgshmYZpCqKj8GARwEsFeY2CsCOIoC2AliJ4iNIF5clBJPmRlPKR4qzXjKa70uM+MpI54ANgLYQu+qWTc4lcAaYOUCc9pwOULFbsNpt6Z7HrnNYTewGVax22rWradF2mzWusNmvTfOaQ/lGgvlHHPZcTusa8U77TgdNmuYdhACQZOgaZWa9UAQgqaJw2bgcTlIdDvwuK0RbDVBtbrkJTND5/QHTKqDwXDdnXYbNgMF5aTeVISm7rlCD8MQEWl0/BXwdG5srj1xj5XvtQ5GjRrF7373u/BIHLCCEkOGDCEtLY20tLSIgMW4ceNYunQpb7zxRp2CUu+//z4bNmxg27ZtNG/eHICnn36aQYMGRRz3q1/9Kryel5fHgw8+yMKFC5kwYQLx8fEkJibicDhOOF3v1VdfpbKykr/+9a/hnFbPPfcc119/Pf/zP/9D06bWH97T0tJ47rnnsNvtdOjQgWuvvZYPPvjghEGpOXPmMGjQoHD+qoEDBzJnzhyeeuopAJ5//nlSUlJYsGBBeMTV+eefH37/U089xYMPPsh9990X3tarV6+T3r8jPfnkk/zsZz8Lv87IyKBbt24R11m8eDFLlixh7NixfPfdd7z++ussW7YsPHqqJpAG8POf/5zHH3+cTz/9lIsuugi/388rr7zC7373u1OuW10pKCUiZx+7E+LTrBINaXk/7n1mKMl7TYAqUA0ujzX67HT4yqDsByv/l78C/JWhUnHsZbU3NCWx1rTEY01VtNlDATzn4emH4WVo3bBbI9ZK9oRGkO2BiiLsAS+e0m14SreRcaK620KlzvcQqBlAEYVvrCA2TAyC2PAbTioMD6V4KDU9lJjxFAfjKA7GUxLaVhqMx+tzEfTZCJi1A11GeD2AjSoMvOFzW2E3E4OgacMEgqFrGpikGOWkUUaqYRUHpdiNchIpJdUoJ9Uow4OXKpz4TKe1rCmmtQyGXpdh5yA2gqYRuoaBGaqfzWbHbrdht9utUFwwgGnW/JzU/FwEsRlWbWuCfwZB7DWvDWvdYQSxG9Y207BRhocSEikhgZLQerGZEHqdQDEJ+AwPTpcbh8uNy+XG6XIR73YT77KTEAqc1YxkiwsF5+IcdtzOw0G7uFoBvLQEJ02S4s78D4mcETUjpeI1dU9EJKY6dOhAnz59mDNnDldeeSVbtmxhxYoVvPfeewAEAgGmTZvGwoUL2b17Nz6fD5/PV+dE5hs2bKBly5bhgBRA7969jzru73//OzNnzmTz5s2UlZVRXV1NcvJx/xR73Gt169Ytom6XXnopwWCQjRs3hoNSnTp1wm4//P2Tk5PDunXrjnveQCDA/PnzI6Yd3nbbbdx///088cQT2O128vPzufzyy485BbCwsJA9e/Zw1VVXndLnOZaePXtGvC4vL+eJJ57gH//4B3v27KG6uprKykp27NgBQH5+Pna7nb59+x7zfDk5OVx77bXMmTOHiy66iH/84x94vV7+67/+67TrejwxD0q98MIL/O53v6OgoIBOnToxc+ZMLr/88uMev3z5ch544AHWr19Pbm4uEyZMYMyYMVGssYhIHRnG4YBOfXKHcmdlnJkhtKfM77XygZXsgZICK1hVVlgr8BWoFeg4RsEIDSkPjbo51vpRucnsh0e+GTVLmxWI85WGSsnhpbfk8Paa6Z/HYCMIgJ0ATtOPx6yIHD12qkG1M+10ByqZWCPojnVegx/3WeuYvwwT8IVKSMA08OOgCgd+HFRjpxo7JgYB0xYO3tUE+8xQ8M+HwRdZVzBw3LM/osLSEISDUpq6JyKNldNjjViK1bVPwejRoxk7dizPP/88c+fOpVWrVuEAyvTp03nmmWeYOXMmXbp0ISEhgfHjx1NVVbcnWZvHyNNw5MjrNWvWMHz4cJ544gmuvvrq8Iij6dOnn9LnME3zuKO6a28/MnBkGAbBYPC453333XfZvXs3w4YNi9geCAR47733GDRo0AmfxHeyp/TZQk8ir32v/P5jz8A4Mhj4y1/+knfffZff//73tGvXjvj4eG666aZw+9TlCYF33nknt99+O8888wxz585l2LBheDyn9jN0KmIalFq4cCHjx4/nhRde4NJLL+XPf/4zgwYN4ttvvw3Pd6xt69atXHPNNdx111288sorrFy5knvvvZesrCyGDh0ag08gIiI44yC9jVXOBqFk94cDZoHQqLZAZCAtUFUryX/J4SBXzXrNPr/3iFFotc4bDsjVLM1QCQJmreBczTYgLsVKrh+fbo0GPNa6y2PVr9pXq3itEqgKrfusz1orAGiaQaoDAfz+avzVAfzV1firq8GwYbPZsNkd4RFUNpsDm92G3WbH5nBYHSTDTsC0AkMBo2YEVmiEmBkaHRYMYK8qwe4rwV5VjN13CLuvGJuv2FpWlWD3FWP4yzHMyA6fNdrKT9yxnlB5kgBc0Lygfn4+JCYqqqzoqJ68JyKNlmHUeQpdrN18883cd999/O1vf2P+/Pncdddd4SDOihUruOGGG7jtttsAK0fUpk2buOCCun0Pd+zYkR07drBnzx5yc63pjKtXr444ZuXKlbRq1YrHHnssvG379u0Rx7hcLgKBACfSsWNH5s+fT3l5eTh4s3LlSmw2W8RUulM1e/Zshg8fHlE/gGnTpjF79mwGDRpE165dmT9/Pn6//6igV1JSEnl5eXzwwQfhKZK11TytsKCggJ/85CeANcKpLlasWMHIkSO58cYbASgrK2Pbtm3h/V26dCEYDLJ8+fKI5Oe1XXPNNSQkJDBr1izeeecdPvnkkzpd+8eKaVBqxowZjB49mjvvvBOAmTNn8u677zJr1iymTp161PF/+tOfaNmyJTNnzgTgggsu4LPPPuP3v/+9glIiIlI3Z2L02lnCAJyh8mPV652reSJmoOrwsiYnW6Aq9LrWSLuIUXe1p6AG6Z6cU581kyhrn53E/FEX4ahDrjMRETmzEhMTGTZsGBMnTqS4uJiRI0eG97Vr144333yTVatWkZaWxowZM9i7d2+dg1L9+/enffv23HHHHUyfPp2SkpKjgjvt2rVjx44dLFiwgF69evH222+zePHiiGPy8vLYunUr+fn5NG/enKSkJNxud8Qxt956K5MnT2bEiBFMmTKFffv2MW7cOG6//fbw1L1TtW/fPv7v//6PJUuW0Llz54h9I0aM4Nprr2Xfvn2MHTuWP/7xjwwfPpxHH32UlJQU1qxZw0UXXUT79u2ZMmUKY8aMoUmTJgwaNIjS0lJWrlzJuHHjiI+P55JLLmHatGnk5eWxf//+iBxbJ9KuXTsWLVrE9ddfj2EYTJo0KWLUV15eHiNGjGDUqFHhROfbt2+nsLCQm2++GQC73c7IkSN59NFHadeu3TGnV9anmE1CqKqq4vPPP2fAgAER2wcMGMCqVauO+Z7Vq1cfdfzVV1/NZ599dtzhbCIiItJA2ezWSLu4ZCvZf3KO9aCDjLbQ5ALI6QbNLoTmPaHFRdCqN+RdCq0vhzb9oO1P4bz+cP4AyO4S608jpyHV46Lv+Vlc2u6kj1sQEZEoGD16NAcPHqR///4Rs5gmTZrEhRdeyNVXX02/fv3Izs5m8ODBdT6vzWZj8eLF+Hw+LrroIu68805+85vfRBxzww03cP/99zN27Fi6d+/OqlWrmDRpUsQxQ4cOZeDAgVx55ZVkZWXx2muvHXUtj8fDu+++y4EDB+jVqxc33XQTV111Fc8999yp3YxaapKmHysf1JVXXklSUhIvv/wyGRkZfPjhh5SVldG3b1969OjBX/7yl/CoqREjRjBz5kxeeOEFOnXqxHXXXcemTZvC55ozZw5+v5+ePXty3333hROon8wzzzxDWloaffr04frrr+fqq6/mwgsvjDhm1qxZ3HTTTdx777106NCBu+66i/Ly8ohjRo8eTVVVFaNGjTrVW3TKDPNYkzqjYM+ePTRr1oyVK1fSp0+f8Pann36a+fPns3HjxqPec/755zNy5EgmTpwY3rZq1SouvfRS9uzZQ07O0X8lrUm8VqOkpIQWLVpQXFx8yonSRERE5NxTUlJCSkrKOd930H0QEakbr9fL1q1bad26NXFxegiHnH1WrlxJv3792LVr1wlHlZ3oZ72u/YaYp2s9MvHYiZKRHe/4Y22vMXXqVFJSUsKlRYsWp1ljEREREREREZHGxefzsXnzZiZNmsTNN9/8o6c5noqYBaUyMzOx2+3s3bs3YnthYeFxP3h2dvYxj3c4HGRkHPsh5I8++ijFxcXhsnPnzvr5ACIiIiIiIiIijcRrr71G+/btKS4u5re//W1UrhmzoJTL5aJHjx4sW7YsYvuyZcsipvPV1rt376OOf++99+jZs+dRGe1ruN1ukpOTI4qIiIiIiIiIiBw2cuRIAoEAn3/+Oc2aNYvKNWM6fe+BBx7gpZdeYs6cOWzYsIH777+fHTt2MGbMGMAa5XTHHXeEjx8zZgzbt2/ngQceYMOGDcyZM4fZs2fz0EMPxeojiIiIiIiIiIjIj+CI5cWHDRtGUVERTz75JAUFBXTu3Jl//vOftGrVCoCCggJ27NgRPr5169b885//5P777+f5558nNzeXZ599lqFDh8bqI4iIiIiIiIiIyI8Qs6fvxYqeHCMiIiKnQn0Hi+6DiEjd1DyRLC8vj/j4+FhXR+SMqaysZNu2bWf30/dEREREREREGouafMcVFRUxronImVXzM368HN91EdPpeyIiIiIiIiKNid1uJzU1lcLCQgA8Hg+GYcS4ViL1xzRNKioqKCwsJDU1Fbvd/qPPpaCUiIiIiIiISD3Kzs4GCAemRBqj1NTU8M/6j6WglIiIiIiIiEg9MgyDnJwcmjRpgt/vj3V1ROqd0+k8rRFSNRSUEhERERERETkD7HZ7vfzHXaSxUqJzERERERERERGJOgWlREREREREREQk6hSUEhERERERERGRqDvnckqZpglASUlJjGsiIiIiZ4OaPkNNH+JcpT6UiIiI1FVd+0/nXFCqtLQUgBYtWsS4JiIiInI2KS0tJSUlJdbViBn1oURERORUnaz/ZJjn2J/9gsEge/bsISkpCcMw6v38JSUltGjRgp07d5KcnFzv55e6UTs0DGqH2FMbNAxqh9g7nTYwTZPS0lJyc3Ox2c7dzAfqQzV+aoOGQe3QMKgdYk9t0DD82Haoa//pnBspZbPZaN68+Rm/TnJysn5xGgC1Q8Ogdog9tUHDoHaIvR/bBufyCKka6kOdO9QGDYPaoWFQO8Se2qBh+DHtUJf+07n75z4REREREREREYkZBaVERERERERERCTqFJSqZ263m8mTJ+N2u2NdlXOa2qFhUDvEntqgYVA7xJ7aoOFTG8We2qBhUDs0DGqH2FMbNAxnuh3OuUTnIiIiIiIiIiISexopJSIiIiIiIiIiUaeglIiIiIiIiIiIRJ2CUiIiIiIiIiIiEnUKStWzF154gdatWxMXF0ePHj1YsWJFrKvUqH3yySdcf/315ObmYhgGb731VsR+0zSZMmUKubm5xMfH069fP9avXx+byjZSU6dOpVevXiQlJdGkSRMGDx7Mxo0bI45RO5xZs2bNomvXriQnJ5OcnEzv3r155513wvt1/2Nj6tSpGIbB+PHjw9vUFmfelClTMAwjomRnZ4f3qw0aJvWfokv9p9hT/6lhUB+q4VH/KTZi2X9SUKoeLVy4kPHjx/PYY4/x5ZdfcvnllzNo0CB27NgR66o1WuXl5XTr1o3nnnvumPt/+9vfMmPGDJ577jnWrl1LdnY2P/vZzygtLY1yTRuv5cuX84tf/II1a9awbNkyqqurGTBgAOXl5eFj1A5nVvPmzZk2bRqfffYZn332GT/96U+54YYbwl8Uuv/Rt3btWl588UW6du0asV1tER2dOnWioKAgXNatWxfepzZoeNR/ij71n2JP/aeGQX2ohkX9p9iKWf/JlHpz0UUXmWPGjInY1qFDB/ORRx6JUY3OLYC5ePHi8OtgMGhmZ2eb06ZNC2/zer1mSkqK+ac//SkGNTw3FBYWmoC5fPly0zTVDrGSlpZmvvTSS7r/MVBaWmqed9555rJly8y+ffua9913n2ma+l2IlsmTJ5vdunU75j61QcOk/lNsqf/UMKj/1HCoDxUb6j/FViz7TxopVU+qqqr4/PPPGTBgQMT2AQMGsGrVqhjV6ty2detW9u7dG9Embrebvn37qk3OoOLiYgDS09MBtUO0BQIBFixYQHl5Ob1799b9j4Ff/OIXXHvttfTv3z9iu9oiejZt2kRubi6tW7dm+PDhfP/994DaoCFS/6nh0e9JbKj/FHvqQ8WW+k+xF6v+k+O0zyAA7N+/n0AgQNOmTSO2N23alL1798aoVue2mvt+rDbZvn17LKrU6JmmyQMPPMBll11G586dAbVDtKxbt47evXvj9XpJTExk8eLFdOzYMfxFofsfHQsWLOCLL75g7dq1R+3T70J0XHzxxfz1r3/l/PPP54cffuCpp56iT58+rF+/Xm3QAKn/1PDo9yT61H+KLfWhYk/9p9iLZf9JQal6ZhhGxGvTNI/aJtGlNomesWPH8vXXX/Ovf/3rqH1qhzOrffv25Ofnc+jQId58801GjBjB8uXLw/t1/8+8nTt3ct999/Hee+8RFxd33OPUFmfWoEGDwutdunShd+/etG3blvnz53PJJZcAaoOGSG3S8KhNokf9p9hSHyq21H9qGGLZf9L0vXqSmZmJ3W4/6q96hYWFR0UUJTpqnhagNomOcePGsWTJEj766COaN28e3q52iA6Xy0W7du3o2bMnU6dOpVu3bvzhD3/Q/Y+izz//nMLCQnr06IHD4cDhcLB8+XKeffZZHA5H+H6rLaIrISGBLl26sGnTJv0+NEDqPzU8+j2JLvWfYk99qNhS/6lhimb/SUGpeuJyuejRowfLli2L2L5s2TL69OkTo1qd21q3bk12dnZEm1RVVbF8+XK1ST0yTZOxY8eyaNEiPvzwQ1q3bh2xX+0QG6Zp4vP5dP+j6KqrrmLdunXk5+eHS8+ePbn11lvJz8+nTZs2aosY8Pl8bNiwgZycHP0+NEDqPzU8+j2JDvWfGi71oaJL/aeGKar9p9NOlS5hCxYsMJ1Opzl79mzz22+/NcePH28mJCSY27Zti3XVGq3S0lLzyy+/NL/88ksTMGfMmGF++eWX5vbt203TNM1p06aZKSkp5qJFi8x169aZt9xyi5mTk2OWlJTEuOaNxz333GOmpKSYH3/8sVlQUBAuFRUV4WPUDmfWo48+an7yySfm1q1bza+//tqcOHGiabPZzPfee880Td3/WKr99BjTVFtEw4MPPmh+/PHH5vfff2+uWbPGvO6668ykpKTwd7HaoOFR/yn61H+KPfWfGgb1oRom9Z+iL5b9JwWl6tnzzz9vtmrVynS5XOaFF14YfqyrnBkfffSRCRxVRowYYZqm9fjKyZMnm9nZ2abb7TavuOIKc926dbGtdCNzrPsPmHPnzg0fo3Y4s0aNGhX+dycrK8u86qqrwp0p09T9j6UjO1VqizNv2LBhZk5Ojul0Os3c3FxzyJAh5vr168P71QYNk/pP0aX+U+yp/9QwqA/VMKn/FH2x7D8Zpmmapz/eSkREREREREREpO6UU0pERERERERERKJOQSkREREREREREYk6BaVERERERERERCTqFJQSEREREREREZGoU1BKRERERERERESiTkEpERERERERERGJOgWlREREREREREQk6hSUEhERERERERGRqFNQSkTkNBmGwVtvvRXraoiIiIicNdR/EhFQUEpEznIjR47EMIyjysCBA2NdNREREZEGSf0nEWkoHLGugIjI6Ro4cCBz586N2OZ2u2NUGxEREZGGT/0nEWkINFJKRM56breb7OzsiJKWlgZYQ8NnzZrFoEGDiI+Pp3Xr1rzxxhsR71+3bh0//elPiY+PJyMjg7vvvpuysrKIY+bMmUOnTp1wu93k5OQwduzYiP379+/nxhtvxOPxcN5557FkyZIz+6FFREREToP6TyLSECgoJSKN3qRJkxg6dChfffUVt912G7fccgsbNmwAoKKigoEDB5KWlsbatWt54403eP/99yM6TbNmzeIXv/gFd999N+vWrWPJkiW0a9cu4hpPPPEEN998M19//TXXXHMNt956KwcOHIjq5xQRERGpL+o/iUhUmCIiZ7ERI0aYdrvdTEhIiChPPvmkaZqmCZhjxoyJeM/FF19s3nPPPaZpmuaLL75opqWlmWVlZeH9b7/9tmmz2cy9e/eapmmaubm55mOPPXbcOgDmr371q/DrsrIy0zAM85133qm3zykiIiJSX9R/EpGGQjmlROSsd+WVVzJr1qyIbenp6eH13r17R+zr3bs3+fn5AGzYsIFu3bqRkJAQ3n/ppZcSDAbZuHEjhmGwZ88errrqqhPWoWvXruH1hIQEkpKSKCws/LEfSUREROSMUv9JRBoCBaVE5KyXkJBw1HDwkzEMAwDTNMPrxzomPj6+TudzOp1HvTcYDJ5SnURERESiRf0nEWkIlFNKRBq9NWvWHPW6Q4cOAHTs2JH8/HzKy8vD+1euXInNZuP8888nKSmJvLw8Pvjgg6jWWURERCSW1H8SkWjQSCkROev5fD727t0bsc3hcJCZmQnAG2+8Qc+ePbnssst49dVX+fTTT5k9ezYAt956K5MnT2bEiBFMmTKFffv2MW7cOG6//XaaNm0KwJQpUxgzZgxNmjRh0KBBlJaWsnLlSsaNGxfdDyoiIiJST9R/EpGGQEEpETnrLV26lJycnIht7du35z//+Q9gPdllwYIF3HvvvWRnZ/Pqq6/SsWNHADweD++++y733XcfvXr1wuPxMHToUGbMmBE+14gRI/B6vTzzzDM89NBDZGZmctNNN0XvA4qIiIjUM/WfRKQhMEzTNGNdCRGRM8UwDBYvXszgwYNjXRURERGRs4L6TyISLcopJSIiIiIiIiIiUaeglIiIiIiIiIiIRJ2m74mIiIiIiIiISNRppJSIiIiIiIiIiESdglIiIiIiIiIiIhJ1CkqJiIiIiIiIiEjUKSglIiIiIiIiIiJRp6CUiIiIiIiIiIhEnYJSIiIiIiIiIiISdQpKiYiIiIiIiIhI1CkoJSIiIiIiIiIiUaeglIiIiIiIiIiIRN3/A/HdRiiH8hYjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we train the fusion model.\n",
    "num_classes = 47\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "dropout_rate = 0.3\n",
    "image_embed_size = train_image_features[0].shape[1]\n",
    "audio_embed_size = train_audio_features[0].shape[1]\n",
    "hidden_dim = 512\n",
    "# Create the fusion model\n",
    "fusion_model = FusionANN(image_embed_size, audio_embed_size, hidden_dim, num_classes, dropout_rate)\n",
    "fusion_model.to(device)\n",
    "# Train the model.\n",
    "_, history = train_fusion_model(fusion_model, \n",
    "                                train_image_features, \n",
    "                                train_audio_features, \n",
    "                                train_labels, \n",
    "                                val_image_features, \n",
    "                                val_audio_features, \n",
    "                                val_labels, \n",
    "                                num_epochs=num_epochs, \n",
    "                                batch_size=batch_size, \n",
    "                                learning_rate=learning_rate, \n",
    "                                device=device)\n",
    "# Plot the training history\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:02<00:00, 67.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9953\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the test set.\n",
    "test_image_features, test_audio_features, test_labels = extract_features(image_model, audio_model, test_loader, device)\n",
    "test_accuracy, class_accuracy = evaluate_model(fusion_model, test_image_features, test_audio_features, test_labels, device)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE421",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
