{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOhFYpJpn4+Ei8Jg92K/+T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8U_SCR3OOeeC"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from skimage.feature import hog\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","source":["# Path to audio dataset (update this path)\n","DATASET_PATH = \"path/to/audio_dataset\""],"metadata":{"id":"nw6aw0KdOmEc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to convert audio to spectrogram\n","def audio_to_spectrogram(audio_path, img_size=(128, 128)):\n","    y, sr = librosa.load(audio_path, sr=None)\n","    S = librosa.feature.melspectrogram(y=y, sr=sr)\n","    S_dB = librosa.power_to_db(S, ref=np.max)\n","\n","    fig, ax = plt.subplots()\n","    librosa.display.specshow(S_dB, sr=sr, ax=ax)\n","    ax.axis('off')\n","    fig.canvas.draw()\n","\n","    img = np.array(fig.canvas.renderer.buffer_rgba())\n","    img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n","    img = cv2.resize(img, img_size)\n","    plt.close(fig)\n","    return img"],"metadata":{"id":"_JsdLFD7O2aQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to load audio files and extract HOG features\n","def extract_features_and_labels(dataset_path, img_size=(128, 128)):\n","    features = []\n","    labels = []\n","    label_encoder = LabelEncoder()\n","\n","    for category in os.listdir(dataset_path):\n","        category_path = os.path.join(dataset_path, category)\n","        if not os.path.isdir(category_path):\n","            continue\n","\n","        for file_name in os.listdir(category_path):\n","            file_path = os.path.join(category_path, file_name)\n","            if not file_path.endswith(\".wav\"):\n","                continue\n","\n","            img = audio_to_spectrogram(file_path, img_size)\n","            hog_features = hog(img, pixels_per_cell=(16, 16), cells_per_block=(2, 2),\n","                               orientations=9, block_norm='L2-Hys', visualize=False)\n","            features.append(hog_features)\n","            labels.append(category)\n","\n","    labels = label_encoder.fit_transform(labels)\n","    return np.array(features), np.array(labels), label_encoder"],"metadata":{"id":"qi0XkvDOPZJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load data and extract features\n","X, y, label_encoder = extract_features_and_labels(DATASET_PATH)\n","\n","# Split dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train SVM classifier\n","svm_classifier = SVC(kernel='linear', C=1.0)\n","svm_classifier.fit(X_train, y_train)\n","\n","# Evaluate the model\n","y_pred = svm_classifier.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Model Accuracy: {accuracy:.2f}\")\n","\n","# Save the trained model\n","import joblib\n","joblib.dump(svm_classifier, \"svm_audio_classifier.pkl\")\n","joblib.dump(label_encoder, \"label_encoder.pkl\")\n"],"metadata":{"id":"rUdravZkPdSh"},"execution_count":null,"outputs":[]}]}